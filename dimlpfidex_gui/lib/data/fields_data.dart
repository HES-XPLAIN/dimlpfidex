import 'package:dimlpfidex_gui/data/field.dart';
import 'package:dimlpfidex_gui/data/common_fields_data.dart';

// TODO: Handle differenciation between float and int
// TODO: handle this input to fit float & int options
// TODO: Add the empty option in restricted choices list

// const List<Field> testFields = [
//   rootFolderFld,
//   Field(
//     "Normalization file",
//     "normalization_file",
//     Datatype.filePath,
//     defaultValue: "normalization.txt",
//   ),
//   seedFld,
//   dropoutDimFld,
//   Field(
//     "Data files to normalize",
//     "data_files",
//     Datatype.listFilePath,
//     description:
//         "Data files to normalize, they are normalized with respect to the first one if normalization_file is not specified",
//   ),
//   Field("Dropdown", "dropdown", Datatype.restrictedChoiceString,
//       description: "Random dropdown",
//       items: [
//         "choice one",
//         "choice two",
//         "choice three",
//         "choice four",
//         "choice five"
//       ]),
//   Field(
//     "Using dichotomic search",
//     "search-strategy",
//     Datatype.boolean,
//     description:
//         "Whether or not to use the dichotomic search strategy, can increase speed.",
//     defaultValue: "true",
//   ),
//   musFld,
//   sigmasFld,
//   Field(
//     "Enums",
//     "enums",
//     Datatype.listString,
//     description: "List of words",
//     defaultValue: "hello, my, name, is, test",
//   ),
//   Field(
//     "Random dict",
//     "random_dict",
//     Datatype.dictionary,
//     description: "Dictionary",
//     defaultValue: "{1:2, 3:4, 5:6}",
//   ),
// ];

const List<Field> fidexFields = [
  rootFolderFld,
  trainDataFileFld,
  Field(
    "Train true classes file",
    "train_class_file",
    Datatype.filePath,
    description:
        "Path to the file containing the train true classes of the dataset, mandatory if classes are not specified in train data file.",
  ),
  trainPredFileFld,
  Field(
    "Test data file",
    "test_data_file",
    Datatype.filePath,
    isRequired: true,
    description:
        "Path to the file containing the test sample(s) data, prediction (if no test prediction file is specified) and true class (if no test true classes file is specified).",
  ),
  Field(
    "Weights file",
    "weights_file",
    Datatype.filePath,
    description:
        "Path to the file containing the trained weights of the model (mandatory if no rules file is given).",
  ),
  Field(
    "Rules file",
    "rules_file",
    Datatype.filePath,
    description:
        "Path to the file containing the trained rules to be converted to hyperlocus (mandatory if no weights file is given).",
  ),
  Field(
  "Rules output file",
  "rules_outfile",
  Datatype.filePath,
  isRequired: true,
  description: "Path to the file where the output rule(s) will be stored. If a .json extension is given, rules are saved in JSON format.",
  ),
  nbAttributesFld,
  nbClassesFld,
  Field(
    "Test true classes file",
    "test_class_file",
    Datatype.filePath,
    description:
        "Path to the file containing the test true classes of the dataset. If at least the test prediction file is specified, the test data file needs to have only the test datas and eventually classes on same line (don't add the test true classes file in this case).",
  ),
  Field(
    "Test prediction file",
    "test_pred_file",
    Datatype.filePath,
    description:
        "Path to the file containing predictions on the test portion of the dataset.",
  ),
  Field(
    "Attributes file",
    "attributes_file",
    Datatype.filePath,
    description: "Path to the file containing the labels of attributes and classes.",
  ),
  Field(
    "Output statistics file",
    "stats_file",
    Datatype.filePath,
    description:
        "Path to the file where statistics concerning the algorithm execution will be stored.",
  ),
  consoleFileFld,
  Field(
    "Maximum number of training iterations",
    "max_iterations",
    Datatype.integer,
    minValue: "1",
    maxValue: "inf",
    defaultValue: "10",
    description:
        "Maximum training iteration number, also the maximum possible number of attributes in a rule, it should be 25 when working with images.",
  ),
  Field(
    "Minimum covering number",
    "min_covering",
    Datatype.integer,
    minValue: "1",
    maxValue: "inf",
    defaultValue: "2",
    description: "Minimum number of samples covered by the generated rules.",
  ),
  Field(
    "Use covering strategy",
    "covering_strategy",
    Datatype.boolean,
    defaultValue: "true",
    description:
        "Whether to use the covering strategy: if no rule is found with minimum covering, find best rule with best covering using dichotomic search. Decreases minimum fidelity if needed.",
  ),
  Field(
    "Maximum number of failed attempts to find a Fidex rule",
    "max_failed_attempts",
    Datatype.integer,
    minValue: "0",
    maxValue: "inf",
    defaultValue: "30",
    description:
        "Maximum number of failed attempts to find a Fidex rule when the covering is 1 and the covering strategy is used.",
  ),
  Field(
    "Minimal rule fidelity accepted",
    "min_fidelity",
    Datatype.doublePrecision,
    minValue: "0.0",
    maxValue: "1.0",
    defaultValue: "1.0",
    description: "Minimal rule fidelity accepted when generating a rule.",
  ),
  Field(
    "Lowest minimal rule fidelity accepted",
    "lowest_min_fidelity",
    Datatype.doublePrecision,
    minValue: "0.0",
    maxValue: "1.0",
    defaultValue: "0.75",
    description:
        "Minimal min_fidelity to which we agree to go down during the covering strategy.",
  ),
  dropoutDimFld,
  dropoutHypFld,
  Field(
    "Decision threshold for predictions",
    "decision_threshold",
    Datatype.doublePrecision,
    minValue: "0.0",
    maxValue: "1.0",
    description:
        "The decision threshold used for predictions, you need to specify the index of the positive class if you want to use it.",
  ),
  Field(
    "Index of positive class",
    "positive_class_index",
    Datatype.integer,
    minValue: "0",
    maxValue: "# classes - 1",
    description:
        "Index of the positive class for the usage of a decision threshold, index starts at 0.",
  ),
  nbQuantLevelsFld,
  Field(
    "Normalization file",
    "normalization_file",
    Datatype.filePath,
    description:
        "Path to the file containing the mean and standard deviation of some attributes. Used to denormalize the rules if specified.",
  ),
  musFld,
  sigmasFld,
  normalizationIndicesFld,
  seedFld,
];

const List<Field> fidexGloFields = [
  rootFolderFld,
  Field(
    "Test data file",
    "test_data_file",
    Datatype.filePath,
    isRequired: true,
    description:
        "Path to the file containing test sample(s) data, prediction (if no test prediction file is specified) and true class if launching with fidex (and if no test true classes file is specified).",
  ),
  Field(
  "Global rules input file",
  "global_rules_file",
  Datatype.filePath,
  isRequired: true,
  description: "Path to the file containing the global rules obtained with fidexGloRules algorithm.",
  ),
  nbAttributesFld,
  nbClassesFld,
  Field(
    "Test prediction file",
    "test_pred_file",
    Datatype.filePath,
    description:
        "Path to the file containing predictions on the test portion of the dataset. If given, test data file needs to have only the test data.",
  ),
  Field(
    "Explanation file",
    "explanation_file",
    Datatype.filePath,
    description: "Path to the file where explanation(s) will be stored.",
  ),
  Field(
    "Attributes file",
    "attributes_file",
    Datatype.filePath,
    description:
        "Path to the file containing the labels of attributes and classes. Mandatory if rules file contains attribute names, if not, do not add it.",
  ),
  consoleFileFld,
  Field(
    "Use minimal version",
    "with_minimal_version",
    Datatype.boolean,
    defaultValue: "false",
    description:
        "Whether to use minimal version, which only gets correct activated rules and if with_fidex, launches Fidex when no such rule is found.",
  ),
  Field(
    "Use fidex algorithm (train data, prediction and class files, and either weights file or rules files are then mandatory)",
    "with_fidex",
    Datatype.boolean,
    defaultValue: "false",
    description:
        "Whether to use the Fidex algorithm if no rule is found in global rules.",
  ),
  Field(
    "Train data file",
    "train_data_file",
    Datatype.filePath,
    description: "Path to the file containing the train portion of the dataset.",
  );
  Field(
    "Train true classes file",
    "train_class_file",
    Datatype.filePath,
    description:
        "Path to the file containing the train true classes of the dataset. Mandatory if classes are not specified in train data file.",
  ),
  Field(
    "Train prediction file",
    "train_pred_file",
    Datatype.filePath,
    description:
        "Path to the file containing predictions on the train portion of the dataset.",
  );
  Field(
    "Weights file",
    "weights_file",
    Datatype.filePath,
    description:
        "Path to the file containing the trained weights of the model (mandatory if no rules file is given).",
  ),
  Field(
    "Rules file",
    "rules_file",
    Datatype.filePath,
    description:
        "Path to the file containing the trained rules to be converted to hyperlocus (mandatory if no weights file is given).",
  ),
  Field(
    "Test true classes file",
    "test_class_file",
    Datatype.filePath,
    description:
        "Path to the file containing the test true classes of the dataset. Classes can be specified in the test data file.",
  ),
  Field(
    "Maximum number of training iterations",
    "max_iterations",
    Datatype.integer,
    minValue: "1",
    maxValue: "inf",
    defaultValue: "10",
    description:
        "Maximum training iteration number, also the maximum possible number of attributes in a rule, it should be 25 when working with images.",
  ),
  Field(
    "Minimum covering number",
    "min_covering",
    Datatype.integer,
    minValue: "1",
    maxValue: "inf",
    defaultValue: "2",
    description: "Minimum number of samples covered by the generated rules.",
  ),
  Field(
    "Use covering strategy",
    "covering_strategy",
    Datatype.boolean,
    defaultValue: "true",
    description:
        "Whether to use the covering strategy: if no rule is found with minimum covering, find best rule with best covering using dichotomic search. Decreases minimum fidelity if needed.",
  ),
  Field(
    "Maximum number of failed attempts to find a Fidex rule",
    "max_failed_attempts",
    Datatype.integer,
    minValue: "0",
    maxValue: "inf",
    defaultValue: "30",
    description:
        "Maximum number of failed attempts to find a Fidex rule when the covering is 1 and the covering strategy is used.",
  ),
  Field(
    "Minimal rule fidelity accepted",
    "min_fidelity",
    Datatype.doublePrecision,
    minValue: "0.0",
    maxValue: "1.0",
    defaultValue: "1.0",
    description: "Minimal rule fidelity accepted when generating a rule.",
  ),
  Field(
    "Lowest minimal rule fidelity accepted",
    "lowest_min_fidelity",
    Datatype.doublePrecision,
    minValue: "0.0",
    maxValue: "1.0",
    description:
        "Minimal min_fidelity to which we agree to go down during the covering strategy.",
  ),
  Field(
  "Number of Fidex rules to generate per sample with Fidex",
  "nb_fidex_rules",
  Datatype.integer,
  minValue: "1",
  maxValue: "inf",
  defaultValue: "1",
  description:
      "Number of Fidex rules to compute per sample when launching the Fidex algorithm.",
  ),
  dropoutDimFld,
  dropoutHypFld,
  nbQuantLevelsFld,
  Field(
    "Normalization file",
    "normalization_file",
    Datatype.filePath,
    description:
        "Path to the file containing the mean and standard deviation of some attributes. Used to denormalize the rules if specified.",
  ),
  musFld,
  sigmasFld,
  normalizationIndicesFld,
  seedFld,
];

const List<Field> fidexGloRulesFields = [
  rootFolderFld,
  trainDataFileFld,
  Field(
    "Train true classes file",
    "train_class_file",
    Datatype.filePath,
    description:
        "Path to the file containing the train true classes of the dataset, mandatory if classes are not specified in train data file.",
  ),
  trainPredFileFld,
  Field(
    "Weights file",
    "weights_file",
    Datatype.filePath,
    description:
        "Path to the file containing the trained weights of the model (mandatory if no rules file is given).",
  ),
  Field(
    "Rules file",
    "rules_file",
    Datatype.filePath,
    description:
        "Path to the file containing the trained rules to be converted to hyperlocus (mandatory if no weights file is given).",
  ),
  Field(
  "Global rules output file",
  "global_rules_outfile",
  Datatype.filePath,
  isRequired: true,
  description: "Path to the file where the output rule(s) will be stored. If a .json extension is given, rules are saved in JSON format.",
  ),
  Field(
    "Heuristic",
    "heuristic",
    Datatype.integer,
    description:
        "Heuristic 1: optimal fidexGlo, 2: fast fidexGlo 3: very fast fidexGlo. (Faster algorithms are less efficient).",
    minValue: "1",
    maxValue: "3",
    defaultValue: "1",
    isRequired: true,
  ),
  nbAttributesFld,
  nbClassesFld,
  Field(
    "Attributes file",
    "attributes_file",
    Datatype.filePath,
    description: "Path to the file containing the labels of attributes and classes.",
  ),
  consoleFileFld,
  Field(
    "Maximum number of training iterations",
    "max_iterations",
    Datatype.integer,
    minValue: "1",
    maxValue: "inf",
    defaultValue: "10",
    description:
        "Maximum training iteration number, also the maximum possible number of attributes in a rule, it should be 25 when working with images.",
  ),
  Field(
    "Minimum covering number",
    "min_covering",
    Datatype.integer,
    minValue: "1",
    maxValue: "inf",
    defaultValue: "2",
    description: "Minimum number of samples covered by the generated rules.",
  ),
  Field(
    "Use covering strategy",
    "covering_strategy",
    Datatype.boolean,
    defaultValue: "true",
    description:
        "Whether to use the covering strategy: if no rule is found with minimum covering, find best rule with best covering using dichotomic search. Decreases minimum fidelity if needed.",
  ),
  Field(
    "Maximum number of failed attempts to find a Fidex rule",
    "max_failed_attempts",
    Datatype.integer,
    minValue: "0",
    maxValue: "inf",
    defaultValue: "30",
    description:
        "Maximum number of failed attempts to find a Fidex rule when the covering is 1 and the covering strategy is used.",
  ),
  Field(
    "Minimal rule fidelity accepted",
    "min_fidelity",
    Datatype.doublePrecision,
    minValue: "0.0",
    maxValue: "1.0",
    defaultValue: "1.0",
    description: "Minimal rule fidelity accepted when generating a rule.",
  ),
  Field(
    "Lowest minimal rule fidelity accepted",
    "lowest_min_fidelity",
    Datatype.doublePrecision,
    minValue: "0.0",
    maxValue: "1.0",
    defaultValue: "0.75",
    description:
        "Minimal min_fidelity to which we agree to go down during the covering strategy.",
  ),
  dropoutDimFld,
  dropoutHypFld,
  Field(
    "Decision threshold for predictions",
    "decision_threshold",
    Datatype.doublePrecision,
    minValue: "0.0",
    maxValue: "1.0",
    description:
        "The decision threshold used for predictions, you need to specify the index of the positive class if you want to use it.",
  ),
  Field(
    "Index of positive class",
    "positive_class_index",
    Datatype.integer,
    minValue: "0",
    maxValue: "# classes - 1",
    description:
        "Index of the positive class for the usage of a decision threshold, index starts at 0.",
  ),
  nbQuantLevelsFld,
  Field(
    "Normalization file",
    "normalization_file",
    Datatype.filePath,
    description:
        "Path to the file containing the mean and standard deviation of some attributes. Used to denormalize the rules if specified.",
  ),
  musFld,
  sigmasFld,
  normalizationIndicesFld,
  Field(
    "Number of threads used for computing the algorithm",
    "nb_threads",
    Datatype.integer,
    minValue: "1",
    maxValue: "# CPU cores",
    description:
        "Number of threads used for computing the algorithm, 1=sequential execution.",
  ),
  seedFld
];

const List<Field> fidexGloStatsFields = [
  rootFolderFld,
  Field(
    "Test data file",
    "test_data_file",
    Datatype.filePath,
    description: "Path to the file containing the test portion of the dataset.",
    isRequired: true,
  ),
  Field(
    "Test true classes file",
    "test_class_file",
    Datatype.filePath,
    description:
        "Path to the file containing the test true classes of the dataset, mandatory if classes are not specified in test data file.",
  ),
  Field(
    "Test prediction file",
    "test_pred_file",
    Datatype.filePath,
    description: "Path to the file containing predictions on the test portion of the dataset.",
    isRequired: true,
  ),
  Field(
    "Global rules input file",
    "global_rules_file",
    Datatype.filePath,
    description: "Path to the file containing the global rules obtained with fidexGloRules algorithm.",
    isRequired: true,
  ),
  nbAttributesFld,
  nbClassesFld,
  Field(
    "Output rules file",
    "global_rules_outfile",
    Datatype.filePath,
    description:
        "Path to the file where the output global rules will be stored with stats on test set, if you want to compute those statistics.",
  ),
  Field(
    "Attributes file",
    "attributes_file",
    Datatype.filePath,
    description:
        "Path to the file containing the labels of attributes and classes. Mandatory if rules file contains attribute names, if not, do not add it.",
  ),
  Field(
    "Output statistics file",
    "stats_file",
    Datatype.filePath,
    description: "Path to the file where statistics of the global ruleset will be stored.",
  ),
  consoleFileFld,
  Field(
    "Index of positive class",
    "positive_class_index",
    Datatype.integer,
    description:
        "Index of positive class for the usage of a decision threshold and to compute true/false positive/negative rates, index starts at 0. If it is specified in the rules file, it has to be the same value.",
    minValue: "0",
    maxValue: "# classes - 1",
  ),
];

const List<Field> dimlpTrnFields = [
  rootFolderFld,
  trainDataFileFld,
  Field(
    "Train true classes file",
    "train_class_file",
    Datatype.filePath,
    description:
        "Path to the file containing the train true classes of the dataset, mandatory if classes are not specified in the train data file.",
  ),
  nbAttributesFld,
  nbClassesFld,
  Field(
    "Output train prediction file",
    "train_pred_outfile",
    Datatype.filePath,
    defaultValue: "dimlpTrain.out",
    description: "Path to the file where the train predictions will be stored.",
  ),
  Field(
    "Test data file",
    "test_data_file",
    Datatype.filePath,
    description: "Path to the file containing the test portion of the dataset.",
  ),
  Field(
    "Test true classes file",
    "test_class_file",
    Datatype.filePath,
    description:
        "Path to the file containing the test true classes of the dataset.",
  ),
  Field(
    "Output test prediction file",
    "test_pred_outfile",
    Datatype.filePath,
    defaultValue: "dimlpTest.out",
    description: "Path to the file where the test predictions will be stored.",
  ),
  Field(
    "Validation data file",
    "valid_data_file",
    Datatype.filePath,
    description: "Path to the file containing the validation portion of the dataset.",
  ),
  Field(
    "Validation true classes file",
    "valid_class_file",
    Datatype.filePath,
    description:
        "Path to the file containing the validation true classes of the dataset.",
  ),
  Field(
    "Output validation prediction file",
    "valid_pred_outfile",
    Datatype.filePath,
    defaultValue: "dimlpValidation.out",
    description: "Path to the file where the validation predictions will be stored.",
  ),
  Field(
    "Pretrained weights file",
    "weights_file",
    Datatype.filePath,
    description: "Path to the file containing pretrained weights.",
  ),
  Field(
    "Output weights file",
    "weights_outfile",
    Datatype.filePath,
    defaultValue: "dimlp.wts",
    description: "Path to the file where the output trained weights of the model will be stored.",
  ),
  Field(
    "Attributes file",
    "attributes_file",
    Datatype.filePath,
    description: "Path to the file containing the labels of attributes and classes.",
  ),
  Field(
    "Output statistics file",
    "stats_file",
    Datatype.filePath,
    defaultValue: "statsDimlpTrn.txt",
    description: "Path to the file where the train, test and validation accuracy will be stored.",
  ),
  consoleFileFld,
  Field(
    "Number of neurons in the first hidden layer",
    "first_hidden_layer",
    Datatype.integer,
    minValue: "1",
    maxValue: "inf",
    description:
        "Number of neurons in the first hidden layer. It has to be a multiple of the number of attributes. The default value is the number of attributes.",
  ),
  Field(
    "Number of neurons in each hidden layer",
    "hidden_layers",
    Datatype.listInteger,
    minValue: "1",
    maxValue: "inf",
    description:
        "Number of neurons in each hidden layer, from the second layer to the last.",
  ),
  Field(
    "Output hidden layers file",
    "hidden_layers_outfile",
    Datatype.filePath,
    defaultValue: "hidden_layers.out",
    description: "Path to the file where output hidden layers sizes will be stored.",
  ),
  Field(
    "Whether to extract rules with dimlp algorithm",
    "with_rule_extraction",
    Datatype.boolean,
    defaultValue: "false",
    description: "Whether to extract rules with dimlp algorithm.",
  ),
  Field(
    "Global rules output file",
    "global_rules_outfile",
    Datatype.filePath,
    description: "Path to the file where the output rule(s) will be stored.",
    ),
  Field(
    "Back-propagation learning rate",
    "learning_rate",
    Datatype.doublePrecision,
    minValue: "0",
    maxValue: "inf",
    defaultValue: "0.1",
    description: "Back-propagation learning rate parameter.",
  ),
  Field(
    "Back-propagation momentum parameter",
    "momentum",
    Datatype.doublePrecision,
    minValue: "0",
    maxValue: "inf",
    defaultValue: "0.6",
    description: "Back-propagation momentum parameter.",
  ),
  Field(
    "Back-propagation flat spot elimination parameter",
    "flat",
    Datatype.doublePrecision,
    minValue: "0",
    maxValue: "inf",
    defaultValue: "0.1",
    description: "Back-propagation flat spot elimination parameter.",
  ),
  Field(
    "Error threshold",
    "error_thresh",
    Datatype.doublePrecision,
    minValue: "0",
    maxValue: "inf",
    description: "Error threshold to stop training.",
  ),
  Field(
    "Accuracy threshold",
    "acc_thresh",
    Datatype.doublePrecision,
    minValue: "0",
    maxValue: "1",
    description: "Accuracy threshold to stop training.",
  ),
  Field(
    "Absolute difference error threshold",
    "abs_error_thresh",
    Datatype.doublePrecision,
    minValue: "0",
    maxValue: "inf",
    defaultValue: "0",
    description:
        "Absolute difference error threshold, 0 if not using this stopping criteria.",
  ),
  Field(
    "Number of model training epochs",
    "nb_epochs",
    Datatype.integer,
    minValue: "1",
    maxValue: "inf",
    defaultValue: "1500",
    description: "Number of model training epochs.",
  ),
  Field(
    "Number of training epochs before showing error",
    "nb_epochs_error",
    Datatype.integer,
    minValue: "1",
    maxValue: "inf",
    defaultValue: "10",
    description: "Number of training epochs before showing error.",
  ),
  nbQuantLevelsFld,
  Field(
    "Normalization file",
    "normalization_file",
    Datatype.filePath,
    description:
        "Path to the file containing the mean and standard deviation of some attributes. Used to denormalize the rules if specified.",
  ),
  musFld,
  sigmasFld,
  normalizationIndicesFld,
  seedFld
];

const List<Field> dimlpPredFields = [
  rootFolderFld,
  Field(
    "Test data file",
    "test_data_file",
    Datatype.filePath,
    isRequired: true,
    description: "Path to the file containing the test portion of the dataset.",
  ),
  Field(
    "Weights file trained with dimlpTrn",
    "weights_file",
    Datatype.filePath,
    isRequired: true,
    description: "Path to the file containing the weights of the model trained with dimlpTrn.",
  ),
  Field(
    "Hidden layers' sizes file",
    "hidden_layers_file",
    Datatype.filePath,
    isRequired: true,
    description: "Path to the file containing hidden layers sizes.",
  ),
  nbAttributesFld,
  nbClassesFld,
  Field(
    "Output test prediction file",
    "test_pred_outfile",
    Datatype.filePath,
    defaultValue: "dimlpTest.out",
    description:
        "Path to the file where the test predictions will be stored.",
  ),
  consoleFileFld,
  nbQuantLevelsFld,
];

const List<Field> dimlpRulFields = [
  rootFolderFld,
  trainDataFileFld,
  Field(
    "Train true classes file",
    "train_class_file",
    Datatype.filePath,
    description:
        "Path to the file containing the train true classes of the dataset, mandatory if classes are not specified in train data file.",
  ),
  Field(
    "Weights file trained with dimlpTrn",
    "weights_file",
    Datatype.filePath,
    isRequired: true,
    description: "Path to the file containing the weights of the model trained with dimlpTrn.",
  ),
  Field(
    "Hidden layers' sizes file",
    "hidden_layers_file",
    Datatype.filePath,
    isRequired: true,
    description: "Path to the file containing hidden layers sizes.",
  ),
  nbAttributesFld,
  nbClassesFld,
  Field(
    "Test data file",
    "test_data_file",
    Datatype.filePath,
    description: "Path to the file containing the test portion of the dataset.",
  ),
  Field(
    "Test true classes file",
    "test_class_file",
    Datatype.filePath,
    description:
        "Path to the file containing the test true classes of the dataset.",
  ),
  Field(
    "Validation data file",
    "valid_data_file",
    Datatype.filePath,
    description: "Path to the file containing the validation portion of the dataset.",
  ),
  Field(
    "Validation true classes file",
    "valid_class_file",
    Datatype.filePath,
    description:
        "Path to the file containing the validation true classes of the dataset.",
  ),
  Field(
    "Global rules output file",
    "global_rules_outfile",
    Datatype.filePath,
    defaultValue: "dimlp.rls",
    description: "Path to the file where the output rule(s) will be stored.",
    ),
  Field(
    "Attributes file",
    "attributes_file",
    Datatype.filePath,
    description: "Path to the file containing the labels of attributes and classes.",
  ),
  Field(
    "Output statistics file",
    "stats_file",
    Datatype.filePath,
    description:
        "Path to the file where the train, test and validation accuracy will be stored.",
  ),
  consoleFileFld,
  nbQuantLevelsFld,
  Field(
    "Normalization file",
    "normalization_file",
    Datatype.filePath,
    description:
        "Path to the file containing the mean and standard deviation of some attributes. Used to denormalize the rules if specified.",
  ),
  musFld,
  sigmasFld,
  normalizationIndicesFld,
];

const List<Field> dimlpBTFields = [
  rootFolderFld,
  trainDataFileFld,
  Field(
    "Train true classes file",
    "train_class_file",
    Datatype.filePath,
    description: "Path to the file containing the train true classes of the dataset, mandatory if classes are not specified in train data file.",
  ),
  nbAttributesFld,
  nbClassesFld,
  Field(
    "Number of networks",
    "nb_dimlp_nets",
    Datatype.integer,
    defaultValue: "25",
    minValue: "1",
    maxValue: "inf",
    description: "Number of networks.",
  ),
  Field(
    "Output train prediction file",
    "train_pred_outfile",
    Datatype.filePath,
    defaultValue: "dimlpBTTrain.out",
    description: "Path to the file where the train predictions will be stored.",
  ),
  Field(
    "Test data file",
    "test_data_file",
    Datatype.filePath,
    description: "Path to the file containing the test portion of the dataset.",
  ),
  Field(
    "Test true classes file",
    "test_class_file",
    Datatype.filePath,
    description: "Path to the file containing the test true classes of the dataset.",
  ),
  Field(
    "Output test prediction file",
    "test_pred_outfile",
    Datatype.filePath,
    defaultValue: "dimlpBTTest.out",
    description: "Path to the file where the test predictions will be stored.",
  ),
  Field(
    "Output weights file",
    "weights_outfile",
    Datatype.filePath,
    defaultValue: "dimlpBT.wts",
    description: "Path to the file where the output trained weights of the model will be stored.",
  ),
  Field(
    "Attributes file",
    "attributes_file",
    Datatype.filePath,
    description: "Path to the file containing the labels of attributes and classes.",
  ),
  Field(
    "Output statistics file",
    "stats_file",
    Datatype.filePath,
    defaultValue: "statsDimlpBT.txt",
    description:
        "Path to the file where the train, test and validation accuracy, as well as the train and test global accuracy will be stored.",
  ),
  consoleFileFld,
  Field(
    "Number of neurons in the first hidden layer",
    "first_hidden_layer",
    Datatype.integer,
    minValue: "1",
    maxValue: "inf",
    description: "Number of neurons in the first hidden layer. It has to be a multiple of the number of attributes. The default value is the number of attributes.",
  ),
  Field(
    "Number of neurons in each hidden layer",
    "hidden_layers",
    Datatype.listInteger,
    minValue: "1",
    maxValue: "inf",
    description:
        "Number of neurons in each hidden layer, from the second layer to the last.",
  ),
  Field(
    "Output hidden layers file",
    "hidden_layers_outfile",
    Datatype.filePath,
    defaultValue: "hidden_layers.out",
    description: "Path to the file where output hidden layers sizes will be stored.",
  ),
  Field(
    "Whether to extract rules with dimlpBT algorithm",
    "with_rule_extraction",
    Datatype.boolean,
    defaultValue: "false",
    description: "Whether to extract rules with dimlpBT algorithm.",
  ),
  Field(
    "Global rules output file",
    "global_rules_outfile",
    Datatype.filePath,
    description: "Path to the file where the output rule(s) will be stored.",
    ),
  Field(
    "Back-propagation momentum parameter",
    "momentum",
    Datatype.doublePrecision,
    minValue: "0",
    maxValue: "inf",
    defaultValue: "0.6",
    description: "Back-propagation momentum parameter.",
  ),
  Field(
    "Back-propagation flat spot elimination parameter",
    "flat",
    Datatype.doublePrecision,
    minValue: "0",
    maxValue: "inf",
    defaultValue: "0.01",
    description: "Back-propagation flat spot elimination parameter.",
  ),
  Field(
    "Error threshold",
    "error_thresh",
    Datatype.doublePrecision,
    minValue: "0",
    maxValue: "inf",
    description: "Error threshold to stop training.",
  ),
  Field(
    "Accuracy threshold",
    "acc_thresh",
    Datatype.doublePrecision,
    minValue: "0",
    maxValue: "1",
    description: "Accuracy threshold to stop training.",
  ),
  Field(
    "Absolute difference error threshold",
    "abs_error_thresh",
    Datatype.doublePrecision,
    minValue: "0",
    maxValue: "inf",
    defaultValue: "0",
    description:
        "Absolute difference error threshold, 0 if not using this stopping criteria.",
  ),
  Field(
    "Number of model training epochs",
    "nb_epochs",
    Datatype.integer,
    minValue: "1",
    maxValue: "inf",
    defaultValue: "1500",
    description: "Number of model training epochs.",
  ),
  Field(
    "Number of training epochs before showing error",
    "nb_epochs_error",
    Datatype.integer,
    minValue: "1",
    maxValue: "inf",
    defaultValue: "10",
    description: "Number of training epochs before showing error.",
  ),
  Field(
    "Number of examples for one single network",
    "nb_ex_per_net",
    Datatype.integer,
    defaultValue: "0",
    minValue: "1",
    maxValue: "inf",
    description:
        "Number of examples for one single network, 0 for all examples, it is not recommended to change this value.",
  ),
  nbQuantLevelsFld,
  Field(
    "Normalization file",
    "normalization_file",
    Datatype.filePath,
    description:
        "Path to the file containing the mean and standard deviation of some attributes. Used to denormalize the rules if specified.",
  ),
  musFld,
  sigmasFld,
  normalizationIndicesFld,
  seedFld,
];

const List<Field> densClsFields = [
  rootFolderFld,
  trainDataFileFld,
  Field(
    "Train true classes file",
    "train_class_file",
    Datatype.filePath,
    description: "Path to the file containing the train true classes of the dataset, mandatory if classes are not specified in train data file.",
  ),
  Field(
    "Weights file trained with dimlpBT",
    "weights_file",
    Datatype.filePath,
    isRequired: true,
    description: "Path to the file containing the weights of the model trained with dimlpBT.",
  ),
  Field(
    "Hidden layers' sizes file",
    "hidden_layers_file",
    Datatype.filePath,
    isRequired: true,
    description: "Path to the file containing hidden layers sizes.",
  ),
  nbAttributesFld,
  nbClassesFld,
  Field(
    "Output train prediction file",
    "train_pred_outfile",
    Datatype.filePath,
    defaultValue: "densClsTrain.out",
    description: "Path to the file where the train predictions will be stored.",
  ),
  Field(
    "Test data file",
    "test_data_file",
    Datatype.filePath,
    description: "Path to the file containing the test portion of the dataset.",
  ),
  Field(
    "Test true classes file",
    "test_class_file",
    Datatype.filePath,
    description:
        "Path to the file containing the test true classes of the dataset.",
  ),
  Field(
    "Output test prediction file",
    "test_pred_outfile",
    Datatype.filePath,
    defaultValue: "densClsTest.out",
    description: "Path to the file where the test predictions will be stored.",
  ),
  Field(
    "Attributes file",
    "attributes_file",
    Datatype.filePath,
    description: "Path to the file containing the labels of attributes and classes.",
  ),
  Field(
    "Output statistics file",
    "stats_file",
    Datatype.filePath,
    description: "Path to the file where the global train and test accuracy will be stored.",
  ),
  consoleFileFld,
  Field(
    "Whether to extract rules with dimlpBT algorithm",
    "with_rule_extraction",
    Datatype.boolean,
    defaultValue: "false",
    description: "Whether to extract rules with dimlpBT algorithm.",
  ),
  Field(
    "Global rules output file",
    "global_rules_outfile",
    Datatype.filePath,
    description: "Path to the file where the output rule(s) will be stored.",
  ),
  nbQuantLevelsFld,
  Field(
    "Normalization file",
    "normalization_file",
    Datatype.filePath,
    description:
        "Path to the file containing the mean and standard deviation of some attributes. Used to denormalize the rules if specified.",
  ),
  musFld,
  sigmasFld,
  normalizationIndicesFld,
];

const List<Field> dimlpClsFields = [
  rootFolderFld,
  Field(
    "Test data file",
    "test_data_file",
    Datatype.filePath,
    isRequired: true,
    description: "Path to the file containing the test portion of the dataset.",
  ),
  Field(
    "Test true classes file",
    "test_class_file",
    Datatype.filePath,
    description:
        "Path to the file containing the test true classes of the dataset, mandatory if classes are not specified in test data file.",
  ),
  Field(
    "Weights file trained with dimlpTrn",
    "weights_file",
    Datatype.filePath,
    isRequired: true,
    description: "Path to the file containing the weights of the model trained with dimlpTrn.",
  ),
  Field(
    "Hidden layers' sizes file",
    "hidden_layers_file",
    Datatype.filePath,
    isRequired: true,
    description: "Path to the file containing hidden layers sizes.",
  ),
  nbAttributesFld,
  nbClassesFld,
  Field(
    "Output test prediction file",
    "test_pred_outfile",
    Datatype.filePath,
    defaultValue: "dimlpTest.out",
    description:
        "Path to the file where the test predictions will be stored.",
  ),
  Field(
    "First hidden layer values file",
    "hid_file",
    Datatype.filePath,
    defaultValue: "dimlpTest.hid",
    description: "Path to the file where the first hidden layer values will be stored.",
  ),
  Field(
    "Output statistics file",
    "stats_file",
    Datatype.filePath,
    description: "Path to the file where the test accuracy will be stored.",
  ),
  consoleFileFld,
  nbQuantLevelsFld,
];

const List<Field> computeRocCurveFields = [
  rootFolderFld,
  Field(
    "Test true classes file",
    "test_class_file",
    Datatype.filePath,
    description: "Path to the file containing the test true classes of the dataset.",
    isRequired: true,
  ),
  Field(
    "Test prediction file",
    "test_pred_file",
    Datatype.filePath,
    description: "Path to the file containing predictions on the test portion of the dataset.",
    isRequired: true,
  ),
  Field(
    "Index of positive class",
    "positive_class_index",
    Datatype.integer,
    minValue: "1",
    maxValue: "nb_classes-1",
    description: "Index of the positive class, index starts at 0.",
    isRequired: true,
  ),
  nbClassesFld,
  Field(
    "Output ROC curve file",
    "output_roc",
    Datatype.filePath,
    defaultValue: "roc_curve.png",
    description: "Path to the file where the output ROC curve will be saved.",
  ),
  Field(
    "Output statistics file",
    "stats_file",
    Datatype.filePath,
    description: "Path to the file where the AUC score will be added, it can be the training stats file.",
  ),
  Field(
    "Name of the estimator",
    "estimator",
    Datatype.string,
    description: "Name of the estimator.",
  ),
  Field(
    "Show parameters",
    "show_params",
    Datatype.boolean,
    defaultValue: "true",
    description: "Whether to show the parameters.",
  ),
];

const List<Field> cnnTrnFields = [
  rootFolderFld,
  trainDataFileFld,
  Field(
    "Train true classes file",
    "train_class_file",
    Datatype.filePath,
    description:
        "Path to the file containing the train true classes of the dataset, mandatory if classes are not specified in train_data_file.",
  ),
  Field(
    "Test data file",
    "test_data_file",
    Datatype.filePath,
    description: "Path to the file containing the test portion of the dataset.",
    isRequired: true,
  ),
  Field(
    "Test true classes file",
    "test_class_file",
    Datatype.filePath,
    description:
        "Path to the file containing the test true classes of the dataset, mandatory if classes are not specified in test_data_file.",
  ),
  Field(
    "Original input size",
    "original_input_size",
    Datatype.pairInteger,
    minValue: "1",
    maxValue: "inf",
    isRequired: true,
    description: "Original input size.",
  ),
  Field(
    "Number of channels in the input",
    "nb_channels",
    Datatype.integer,
    minValue: "1",
    maxValue: "inf",
    isRequired: true,
    description: "Number of channels in the input (3 for RGB image, 1 for B&W image).",
  ),
  Field(
    "Model",
    "model",
    Datatype.restrictedChoiceString,
    items: ["small", "large", "vgg", "resnet"],
    isRequired: true,
    description: "Training model.",
  ),
  Field(
    "Data format",
    "data_format",
    Datatype.restrictedChoiceString,
    items: ["normalized_01", "classic", "other"],
    isRequired: true,
    description: "Format of the values of the data, normalized_01 if the data are normalized between 0 and 1, classic if they are between 0 and 255.",
  ),
  nbClassesFld,
  Field(
    "Output train and validation prediction file",
    "train_valid_pred_outfile",
    Datatype.filePath,
    defaultValue: "predTrain.out",
    description:
        "Path to the file where the output train and validation (in this order) prediction will be stored.",
  ),
  Field(
    "Output test prediction file",
    "test_pred_outfile",
    Datatype.filePath,
    defaultValue: "predTest.out",
    description: "Path to the file where the test predictions will be stored.",
  ),
  Field(
    "Percentage of train data taken for validation",
    "valid_ratio",
    Datatype.doublePrecision,
    minValue: "0",
    maxValue: "1",
    defaultValue: "0.1",
    description: "Percentage of train data taken for validation.",
  ),
  Field(
    "Validation data file",
    "valid_data_file",
    Datatype.filePath,
    description: "Path to the file containing the validation portion of the dataset.",
  ),
  Field(
    "Validation true classes file",
    "valid_class_file",
    Datatype.filePath,
    description:
        "Path to the file containing the validation true classes of the dataset, mandatory if classes are not specified in valid_data_file. BE CAREFUL if there is validation files, and you want to use Fidex algorithms later, you will have to use both train and validation datas given here in the train datas and classes of Fidex.",
  ),
  Field(
    "Output weights file",
    "weights_outfile",
    Datatype.filePath,
    defaultValue: "weights.wts",
    description: "Path to the file where the output trained weights of the model will be stored.",
  ),
  Field(
    "Output statistics file",
    "stats_file",
    Datatype.filePath,
    defaultValue: "stats.txt",
    description: "Path to the file where the train and test accuracy will be stored.",
  ),
  consoleFileFld,
  Field(
    "Number of model training epochs",
    "nb_epochs",
    Datatype.integer,
    minValue: "1",
    maxValue: "inf",
    defaultValue: "80",
    description: "Number of model training epochs.",
  ),
  Field(
    "Input size in the model",
    "model_input_size",
    Datatype.pairInteger,
    minValue: "1",
    maxValue: "inf",
    description: "Input size in the model. A small size is recommended to speed up the process. The size is modified if necessary.",
  ),
  nbQuantLevelsFld,
  Field(
    "Parameter to improve dynamics by normalizing input data",
    "K",
    Datatype.doublePrecision,
    minValue: "0",
    maxValue: "inf",
    defaultValue: "1.0",
    description: "Parameter to improve dynamics by normalizing input data.",
  ),
  seedFld,
];

const List<Field> gradBoostTrnFields = [
  rootFolderFld,
  trainDataFileFld,
  Field(
    "Train true classes file",
    "train_class_file",
    Datatype.filePath,
    description:
        "Path to the file containing the train true classes of the dataset, mandatory if classes are not specified in train_data_file.",
  ),
  Field(
    "Test data file",
    "test_data_file",
    Datatype.filePath,
    description: "Path to the file containing the test portion of the dataset.",
    isRequired: true,
  ),
  Field(
    "Test true classes file",
    "test_class_file",
    Datatype.filePath,
    description:
        "Path to the file containing the test true classes of the dataset, mandatory if classes are not specified in test_data_file.",
  ),
  nbAttributesFld,
  nbClassesFld,
  Field(
    "Output train prediction file",
    "train_pred_outfile",
    Datatype.filePath,
    defaultValue: "predTrain.out",
    description: "Path to the file where the train predictions will be stored.",
  ),
  Field(
    "Output test prediction file",
    "test_pred_outfile",
    Datatype.filePath,
    defaultValue: "predTest.out",
    description: "Path to the file where the test predictions will be stored.",
  ),
  Field(
    "Output statistics file",
    "stats_file",
    Datatype.filePath,
    defaultValue: "stats.txt",
    description: "Path to the file where the train and test accuracy will be stored.",
  ),
  consoleFileFld,
  Field(
  "Rules output file",
  "rules_outfile",
  Datatype.filePath,
  description: "Path to the file where the gradient boosting output rules will be stored.",
  ),
  Field(
    "Number of generated trees",
    "n_estimators",
    Datatype.integer,
    minValue: "1",
    defaultValue: "100",
    description: "Number of generated trees in the forest.",
  ),
  Field(
    "Loss function",
    "loss",
    Datatype.restrictedChoiceString,
    defaultValue: "log_loss",
    items: ["log_loss", "exponential"],
    description: "Loss function to be optimized.",
  ),
  Field(
    "Learning rate",
    "learning_rate",
    Datatype.doublePrecision,
    minValue: "0",
    maxValue: "inf",
    defaultValue: "0.1",
    description: "Shrinks the contribution of each tree.",
  ),
  Field(
    "Fraction of samples to be used",
    "subsample",
    Datatype.doublePrecision,
    minValue: "0.0",
    maxValue: "1.0",
    defaultValue: "1.0",
    description:
        "Fraction of samples to be used for fitting the individual base learners.",
  ),
  Field(
    "Function to measure split quality",
    "criterion",
    Datatype.restrictedChoiceString,
    defaultValue: "friedman_mse",
    items: ["friedman_mse", "squared_error"],
    description: "Function to measure split quality.",
  ),
  Field(
    "Maximum depth",
    "max_depth",
    Datatype.integer, // TODO add category too ("no_max_depth")
    minValue: "2",
    maxValue: "inf",
    defaultValue: "3",
    description: "Maximum depth of the individual regression estimators.",
  ),
  Field(
    "Minimum number of samples to split a node",
    "min_samples_split",
    Datatype.integer, // TODO float & integer
    minValue: "2",
    maxValue: "inf",
    defaultValue: "2",
    description:
        "Minimum number of samples required to split an internal node, if float, it is a fraction of the number of samples.",
  ),
  Field(
    "Minimum number of samples at leaf node",
    "min_samples_leaf",
    Datatype.integer,// TODO float & integer
    defaultValue: "1",
    minValue: "1",
    maxValue: "inf",
    description:
        "Minimum number of samples required to be at a leaf node, if float, it is a fraction of the number of samples.",
  ),
  Field(
    "Minimum weighted fraction",
    "min_weight_fraction_leaf",
    Datatype.doublePrecision,
    minValue: "0",
    maxValue: "0.5",
    defaultValue: "0.0",
    description:
        "Minimum weighted fraction of the sum total of input samples weights required to be at a leaf node.",
  ),
  Field(
    "Maximum number of features",
    "max_features",
    Datatype.restrictedChoiceString,
    defaultValue: "sqrt",
    items: ["sqrt", "log2", "all"], // TODO add float option
    description:
        "Number of features to consider when looking for the best split if float, it is a fraction of the number of features. 1 stands for 1 feature, for all features put 'all', not 1.0.",
  ),
  Field(
    "Maximum leaf nodes",
    "max_leaf_nodes",
    Datatype.integer,
    minValue: "2",
    maxValue: "inf",
    description: "Grow trees with max_leaf_nodes in best-first fashion.",
  ),
  Field(
    "Minimum impurity decrease",
    "min_impurity_decrease",
    Datatype.doublePrecision,
    minValue: "0.0",
    maxValue: "inf",
    defaultValue: "0.0",
    description:
        "A node will be split if this split induces a decrease of the impurity greater than or equal to this value.",
  ),
  Field(
    "Estimator used to compute the initial predictions",
    "init",
    Datatype.restrictedChoiceString,
    items: ["zero"],
    description: "Estimator object used to compute the initial predictions.",
  ),
  Field(
    "Seed for random number generation",
    "seed",
    Datatype.integer,
    minValue: "0",
    maxValue: "inf",
    description: "Seed for random number generation.",
  ),
  Field(
    "Verbosity level",
    "verbose",
    Datatype.integer,
    minValue: "0",
    maxValue: "inf",
    defaultValue: "0",
    description: "Controls the verbosity when fitting and predicting.",
  ),
  Field(
    "Reuse the solution of the previous call",
    "warm_start",
    Datatype.boolean,
    defaultValue: "false",
    description:
        "Whether to reuse the solution of the previous call to fit and add more estimators to the ensemble.",
  ),
  Field(
    "Proportion of training data",
    "validation_fraction",
    Datatype.doublePrecision,
    minValue: "0.0",
    maxValue: "1.0",
    defaultValue: "0.1",
    description:
        "Proportion of training data to set aside as validation set for early stopping.",
  ),
  Field(
    "Number of iterations with no improvements",
    "n_iter_no_change",
    Datatype.integer,
    minValue: "1",
    maxValue: "inf",
    description:
        "Decide if early stopping will be used to terminate training when validation score is not improving, stopping if validation doesn't improve during this number of iterations.",
  ),
  Field(
    "Tolerance for the early stopping",
    "tol",
    Datatype.doublePrecision,
    minValue: "0",
    maxValue: "inf",
    defaultValue: "0.0001",
    description: "Tolerance for the early stopping.",
  ),
  Field(
    "Complexity parameter",
    "ccp_alpha",
    Datatype.doublePrecision,
    minValue: "0",
    maxValue: "inf",
    defaultValue: "0.0",
    description:
        "Complexity parameter used for Minimal Cost-Complexity Pruning.",
  ),
];

const List<Field> mlpTrnFields = [
  rootFolderFld,
  trainDataFileFld,
  Field(
    "Train true classes file",
    "train_class_file",
    Datatype.filePath,
    description:
        "Path to the file containing the train true classes of the dataset, mandatory if classes are not specified in train_data_file.",
  ),
  Field(
    "Test data file",
    "test_data_file",
    Datatype.filePath,
    description: "Path to the file containing the test portion of the dataset.",
    isRequired: true,
  ),
  Field(
    "Test true classes file",
    "test_class_file",
    Datatype.filePath,
    description:
        "Path to the file containing the test true classes of the dataset, mandatory if classes are not specified in test_data_file.",
  ),
  nbAttributesFld,
  nbClassesFld,
  Field(
    "Output train prediction file",
    "train_pred_outfile",
    Datatype.filePath,
    defaultValue: "predTrain.out",
    description: "Path to the file where the train predictions will be stored.",
  ),
  Field(
    "Output test prediction file",
    "test_pred_outfile",
    Datatype.filePath,
    defaultValue: "predTest.out",
    description: "Path to the file where the test predictions will be stored.",
  ),
  Field(
    "Output statistics file",
    "stats_file",
    Datatype.filePath,
    defaultValue: "stats.txt",
    description: "Path to the file where the train and test accuracy will be stored.",
  ),
  consoleFileFld,
  Field(
    "Output weights file",
    "weights_outfile",
    Datatype.filePath,
    defaultValue: "weights.wts",
    description: "Path to the file where the output trained weights of the model will be stored.",
  ),
  nbQuantLevelsFld,
  Field(
    "Parameter to improve dynamics by normalizing input data",
    "K",
    Datatype.doublePrecision,
    minValue: "0.0",
    maxValue: "inf",
    defaultValue: "1.0",
    description: "Parameter to improve dynamics by normalizing input data.",
  ),
  Field(
    "Size of each hidden layers",
    "hidden_layer_sizes",
    Datatype.listInteger,
    minValue: "1",
    maxValue: "inf",
    defaultValue: "100",
    description: "Size of each hidden layers.",
  ),
  Field(
    "Activation function",
    "activation",
    Datatype.restrictedChoiceString,
    items: ["relu", "identity", "tanh", "logistic"],
    defaultValue: "relu",
    description: "Activation function.",
  ),
  Field(
    "Solver for weight optimization",
    "solver",
    Datatype.restrictedChoiceString,
    defaultValue: "adam",
    items: ["adam", "lbfgs", "sgd"],
    description: "Solver for weight optimization.",
  ),
  Field(
    "Strength of the L2 regularization term",
    "alpha",
    Datatype.doublePrecision,
    minValue: "0.0",
    maxValue: "inf",
    defaultValue: "0.0001",
    description: "Strength of the L2 regularization term.",
  ),
  Field(
    "Size of minibatches",
    "batch_size",
    Datatype.integer, //TODO auto or int, default : auto
    minValue: "0",
    maxValue: "inf",
    description:
        "Size of minibatches for stochastic optimizers for adam and stochastic gradient descent.",
  ),
  Field(
    "Learning rate schedule",
    "learning_rate",
    Datatype.restrictedChoiceString,
    defaultValue: "constant",
    items: ["constant", "invscalling", "adaptative"],
    description: "Learning rate schedule for weight updates for stochastic gradient descent solver.",
  ),
  Field(
    "Initial learning rate for adam and stochastic gradient descent",
    "learning_rate_init",
    Datatype.doublePrecision,
    minValue: "0.0",
    maxValue: "inf",
    defaultValue: "0.001",
    description: "Initial learning rate for adam and stochastic gradient descent.",
  ),
  Field(
    "Exponent for inverse scaling learning rate",
    "power_t",
    Datatype.doublePrecision,
    minValue: "0.0",
    maxValue: "inf",
    defaultValue: "0.5",
    description: "Exponent for inverse scaling learning rate for stochastic gradient descent.",
  ),
  Field(
    "Maximum number of training iterations",
    "max_iterations",
    Datatype.integer,
    minValue: "1",
    maxValue: "inf",
    defaultValue: "200",
    description: "Maximum number of training iterations.",
  ),
  Field(
    "Shuffle samples",
    "shuffle",
    Datatype.boolean,
    defaultValue: "true",
    description:
        "Whether to shuffle samples in each iteration for stochastic gradient descent and adam.",
  ),
    Field(
    "Seed for random number generation",
    "seed",
    Datatype.integer,
    minValue: "0",
    maxValue: "inf",
    description: "Seed for random number generation for stochastic gradient descent and adam.",
  ),
  Field(
    "Tolerance for optimization",
    "tol",
    Datatype.doublePrecision,
    minValue: "0.0",
    maxValue: "inf",
    defaultValue: "0.0001",
    description: "Tolerance for optimization.",
  ),
  Field(
    "Enable verbose output",
    "verbose",
    Datatype.boolean,
    defaultValue: "false",
    description: "Enable verbose output.",
  ),
  Field(
    "Reuse the previous solution to fit initialization",
    "warm_start",
    Datatype.boolean,
    defaultValue: "false",
    description: "Whether to reuse the previous solution to fit initialization.",
  ),
  Field(
    "Momentum for gradient descent",
    "momentum",
    Datatype.doublePrecision,
    minValue: "0.0",
    maxValue: "1.0",
    defaultValue: "0.9",
    description: "Momentum for gradient descent update for stochastic gradient descent.",
  ),
  Field(
    "Use the Nesterov’s momentum",
    "nesterovs_momentum",
    Datatype.boolean,
    defaultValue: "true",
    description: "Whether to use the Nesterov’s momentum for stochastic gradient descent and momentum.",
  ),
  Field(
    "Use early stopping",
    "early_stopping",
    Datatype.boolean,
    defaultValue: "false",
    description:
        "Whether to use early stopping to terminate training when validation score is not improving for stochastic gradient descent and adam.",
  ),
  Field(
    "Proportion of training data to set aside as validation set",
    "validation_fraction",
    Datatype.doublePrecision,
    minValue: "0.0",
    maxValue: "1.0",
    defaultValue: "0.1",
    description:
        "Proportion of training data to set aside as validation set for early stopping.",
  ),
  Field(
    "First exponential decay rate",
    "beta_1",
    Datatype.doublePrecision,
    minValue: "0.0",
    maxValue: "1.0",
    defaultValue: "0.9",
    description:
        "Exponential decay rate for estimates of first moment vector in adam.",
  ),
  Field(
    "Second exponential decay rate",
    "beta_2",
    Datatype.doublePrecision,
    minValue: "0.0",
    maxValue: "1.0",
    defaultValue: "0.999",
    description:
        "Exponential decay rate for estimates of second moment vector in adam.",
  ),
  Field(
    "Value for numerical stability",
    "epsilon",
    Datatype.doublePrecision,
    minValue: "0.0",
    maxValue: "inf",
    defaultValue: "1e-08",
    description: "Value for numerical stability in adam.",
  ),
  Field(
    "Maximum number of epochs",
    "n_iter_no_change",
    Datatype.integer,
    minValue: "1",
    maxValue: "inf",
    defaultValue: "10",
    description:
        "Maximum number of epochs to not meet tol improvement for stochastic gradient descent and adam.",
  ),
  Field(
    "Maximum number of loss function calls for lbfgs",
    "max_fun",
    Datatype.integer,
    minValue: "1",
    maxValue: "inf",
    defaultValue: "15000",
    description: "Maximum number of loss function calls for lbfgs.",
  ),
];

const List<Field> randForestsTrnFields = [
  rootFolderFld,
  trainDataFileFld,
  Field(
    "Train true classes file",
    "train_class_file",
    Datatype.filePath,
    description:
        "Path to the file containing the train true classes of the dataset, mandatory if classes are not specified in train_data_file.",
  ),
  Field(
    "Test data file",
    "test_data_file",
    Datatype.filePath,
    description: "Path to the file containing the test portion of the dataset.",
    isRequired: true,
  ),
  Field(
    "Test true classes file",
    "test_class_file",
    Datatype.filePath,
    description:
        "Path to the file containing the test true classes of the dataset, mandatory if classes are not specified in test_data_file.",
  ),
  nbAttributesFld,
  nbClassesFld,
  Field(
    "Output train prediction file",
    "train_pred_outfile",
    Datatype.filePath,
    defaultValue: "predTrain.out",
    description: "Path to the file where the train predictions will be stored.",
  ),
  Field(
    "Output test prediction file",
    "test_pred_outfile",
    Datatype.filePath,
    defaultValue: "predTest.out",
    description: "Path to the file where the test predictions will be stored.",
  ),
  Field(
    "Output statistics file",
    "stats_file",
    Datatype.filePath,
    defaultValue: "stats.txt",
    description: "Path to the file where the train and test accuracy will be stored.",
  ),
  consoleFileFld,
  Field(
    "Rules output file",
    "rules_outfile",
    Datatype.filePath,
    description: "Path to the file where the random forests output rules will be stored.",
    ),
  Field(
    "Number of generated trees in the forest",
    "n_estimators",
    Datatype.integer,
    defaultValue: "100",
    minValue: "1",
    maxValue: "inf",
    description: "Number of generated trees in the forest.",
  ),
  Field(
    "Function to measure split quality",
    "criterion",
    Datatype.restrictedChoiceString,
    items: ["gini", "entropy", "log_loss"],
    defaultValue: "gini",
    description: "Function to measure split quality.",
  ),
  Field(
    "Maximum depth of the tree",
    "max_depth",
    Datatype.integer,
    minValue: "1",
    maxValue: "inf",
    description: "Maximum depth of the tree.",
  ),
  Field(
    "Minimum number of samples to split an internal node",
    "min_samples_split",
    Datatype.doublePrecision,   //TODO Handle differenciation between float and int
    defaultValue: "2",
    minValue: "2",
    maxValue: "inf",
    description:
        "Minimum number of samples required to split an internal node, if float, it is a fraction of the number of samples.",
  ),
  Field(
    "Minimum number of samples to be at a leaf",   //TODO Handle differenciation between float and int
    "min_samples_leaf",
    Datatype.doublePrecision,
    defaultValue: "1",
    minValue: "1",
    maxValue: "inf",
    description:
        "Minimum number of samples required to be at a leaf node, if float, it is a fraction of the number of samples.",
  ),
  Field(
    "Minimum weighted fraction",
    "min_weight_fraction_leaf",
    Datatype.doublePrecision,
    defaultValue: "0.0",
    minValue: "0.0",
    maxValue: "0.5",
    description:
        "Minimum weighted fraction of the sum total of input samples weights required to be at a leaf node.",
  ),
  Field(
    "Number of features to consider when looking for the best split",   // TODO: handle this input to fit float & int options and remove comment in description
    "max_features",
    Datatype.restrictedChoiceString,
    defaultValue: "sqrt",
    items: ["sqrt", "log2", "all"],
    description:
        "(ONLY CATEGORIES ARE AVAILABLE YET, NO FLOAT OR INT OPTIONS. DO IT MANUALLY IF NECESSARY)\nNumber of features to consider when looking for the best split. If float, it is a fraction of the number of features. 1 stands for 1 feature, for all features put 'all', not 1.0.",
  ),
  Field(
    "Maximum number of leaf nodes",
    "max_leaf_nodes",
    minValue: "2",
    maxValue: "inf",
    Datatype.integer,
    description: "Grow trees with max_leaf_nodes in best-first fashion.",
  ),
  Field(
    "Minimal impurity decrease",
    "min_impurity_decrease",
    Datatype.doublePrecision,
    defaultValue: "0.0",
    minValue: "0.0",
    maxValue: "inf",
    description:
        "A node will be split if this split induces a decrease of the impurity greater than or equal to this value.",
  ),
  Field(
    "Use bootstrap samples",
    "bootstrap",
    Datatype.boolean,
    defaultValue: "true",
    description: "Whether bootstrap samples are used when building trees.",
  ),
  Field(
    "Whether to use out-of-bag samples",
    "oob_score",
    Datatype.boolean,
    defaultValue: "false",
    description:
        "Whether to use out-of-bag samples to estimate the generalization score.",
  ),
  Field(
    "Number of parallel jobs",
    "n_jobs",
    Datatype.integer,
    defaultValue: "1",
    minValue: "-1",
    maxValue: "# CPUs available",
    description: "Number of jobs to run in parallel, -1 = using all processors.",
  ),
  Field(
    "Seed for random number generation",
    "seed",
    Datatype.integer,
    minValue: "0",
    maxValue: "inf",
    description: "Seed for random number generation.",
  ),
  Field(
    "Verbose level",
    "verbose",
    Datatype.integer,
    defaultValue: "0",
    minValue: "0",
    maxValue: "inf",
    description: "Controls the verbosity when fitting and predicting.",
  ),
  Field(
    "Reuse the solution of the previous call",
    "warm_start",
    Datatype.boolean,
    defaultValue: "false",
    description:
        "Whether to reuse the solution of the previous call to fit and add more estimators to the ensemble.",
  ),
  Field(
    "Class balance",
    "class_weight",
    Datatype.string, // TODO : Add categories...
    description:
        "Class balance, for example with a dictionary and 2 classes: {0:1.2, 1:3.5}.",
  ),
  Field(
    "Complexity parameter",
    "ccp_alpha",
    Datatype.doublePrecision,
    defaultValue: "0.0",
    minValue: "0.0",
    maxValue: "inf",
    description:
        "Complexity parameter used for Minimal Cost-Complexity Pruning.",
  ),
  Field(
    "Maximum number of samples",
    "max_samples",
    Datatype.doublePrecision, // TODO : float or int ...
    minValue: "0",
    maxValue: "inf",
    description:
        "Number of samples to draw to train each base estimator for bootstrap, if float, it is a fraction of the number of samples.",
  ),
];

const List<Field> svmTrnFields = [
  rootFolderFld,
  trainDataFileFld,
  Field(
    "Train true classes file",
    "train_class_file",
    Datatype.filePath,
    description:
        "Path to the file containing the train true classes of the dataset, mandatory if classes are not specified in train_data_file.",
  ),
  Field(
    "Test data file",
    "test_data_file",
    Datatype.filePath,
    description: "Path to the file containing the test portion of the dataset.",
    isRequired: true,
  ),
  Field(
    "Test true classes file",
    "test_class_file",
    Datatype.filePath,
    description:
        "Path to the file containing the test true classes of the dataset, mandatory if classes are not specified in test_data_file.",
  ),
  nbAttributesFld,
  nbClassesFld,
  Field(
    "Output train prediction file",
    "train_pred_outfile",
    Datatype.filePath,
    defaultValue: "predTrain.out",
    description: "Path to the file where the train predictions will be stored.",
  ),
  Field(
    "Output test prediction file",
    "test_pred_outfile",
    Datatype.filePath,
    defaultValue: "predTest.out",
    description: "Path to the file where the test predictions will be stored.",
  ),
  Field(
    "Output statistics file",
    "stats_file",
    Datatype.filePath,
    defaultValue: "stats.txt",
    description: "Path to the file where the train and test accuracy will be stored.",
  ),
  consoleFileFld,
  Field(
    "Output weights file",
    "weights_outfile",
    Datatype.filePath,
    defaultValue: "weights.wts",
    description: "Path to the file where the output trained weights of the model will be stored.",
  ),
  Field(
    "Output ROC curve file",
    "output_roc",
    Datatype.filePath,
    defaultValue: "roc_curve.png",
    description: "Path to the file where the output ROC curve will be saved.",
  ),
  Field(
    "Whether to return ROC statistics",
    "return_roc",
    Datatype.boolean,
    defaultValue: "false",
    description: "Whether to return ROC statistics.",
  ),
  Field(
    "Index of positive class",
    "positive_class_index",
    minValue: "0",
    maxValue: "# classes -1",
    Datatype.integer,
    description:
        "Index of the positive class for the roc curve calculation, index starts at 0.",
  ),
  nbQuantLevelsFld,
  Field(
    "Parameter to improve dynamics by normalizing input data",
    "K",
    Datatype.doublePrecision,
    minValue: "0",
    maxValue: "inf",
    defaultValue: "1.0",
    description: "Parameter to improve dynamics by normalizing input data.",
  ),
  Field(
    "Regularization parameter",
    "C",
    Datatype.doublePrecision,
    minValue: "0.0",
    maxValue: "inf",
    defaultValue: "1.0",
    description: "Regularization parameter.",
  ),
  Field(
    "Kernel type",
    "kernel",
    Datatype.restrictedChoiceString,
    defaultValue: "rbf",
    items: ["linear", "poly", "rbf", "sigmoid"],
    description: "Kernel type.",
  ),
  Field(
    "Polynomial degree",
    "degree",
    Datatype.integer,
    minValue: "0",
    maxValue: "inf",
    defaultValue: "3",
    description: "Polynomial degree.",
  ),
  Field(
    "Gamma predefined value (do not use with the custom field below)",
    "gamma_1",
    Datatype.restrictedChoiceString,
    defaultValue: "scale",
    items: ["", "scale", "auto"],
    description: "Gamma predefined value.",
  ),
  Field(
    "Gamma custom value (do not use with the predefined field above)",
    "gamma_2",
    Datatype.doublePrecision,
    minValue: "0.0",
    maxValue: "inf",
    description: "Gamma custom floating point value.",
  ),
  Field(
    "Term in kernel function",
    "coef0",
    Datatype.doublePrecision,
    defaultValue: "0.0",
    description: "Term in the kernel function.",
  ),
  Field(
    "Use the shrinking heuristic",
    "shrinking",
    Datatype.boolean,
    defaultValue: "true",
    description: "Whether to use the shrinking heuristic.",
  ),
  Field(
    "Tolerance for stopping criterion",
    "tol",
    Datatype.doublePrecision,
    minValue: "0.0",
    maxValue: "inf",
    defaultValue: "0.001",
    description: "Tolerance for stopping criterion.",
  ),
  Field(
    "Kernel cache size(MB)",
    "cache_size",
    Datatype.doublePrecision,
    minValue: "0.0",
    maxValue: "inf",
    defaultValue: "200",
    description: "Kernel cache size(MB).",
  ),
  Field(
    "Class balance",
    "class_weight",
    Datatype.dictionary, // TODO : add balanced, so dict or category
    description:
        "Class balance, for example with a dictionary and 2 classes: {0:1.2, 1:3.5}.",
  ),
  Field(
    "Enable verbose output",
    "verbose",
    Datatype.boolean,
    defaultValue: "false",
    description: "Whether to enable verbose output.",
  ),
  Field(
    "Maximum number of training iterations",
    "max_iterations",
    Datatype.integer,
    minValue: "-1",
    maxValue: "inf",
    defaultValue: "-1",
    description: "Maximal number of training iterations, -1 designates no limit.",
  ),
  Field(
    "Decision function shape",
    "decision_function_shape",
    Datatype.restrictedChoiceString,
    defaultValue: "ovr",
    items: ["ovr", "ovo"],
    description: "Decision function shape.",
  ),
  Field(
    "Whether to break tie decision",
    "break_ties",
    Datatype.boolean,
    defaultValue: "false",
    description:
        "Whether to break tie decision for ovr with more than 2 classes.",
  ),
];

const List<Field> normalizationFields = [
  rootFolderFld,
  nbAttributesFld,
  Field(
    "Number of classes",
    "nb_classes",
    Datatype.integer,
    minValue: "2",
    maxValue: "inf",
    description: "Number of classes in the dataset.",
  ),
  Field(
    "Data files to normalize",
    "data_files",
    Datatype.listFilePath,
    description:
        "List of paths to data files to normalize, they are normalized with respect to the first one if normalization_file is not specified. Either 'data_files' or 'rule_files' must be specified.",
  ),
  Field(
    "Rule files to denormalize",
    "rule_files",
    Datatype.listFilePath,
    description:
        "List of paths to rule files to denormalize, denormalization is possible only if a normalization_file file or mus, sigmas and normalization_indices are given. Either 'data_files' or 'rule_files' must be specified.",
  ),
  Field(
    "String representing a missing value in the data",
    "missing_values",
    Datatype.string,
    description:
        "String representing a missing value in the data, put 'NaN' (or any string not present in the data) if there is no missing value, mandatory for normalization.",
  ),
  Field(
    "Normalization file",
    "normalization_file",
    Datatype.filePath,
    description:
        "Path to the file containing the mean and standard deviation of some attributes. Used to denormalize the rules if specified.",
  ),
  Field(
    "Mus",
    "mus",
    Datatype.listDoublePrecision,
    minValue: "-inf",
    maxValue: "inf",
    description:
        "Mean or median of each attribute index of interest.",
  ),
  Field(
    "Sigmas",
    "sigmas",
    Datatype.listDoublePrecision,
    minValue: "-inf",
    maxValue: "inf",
    description:
        "Standard deviation of each attribute index of interest.",
  ),
  Field(
    "Normalization indices",
    "normalization_indices",
    Datatype.listInteger,
    minValue: "0",
    maxValue: "# attributes - 1",
    description:
        "Attribute indices to be normalized or denormalized, index starts at 0, only used when no normalization_file is given, index starts at 0 (default: [0,...,nb_attributes-1]).",
  ),
  Field(
    "Output normalization file",
    "output_normalization_file",
    Datatype.filePath,
    defaultValue: "normalization_stats.txt",
    description:
        "Path to the file where the mean and standard deviation of the normalized attributes will be stored if normalization_file is not specified.",
  ),
  Field(
    "Normalized files",
    "output_data_files",
    Datatype.listFilePath,
    description:
        "List of paths where the normalized files will be saved, it is mandatory to specify each of them if one is specified (default: <original_name>_normalized<original_extension>).",
  ),
  Field(
    "Normalized rule files",
    "output_rule_files",
    Datatype.listFilePath,
    description:
        "List of paths where the normalized rule files will be saved, it is mandatory to specify each of them if one is specified (default: <original_name>_denormalized<original_extension>).",
  ),
  Field(
    "Attributes file",
    "attributes_file",
    Datatype.filePath,
    description:
        "Path to the file containing the labels of attributes and classes. Mandatory if rules or normalization stats are written with attribute names.",
  ),
  Field(
    "Whether to use median instead of mean normalize",
    "with_median",
    Datatype.boolean,
    defaultValue: "false",
    description:
        "Whether to use median instead of mean to normalize.",
  ),
  Field(
    "Whether to fill missing values with mean or median during normalization",
    "fill_missing_values",
    Datatype.boolean,
    defaultValue: "true",
    description:
        "Whether to fill missing values with mean (or median) during normalization.",
  ),
];
