{
 "cells": [
  {
   "cell_type": "raw",
   "id": "fe0d6b76-c4d5-4df3-9f9a-4d6274907172",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Exploring CNN models and Fidex rule generation for MNIST classification\n",
    "\n",
    "**Introduction:**\n",
    "\n",
    "Welcome to HES-Xplain, our interactive platform designed to facilitate explainable artificial intelligence (XAI) techniques. In this use case, we dive into the classification with CNN models trained on MNIST.\n",
    "By the end of this notebook, you'll have a solid understanding of how to use a CNN to train the model and the Fidex algorithms to extract rules.\n",
    "\n",
    "**Objectives:**\n",
    "\n",
    "    1. Observe a different use case where XAI can be used.\n",
    "    3. Understand how to use CNNs and Fidex.\n",
    "    4. Showcase the versatility of HES-Xplain using a different dataset and training model.\n",
    "    5. Provide practical insights into applying CNNs and Fidex to MNIST classifiers through an interactive notebook.\n",
    "    6. Foster a community of XAI enthusiasts and practitioners.\n",
    "\n",
    "**Outline:**\n",
    "\n",
    "    1. Dataset and Problem Statement.\n",
    "    2. Model training.\n",
    "    3. Local rules generation - Fidex.\n",
    "    4. Global ruleSet generation - FidexGlo.\n",
    "    5. Explanation and image generation.\n",
    "    6. Conclusion.\n",
    "    7. References."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "62a8f3b4-f169-4ec4-bf69-3f325ae269ec",
   "metadata": {},
   "source": [
    "# Dataset and Problem Statement\n",
    "\n",
    "The MNIST Dataset used in this use case consists of 60'000 data samples representing images of digits between 0 and 9. Each image sample has 784 attributes (shape 28x28x1). This dataset is available on [Kaggle](https://www.kaggle.com/datasets/oddrationale/mnist-in-csv). We already preprocessed the data and saved it in the `data/MnistDataset` folder. It is composed of 50'000 training samples and 10'000 testing samples.\n",
    "\n",
    "Each attribute is a pixel value ranging from 0 to 255. It's not necessary to normalize the data as it is done during the CNN training process.\n",
    "\n",
    "**Problem Statement:** Our objective is to build a robust CNN classifier capable of accurately classifying the images among the 10 classes. By leveraging deep learning techniques and Fidex algorithms, we aim to not only achieve high classification performance but also gain insights into the attributes that contribute to the classification decisions.\n",
    "\n",
    "We'll start by importing all libraries. A warning might appear, but there's no need to worry about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c2697a5-c92e-40a6-86ce-018b897baea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeanmarc/dimlpfidex/notebooks/.venv/lib/python3.10/site-packages/numpy/core/getlimits.py:542: UserWarning: Signature b'\\x00\\xd0\\xcc\\xcc\\xcc\\xcc\\xcc\\xcc\\xfb\\xbf\\x00\\x00\\x00\\x00\\x00\\x00' for <class 'numpy.longdouble'> does not match any known type: falling back to type probe function.\n",
      "This warnings indicates broken support for the dtype!\n",
      "  machar = _get_machar(dtype)\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from dimlpfidex.fidex import fidex, fidexGloRules, fidexGloStats, fidexGlo\n",
    "from trainings.cnnTrn import cnnTrn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c01997-d95c-4c99-8ea4-3dfa31d7ba2f",
   "metadata": {},
   "source": [
    "# Model training\n",
    "\n",
    "We train the MNIST dataset with a CNN. We use the cnnTrn module to do so. First, let's look at the parameters :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2566d658-96d1-4675-b76f-7d6d70730ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: \n",
      "--train_data_file <str> --test_data_file <str> --original_input_size <pair<int [1, inf[>> --nb_channels <int [1,inf[> --model <{small, large, vgg, resnet}> --data_format <{normalized_01, classic, other}> --nb_classes <int [1,inf[> [-h, --help] [--json_config_file <str>] [--root_folder <str>] [--train_class_file <str>] [--test_class_file <str>] [--train_valid_pred_outfile <str>] [--test_pred_outfile <str>] [--valid_ratio <float ]0,inf[>] [--valid_data_file <str>] [--valid_class_file <str>] [--weights_outfile <str>] [--stats_file <str>] [--console_file <str>] [--nb_epochs <int [1,inf[>] [--nb_quant_levels <int [3,inf[>] [--K <float ]0,inf[>] [--model_input_size <pair<int [1, inf[>>] [--seed <{int [0,inf[}>]\n",
      "\n",
      "This is a parser for cnnTrn\n",
      "\n",
      "\n",
      "Parameters:\n",
      "\n",
      "  ---------------------------------------------------------------------\n",
      "\n",
      "  Warning! The files are located with respect to the root folder dimlpfidex.\n",
      "\n",
      "  The arguments can be specified in the command or in a json configuration file with --json_config_file your_config_file.json.\n",
      "\n",
      "  ----------------------------\n",
      "\n",
      "  Required parameters:\n",
      "\n",
      "  --train_data_file <str>                          Path to the file containing the train portion of the dataset\n",
      "  --test_data_file <str>                           Path to the file containing the test portion of the dataset\n",
      "  --original_input_size <pair<int [1, inf[>>       Original input size size\n",
      "  --nb_channels <int [1,inf[>                      Number of channels in the input (3 for RGB image, 1 for B&W image)\n",
      "  --model <{small, large, vgg, resnet}>            Training model\n",
      "  --data_format <{normalized_01, classic, other}>  Format of the values of the data, normalized_01 if the data are normalized between 0 and 1, classic\n",
      "                                                   if they are between 0 and 255\n",
      "  --nb_classes <int [1,inf[>                       Number of classes in the dataset\n",
      "\n",
      "  ----------------------------\n",
      "\n",
      "  Optional parameters:\n",
      "\n",
      "  -h --help                                        show this help message and exit\n",
      "  --json_config_file <str>                         Path to the JSON file that configures all parameters. If used, this must be the sole argument and\n",
      "                                                   must specify the file's relative path\n",
      "  --root_folder <str>                              Path to the folder, based on main default folder dimlpfidex, containing all used files and where\n",
      "                                                   generated files will be saved. If a file name is specified with another option, its path will be\n",
      "                                                   relative to this root folder> (default: \"\")\n",
      "  --train_class_file <str>                         Path to the file containing the train true classes of the dataset, mandatory if classes are not\n",
      "                                                   specified in train_data_file\n",
      "  --test_class_file <str>                          Path to the file containing the test true classes of the dataset, mandatory if classes are not\n",
      "                                                   specified in test_data_file\n",
      "  --train_valid_pred_outfile <str>                 Path to the file where the output train and validation (in this order) prediction will be stored\n",
      "                                                   (default: predTrain.out)\n",
      "  --test_pred_outfile <str>                        Path to the file where the test predictions will be stored (default: predTest.out)\n",
      "  --valid_ratio <float ]0,inf[>                    Percentage of train data taken for validation (default: 0.1)\n",
      "  --valid_data_file <str>                          Path to the file containing the validation portion of the dataset\n",
      "  --valid_class_file <str>                         Path to the file containing the validation true classes of the dataset, mandatory if classes are\n",
      "                                                   not specified in valid_data_file. BE CAREFUL if there is validation files, and you want to use\n",
      "                                                   Fidex algorithms later, you will have to use both train and validation datas given here in the\n",
      "                                                   train datas and classes of Fidex\n",
      "  --weights_outfile <str>                          Path to the file where the output trained weights of the model will be stored (default:\n",
      "                                                   weights.wts)\n",
      "  --stats_file <str>                               Path to the file where the train and test accuracy will be stored (default: stats.txt)\n",
      "  --console_file <str>                             Path to the file where the terminal output will be redirected. If not specified, all output will be\n",
      "                                                   shown on your terminal\n",
      "  --nb_epochs <int [1,inf[>                        Number of model training epochs (default: 80)\n",
      "  --nb_quant_levels <int [3,inf[>                  Number of stairs in the staircase activation function (default: 50)\n",
      "  --K <float ]0,inf[>                              Parameter to improve dynamics by normalizing input data (default: 1.0)\n",
      "\n",
      "  ----------------------------\n",
      "\n",
      "  CNN parameters (optional):\n",
      "\n",
      "  --model_input_size <pair<int [1, inf[>>          Input size in the model. A small size is recommended to speed up the process. The size is modified\n",
      "                                                   if necessary\n",
      "  --seed <{int [0,inf[}>                           Seed for random number generation, 0=random. Anything else than 0 is an arbitrary seed that can be\n",
      "                                                   reused to obtain the same randomly generated sequence and therefore getting same results (default:\n",
      "                                                   0)\n",
      "\n",
      "  ----------------------------\n",
      "\n",
      "Execution example :\n",
      "\n",
      "cnnTrn('--model small --train_data_file trainData.txt --train_class_file trainClass.txt --test_data_file testData.txt --test_class_file testClass.txt --valid_data_file validData.txt --valid_class_file validClass.txt --original_input_size (28,28) --nb_channels 1 --data_format classic --nb_classes 10 --root_folder dimlp/datafiles/Mnist')\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "status = cnnTrn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69eb22f",
   "metadata": {},
   "source": [
    "To configure our training, we will use this configuration file, located at `data/MnistTemplates/config_cnn.json`:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"root_folder\": \"data/MnistDataset\",\n",
    "    \"train_data_file\": \"trainData.txt\",\n",
    "    \"train_class_file\": \"trainClass.txt\",\n",
    "    \"test_data_file\": \"testData.txt\",\n",
    "    \"test_class_file\": \"testClass.txt\",\n",
    "    \"valid_ratio\": 0.1,\n",
    "    \"original_input_size\": \"[28,28]\",\n",
    "    \"data_format\": \"classic\",\n",
    "    \"nb_channels\": 1,\n",
    "    \"nb_classes\": 10,\n",
    "    \"model\": \"small\"\n",
    "}\n",
    "```\n",
    "\n",
    "> A detailed list of parameters is available [here](https://hes-xplain.github.io/documentation/algorithms/trainings/cnnTrn/). If you want to create your own configuration file, we recommend using our [configuration file creator](https://hes-xplain.github.io/documentation/gui/)\n",
    "TODO : ajouter partout dans tous les notebooks le lien vers les listes de param√®tres.\n",
    "\n",
    "\n",
    "We start by training our model. As it may take some time, the training has already been done. If you wish to train it yourself, you can uncomment and run the next instruction :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e804d87b-b2dc-4946-9e99-caf1fa3fa066",
   "metadata": {},
   "outputs": [],
   "source": [
    "#res = cnnTrn('--json_config_file data/MnistTemplates/config_cnn.json')\n",
    "#if (res == 0):\n",
    "#    print(\"cnnTrn done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c12044-2b09-4b7c-82b4-e6285ef55dfc",
   "metadata": {},
   "source": [
    "You can check all outputs inside the `data/MnistDataset` folder.\n",
    "\n",
    "Inside `stats.txt` you can see the train and test accuracy.\n",
    "\n",
    "There are also the train predictions, test predictions, and the weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0865c6d-1648-4a61-8962-e81690b8d491",
   "metadata": {},
   "source": [
    "# Local rules generation - Fidex\n",
    "\n",
    "Fidex is an algorithm used in classification problems that allows us to obtain a rule explaining the decision class of the model for a given test sample. It enables us to grasp the model's decision-making process and to better understand the importance of each parameter in discerning the nature of the tumor, distinguishing between benign and malignant cases.\n",
    "\n",
    "Now we can generate some local rules to explain the models' results. We can start with launching Fidex on one test sample. This will generate a rule explaining the sample locally. It is local because the algorithm searches a rule only for one sample.\n",
    "Fidex is located in the fidex module. Let's take a look at the parameters :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "368222c7-c0f8-4af0-a6a7-7adf290b7192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "Warning! The files are located with respect to the root folder dimlpfidex.\n",
      "The arguments can be specified in the command or in a json configuration file with --json_config_file your_config_file.json.\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Required parameters:\n",
      "\n",
      "--train_data_file <str>       Path to the file containing the train portion of the dataset\n",
      "--train_class_file <str>      Path to the file containing the train true classes of the dataset, not mandatory if classes are specified in train data file\n",
      "--train_pred_file <str>       Path to the file containing predictions on the train portion of the dataset\n",
      "--test_data_file <str>        Path to the file containing the test sample(s) data, prediction (if no --test_pred_file) and true class(if no --test_class_file)\n",
      "--weights_file <str>          Path to the file containing the trained weights of the model (not mandatory if a rules file is given with --rules_file)\n",
      "--rules_file <str>            Path to the file containing the trained rules to be converted to hyperlocus (not mandatory if a weights file is given with --weights_file)\n",
      "--rules_outfile <str>         Path to the file where the output rule(s) will be stored. If a .json extension is given, rules are saved in JSON format\n",
      "--nb_attributes <int [1,inf[> Number of attributes in the dataset\n",
      "--nb_classes <int [2,inf[>    Number of classes in the dataset\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Optional parameters: \n",
      "\n",
      "--json_config_file <str>      Path to the JSON file that configures all parameters. If used, this must be the sole argument and must specify the file's relative path\n",
      "--root_folder <str>           Path to the folder, based on main default folder dimlpfidex, containing all used files and where generated files will be saved. If a file name is specified with another option, its path will be relative to this root folder\n",
      "--test_class_file <str>       Path to the file containing the test true classes of the dataset. If at least --test_pred_file is specified, --test_data_file needs to have only test datas and eventually classes on same line (don't add --test_class_file in this case)\n",
      "--test_pred_file <str>        Path to the file containing predictions on the test portion of the dataset\n",
      "--attributes_file <str>       Path to the file containing the labels of attributes and classes\n",
      "--stats_file <str>            Path to the file where statistics concerning the algorithm execution will be stored\n",
      "--console_file <str>          Path to the file where the terminal output will be redirected. If not specified, all output will be shown on your terminal\n",
      "--max_iterations <int [1,inf[>\n",
      "                              Maximum iteration number, also the maximum possible number of attributes in a rule, it should be 25 when working with images (default: 10)\n",
      "--min_covering <int [1,inf[>  Minimum number of samples covered by the generated rules (default: 2)\n",
      "--covering_strategy <bool>    Whether to use the covering strategy : if no rule is found with min_covering, find best rule with best covering using dichotomic search. Decreases min_fidelity if needed (default: True)\n",
      "--max_failed_attempts <int [0,inf[>\n",
      "                              Maximum number of failed attempts to find a Fidex rule when the covering is 1 and the covering strategy is used (default: 30)\n",
      "--min_fidelity <float [0,1]>  Minimal rule fidelity accepted when generating a rule (default: 1.0)\n",
      "--lowest_min_fidelity <float [0,1]>\n",
      "                              Minimal min_fidelity to which we agree to go down during the covering_strategy (default: 0.75)\n",
      "--dropout_dim <float [0,1]>   Probability of dropping a dimension during rule extraction (default: 0.0)\n",
      "--dropout_hyp <float [0,1]>   Probability of dropping a hyperplane during rule extraction (default: 0.0)\n",
      "--decision_threshold <float [0,1]>\n",
      "                              The decision threshold used for predictions, you need to specify the index of the positive class if you want to use it\n",
      "--positive_class_index <int [0,nb_classes-1]>\n",
      "                              Index of the positive class for the usage of a decision threshold, index starts at 0\n",
      "--nb_quant_levels <int [3,inf[>\n",
      "                              Number of stairs in the staircase activation function (default: 50)\n",
      "--normalization_file <str>    Path to the file containing the mean and standard deviation of some attributes. Used to denormalize the rules if specified\n",
      "--mus <list<float ]-inf,inf[>>\n",
      "                              Mean or median of each attribute index to be denormalized in the rules\n",
      "--sigmas <list<float ]-inf,inf[>>\n",
      "                              Standard deviation of each attribute index to be denormalized in the rules\n",
      "--normalization_indices <list<int [0,nb_attributes-1]>>\n",
      "                              Attribute indices to be denormalized in the rules, only used when no normalization_file is given, index starts at 0 (default: [0,...,nb_attributes-1])\n",
      "--seed <int [0,inf[>          Seed for random number generation, 0=random. Anything else than 0 is an arbitrary seed that can be reused to obtain the same randomly generated sequence and therefore getting same results (default: 0)\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Execution example :\n",
      "\n",
      "fidex.fidex(\"--train_data_file datanormTrain.txt --train_pred_file predTrain.out --train_class_file dataclass2Train.txt --test_data_file testSampleDataCombine.txt --nb_attributes 16 --nb_classes 2 --weights_file weights.wts --rules_outfile rules.rls --stats_file stats.txt --root_folder dimlp/datafiles\")\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = fidex(\"--help\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4603d85-d0eb-4fb1-bd50-e66cac47b936",
   "metadata": {},
   "source": [
    "We see that we need the number of attributes and classes, the train and test data and class files, as well as train and test predictions, weights file name, and rule output file name where the rules will be saved.<br>\n",
    "We specify as well the saved folder and the attributes.<br>\n",
    "We also need to specify the normalization file obtained from training, to denormalize the values in the generated rule, otherwise the values will be normalized and impossible to interpret.<br>\n",
    "\n",
    "To see how it works, we launch it with just one sample using the configuration file `data/MnistTemplates/config_fidex.json`, and we have saved beforehand the test data sample with its class and predictions in the file `data/MnistDataset/testDataSample.txt`. **It should take about 1 minute**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "add3ff77-f54f-4288-b7fa-3c780a617653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters list:\n",
      " - train_data_file                                                      data/MnistDataset/trainData.txt\n",
      " - train_pred_file                                                      data/MnistDataset/predTrain.out\n",
      " - train_class_file                                                    data/MnistDataset/trainClass.txt\n",
      " - test_data_file                                                  data/MnistDataset/testDataSample.txt\n",
      " - rules_outfile                                                             data/MnistDataset/rule.rls\n",
      " - root_folder                                                                        data/MnistDataset\n",
      " - weights_file                                                           data/MnistDataset/weights.wts\n",
      " - nb_attributes                                                                                    784\n",
      " - nb_classes                                                                                        10\n",
      " - nb_quant_levels                                                                                   50\n",
      " - max_iterations                                                                                    10\n",
      " - min_covering                                                                                       2\n",
      " - max_failed_attempts                                                                               30\n",
      " - positive_class_index                                                                              -1\n",
      " - seed                                                                                               0\n",
      " - decision_threshold                                                                         -1.000000\n",
      " - hi_knot                                                                                     5.000000\n",
      " - dropout_hyp                                                                                 0.000000\n",
      " - dropout_dim                                                                                 0.000000\n",
      " - min_fidelity                                                                                1.000000\n",
      " - lowest_min_fidelity                                                                         0.750000\n",
      " - covering_strategy                                                                                  1\n",
      "End of Parameters list.\n",
      "\n",
      "Import files...\n",
      "\n",
      "Import time = 29.7188 sec\n",
      "Files imported\n",
      "\n",
      "----------------------------------------------\n",
      "\n",
      "Creation of hyperspace...\n",
      "\n",
      "Parameters of hyperLocus :\n",
      "\n",
      "- Number of stairs 50\n",
      "- Interval : [-5,5]\n",
      "\n",
      "Import weight file...\n",
      "Weight file imported\n",
      "\n",
      "computation of hyperLocus\n",
      "HyperLocus computed\n",
      "\n",
      "Hyperspace created\n",
      "\n",
      "Searching for discriminating hyperplans...\n",
      "Initial fidelity : 0.104533\n",
      "Final fidelity : 1\n",
      "Discriminating hyperplans generated.\n",
      "\n",
      "\n",
      "Extracted rule :\n",
      "X739>=249.9 X202>=15.3 -> class 7\n",
      "   Train Covering size : 61\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.999997\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "\n",
      "Time without data import = 45.5469 sec\n",
      "\n",
      "Full execution time = 75.2656 sec\n"
     ]
    }
   ],
   "source": [
    "res = fidex(\"--json_config_file data/MnistTemplates/config_fidex.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dcf258-9284-4a41-817b-9158f321a2df",
   "metadata": {},
   "source": [
    "You can see the walkthrough of the algorithm and the rule extracted. The rule is also saved in the rule.rls file. The Xi terms reprensent the ith pixel of the image (or ith attribute). With the rule, we see also the covering size of the rule on the training set, the fidelity, the accuracy, and the confidence of the rule. The confidence shows how much the rule is confident with his choices, with respect to the prediction values.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2c1cad-7802-47e5-bc09-aa28967913cc",
   "metadata": {},
   "source": [
    "# Global ruleSet generation - FidexGlo\n",
    "We've seen how to compute a rule that explains the decision of the model for a specific sample. Now, we will generalize a ruleset that characterizes the whole train dataset. That means that for each training sample, there is a rule in the set of rules that explains the model's decision for this sample. We will use this global ruleset to explain the results obtained on new test samples. If there is a rule of the ruleset corresponding to the sample, we take this one and get a global explanation for the sample. If there is none, we call Fidex and only have a local explanation.<br>\n",
    "\n",
    "To get the ruleSet we execute fidexGloRules which is located in the fidex module. Here are the possible parameters :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8286ec5a-306b-4048-84cb-7358c2647863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "Warning! The files are located with respect to the root folder dimlpfidex.\n",
      "The arguments can be specified in the command or in a json configuration file with --json_config_file your_config_file.json.\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Required parameters:\n",
      "\n",
      "--train_data_file <str>       Path to the file containing the train portion of the dataset\n",
      "--train_class_file <str>      Path to the file containing the train true classes of the dataset, not mandatory if classes are specified in train data file\n",
      "--train_pred_file <str>       Path to the file containing predictions on the train portion of the dataset\n",
      "--weights_file <str>          Path to the file containing the trained weights of the model (not mandatory if a rules file is given with --rules_file)\n",
      "--rules_file <str>            Path to the file containing the trained rules to be converted to hyperlocus (not mandatory if a weights file is given with --weights_file)\n",
      "--global_rules_outfile <str>  Path to the file where the output rule(s) will be stored. If a .json extension is given, rules are saved in JSON format\n",
      "--heuristic <int [1,3]>       Heuristic 1: optimal fidexGlo, 2: fast fidexGlo 3: very fast fidexGlo. (Faster algorithms are less efficient)\n",
      "--nb_attributes <int [1,inf[> Number of attributes in the dataset\n",
      "--nb_classes <int [2,inf[>    Number of classes in the dataset\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Optional parameters: \n",
      "\n",
      "--json_config_file <str>      Path to the JSON file that configures all parameters. If used, this must be the sole argument and must specify the file's relative path\n",
      "--root_folder <str>           Path to the folder, based on main default folder dimlpfidex, containing all used files and where generated files will be saved. If a file name is specified with another option, its path will be relative to this root folder\n",
      "--attributes_file <str>       Path to the file containing the labels of attributes and classes\n",
      "--console_file <str>          Path to the file where the terminal output will be redirected. If not specified, all output will be shown on your terminal\n",
      "--max_iterations <int [1,inf[>\n",
      "                              Maximum iteration number, also the maximum possible number of attributes in a rule, it should be 25 when working with images (default: 10)\n",
      "--min_covering <int [1,inf[>  Minimum number of samples covered by the generated rules (default: 2)\n",
      "--covering_strategy <bool>    Whether to use the covering strategy : if no rule is found with min_covering, find best rule with best covering using dichotomic search. Decreases min_fidelity if needed (default: True)\n",
      "--max_failed_attempts <int [0,inf[>\n",
      "                              Maximum number of failed attempts to find a Fidex rule when the covering is 1 and the covering strategy is used (default: 30)\n",
      "--min_fidelity <float [0,1]>  Minimal rule fidelity accepted when generating a rule (default: 1.0)\n",
      "--lowest_min_fidelity <float [0,1]>\n",
      "                              Minimal min_fidelity to which we agree to go down during the covering_strategy (default: 0.75)\n",
      "--dropout_dim <float [0,1]>   Probability of dropping a dimension during rule extraction (default: 0.0)\n",
      "--dropout_hyp <float [0,1]>   Probability of dropping a hyperplane during rule extraction (default: 0.0)\n",
      "--decision_threshold <float [0,1]>\n",
      "                              The decision threshold used for predictions, you need to specify the index of the positive class if you want to use it\n",
      "--positive_class_index <int [0,nb_classes-1]>\n",
      "                              Index of the positive class for the usage of a decision threshold, index starts at 0\n",
      "--nb_quant_levels <int [3,inf[>\n",
      "                              Number of stairs in the staircase activation function (default: 50)\n",
      "--normalization_file <str>    Path to the file containing the mean and standard deviation of some attributes. Used to denormalize the rules if specified\n",
      "--mus <list<float ]-inf,inf[>>\n",
      "                             "
     ]
    }
   ],
   "source": [
    "res = fidexGloRules(\"--help\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665be28c-c788-41c2-ae00-b7a7b3118c2b",
   "metadata": {},
   "source": [
    "We use nearly the same parameters as for Fidex but we only need train data. We need to choose a heuristic for fidexGloRules, we choose the optimal to get better results.<br>\n",
    "The process is very long and can last several days, so we already computed it beforehand using the configuration file `data/MnistTemplates/config_fidexGloRules.json`. The ruleset is available in the file `data/MnistDataset/globalRules.txt`.<br>\n",
    "If you want to launch it, and you have several processors available, you should add the parameter nb_threads with the number of processors that you want to use, it can speed up the process a lot. If you want to accelerate the process even more, you can use some dropout, the algorithm will randomly skip some dimensions or some hyperplans. For example, you can put: -d 0.9 -h 0.9, to skip half dimensions and half hyperplans, which should be about 4 times faster. You just need to uncomment the next lines :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26e0d897-ab14-4e8d-a0f9-da7fe35bfb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#res = fidexGloRules('--json_config_file data/MnistTemplates/config_fidexGloRules.json')  \n",
    "#if (res == 0):\n",
    "#    print(\"FidexGloRules done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e7b780-5fc6-4d0a-a82e-1b86ed6853d4",
   "metadata": {},
   "source": [
    "We have generated about 5000 rules explaining the whole train dataset. You can see at the top of the globalRules file the number of rules, the mean covering number per rule, and the mean number of antecedents. Here is an example of a rule that you may obtain:<br>\n",
    "\n",
    "Rule 1: X323>=219.3 X517>=198.9 X180<5.1 X492<25.5 X272<25.5 X347<10.2 X576<20.4 X236<30.6 X436<132.6 X541<30.6 -> class 1 <br>\n",
    "   Train Covering size : 2156 <br>\n",
    "   Train Fidelity : 1 <br>\n",
    "   Train Accuracy : 1 <br>\n",
    "   Train Confidence : 0.999678 <br>\n",
    "\n",
    "This rule is the first rule, which means that it's the rule with the maximum covering. Here, 2156 train samples verify this rule. It is 100% fidel with the model and has about 100% train accuracy.\n",
    "This rule says that if the 323rd pixel of the image is greater than 219.3 and if the other antecedents are verified, then this is an image on the digit 1. And this rule is accurate, on train test, at 100% and has 99% of confidence.<br>\n",
    "\n",
    "Now, we can see some global statistics on the test set, and also some statistics directly on each rule. So we will see the test accuracy on this rule.<br>\n",
    "We execute fidexGloStats which is located in the fidex module. First, let's check the parameters :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d6aaa70-4ffa-4205-99f8-840d67b260cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "Warning! The files are located with respect to the root folder dimlpfidex.\n",
      "The arguments can be specified in the command or in a json configuration file with --json_config_file your_config_file.json.\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Required parameters:\n",
      "\n",
      "--test_data_file <str>        Path to the file containing the test portion of the dataset\n",
      "--test_class_file <str>       Path to the file containing the test true classes of the dataset, not mandatory if classes are specified in test data file\n",
      "--test_pred_file <str>        Path to the file containing predictions on the test portion of the dataset\n",
      "--global_rules_file <str>     Path to the file containing the global rules obtained with fidexGloRules algorithm.\n",
      "--nb_attributes <int [1,inf[> Number of attributes in the dataset\n",
      "--nb_classes <int [2,inf[>    Number of classes in the dataset\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Optional parameters: \n",
      "\n",
      "--json_config_file <str>      Path to the JSON file that configures all parameters. If used, this must be the sole argument and must specify the file's relative path\n",
      "--root_folder <str>           Path to the folder, based on main default folder dimlpfidex, containing all used files and where generated files will be saved. If a file name is specified with another option, its path will be relative to this root folder\n",
      "--global_rules_outfile <str>  Path to the file where the output global rules will be stored with stats on test set, if you want to compute those statistics.\n",
      "--attributes_file <str>       Path to the file containing the labels of attributes and classes> Mandatory if rules file contains attribute names, if not, do not add it\n",
      "--stats_file <str>            Path to the file where statistics of the global ruleset will be stored\n",
      "--console_file <str>          Path to the file where the terminal output will be redirected. If not specified, all output will be shown on your terminal\n",
      "--positive_class_index <int [0,nb_classes-1]>\n",
      "                              Index of the positive class to compute true/false positive/negative rates, index starts at 0. If it is specified in the rules file, it has to be the same value.\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Execution example :\n",
      "\n",
      "fidex.fidexGloStats(\"--test_data_file datanormTest.txt --test_pred_file predTest.out --test_class_file dataclass2Test.txt --global_rules_file globalRules.rls --nb_attributes 16 --nb_classes 2 --stats_file stats.txt --root_folder dimlp/datafiles\")\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = fidexGloStats(\"--help\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b7ebed-01b9-4016-addb-d99839f7be74",
   "metadata": {},
   "source": [
    "We need the test files(data, prediction, class), the rules file, and the number of attributes and classes. We choose to save the results in the file fidexGloStats.txt. With the parameter global_rules_outfile we can generate the statistics on rules which will modify the rules file. If you want to keep the first ruleSet unchanged, you should give another name. So here is the command using the configuration file `data/MnistTemplates/config_fidexGloStats.json`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "375ef5c0-aca8-4e1a-a842-ed229d23e8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters list:\n",
      " - test_data_file                                                        data/MnistDataset/testData.txt\n",
      " - test_pred_file                                                        data/MnistDataset/predTest.out\n",
      " - test_class_file                                                      data/MnistDataset/testClass.txt\n",
      " - global_rules_outfile                                  data/MnistDataset/globalRulesWithTestStats.rls\n",
      " - global_rules_file                                                  data/MnistDataset/globalRules.txt\n",
      " - root_folder                                                                        data/MnistDataset\n",
      " - stats_file                                                       data/MnistDataset/fidexGloStats.txt\n",
      " - nb_attributes                                                                                    784\n",
      " - nb_classes                                                                                        10\n",
      " - positive_class_index                                                                              -1\n",
      "End of Parameters list.\n",
      "\n",
      "Importing files...\n",
      "\n",
      "Data imported.\n",
      "\n",
      "Compute statistics...\n",
      "\n",
      "Global statistics of the rule set : \n",
      "Number of rules : 4910, mean sample covering number per rule : 101.016701, mean number of antecedents per rule : 7.106314\n",
      "\n",
      "Statistics with a test set of 10000 samples :\n",
      "\n",
      "No decision threshold is used.\n",
      "No positive index class is used.\n",
      "The global rule fidelity rate is : 0.970900\n",
      "The global rule accuracy is : 0.966600\n",
      "The explainability rate (when we can find one or more rules, either correct ones or activated ones which all agree on the same class) is : 0.951000\n",
      "The default rule rate (when we can't find any rule activated for a sample) is : 0.044100\n",
      "The mean number of correct(fidel) activated rules per sample is : 8.366100\n",
      "The mean number of wrong(not fidel) activated rules per sample is : 0.225300\n",
      "The model test accuracy is : 0.993000\n",
      "The model test accuracy when rules and model agree is : 0.994747\n",
      "The model test accuracy when activated rules and model agree is : 0.996439\n",
      "\n",
      "Full execution time = 13.4531 sec\n"
     ]
    }
   ],
   "source": [
    "res = fidexGloStats(\"--json_config_file data/MnistTemplates/config_fidexGloStats.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c523c382-b2ed-413e-84e7-c0d39c6d1bf5",
   "metadata": {},
   "source": [
    "Here you can see the global statistics on the test set. We have about 97% fidelity, which is good, and a rule accuracy(96.6%) about 3% lower than the model accuracy(99.3%). So the rules seem to classify a bit worse. The explainability rate is the percentage of samples for which we can find a rule in the rules set. For the others, we need to execute Fidex (this is the default rule rate). In our case, we had more than a 95% explainability rate, so only in 5% of cases do we need to compute Fidex. Each rule can activate many rules. Here on average, a sample activates 8 correct rules and 0.2 wrong rules. A wrong rule is a rule with which the model doesn't agree. For example, if the rule says malign and the model says benign. Something interesting is the model test accuracy when rules and model agree. You can see that, generally, the accuracy increases if we consider samples where rules and model agree, and increases even more if we take only the activated rules (when there are no activated rules, we choose the model prediction). That means that the rules confirm well the model decision, but when no rule is found, the model decision may as well be wrong. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5400680-5058-4f75-97f1-552b1cead6d8",
   "metadata": {},
   "source": [
    "In globalRulesWithTestStats file, you can now see the statistics of rules on the test set. Here is the same rule as before that we have now:<br>\n",
    "\n",
    "Rule 1: X323>=219.3 X517>=198.9 X180<5.1 X492<25.5 X272<25.5 X347<10.2 X576<20.4 X236<30.6 X436<132.6 X541<30.6 -> class 1 <br>\n",
    "   Train Covering size : 2156 --- Test Covering size : 370 <br>\n",
    "   Train Fidelity : 1 --- Test Fidelity : 0.997297 <br>\n",
    "   Train Accuracy : 1 --- Test Accuracy : 1 <br>\n",
    "   Train Confidence : 0.999678 --- Test Confidence : 0.997311 <br>\n",
    "\n",
    "We see that the rule no longer always agrees with the model, only in 99.7% of cases. However, the rule accuracy is perfect. That means that the rule is very good in reality, with 100% of correct classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72abe27f-3d11-4128-90ab-307e5e16d5a6",
   "metadata": {},
   "source": [
    "# Explanation and image generation\n",
    "\n",
    "Now we get the explanations on a few test samples. We use the files `testDataSamples`, `testClassSamples`, and `testPredSamples` containing 10 test samples. <br>\n",
    "We launch it like this using the configuration file `data/MnistTemplates/config_fidexGlo.json` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd579681-492d-4900-84ae-69aeef690a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanations generated\n"
     ]
    }
   ],
   "source": [
    "res = fidexGlo(\"--json_config_file data/MnistTemplates/config_fidexGlo.json\")\n",
    "if res == 0:\n",
    "    print(\"Explanations generated\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccf58f4-b70b-4586-ad3c-345d9a5d0823",
   "metadata": {},
   "source": [
    "The explanations for each test sample can then be found in the file `data/MnistDataset/explanations.txt`. We find a global rule for every of those 10 samples. <br>\n",
    "Now, we parse the explanation file to get the first exaplanation rule of each sample and we generate the test images with colored pixels where the rule is activated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c423f7c5-ae3d-4c15-9a3a-2563ec2ec656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAcABwDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDwOC3mup0gt4ZJpnOEjjUszH0AHWnXNnc2Upiu7aaCQfwSoVP5GpNN1K90fUIb/TrmS2u4STHLGcMuQQcfgSK7C0+LfjeCFEOtrc7SSBdwxyMAB/eZe/pnOR+YNJvY4fy383ygNz7toC/Nk+2OtNr2D4j+INQT4eaRpOvSW1xrupONQlVLdENpBjEaDaAMtgk9+o9K8foB26BXcfDrw5a6hNea9roceG9HUXF2B0mk/giA7kk/l6Zrh66OLxtq0Hgl/CcAgi0+SUySsqHzJckHDEnGMquOM8dcE0mLXoU/E+v3PifxHe6xdDa9xJlUHSNBwqj2AAFZFFFMD//Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAABw0lEQVR4Ae2Uu4rCQBSGc1kLIY2KQgpRECxsRDB4D8KWYqWvYKWdvZ2ND+Ab6CPY+AqKa6FivCAqoggqaqF4yZ4liwxJSGZTbOVUc875/n9OZiZDEO/x3gHsHRAxSFLJZLPZXC63Wq0ul0utVluv1+PxWImhGVgJNULnv9h0OnW73S/N6XTq9XqvEJ0sl8tKpdJqtdAkzD9kMYTQpt/v7/f7Pp8vEAgkk8lwOLxYLJxOpwTf7/ftdsuyLITz+VxpqtKpbBmLxQLWoOQ4TirBtgiCMBgMrFZroVCoVqsyicEwk8k8Ho9utwu+Bi1kMofDsdlsRFEEa1lJCinVLJpU3qF8Pm+32/f7/XA4REkjc8k9Fotdr9fn88nzvBEXVU25XAbHZrNpMplUAdzkawfMZnO73YbTj0ajuGJdrlQqQZuNRkOXxAVSqdTtdjscDpFIBFejzdlstslkAm3W63VtErdK0zQhEuA4Go08Hg+uTJvzer3gCCOdTmuTuFWXyzWbzcCxWCySpP5bgeUrXUwwDQaDWAJdKJFIHI/Hny//i6nOvx+PxxmGoUgKjv58Pus2IQEqj7RS2fnqhD5Du91OWfq/zDfVxbkSIgT+IwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAcABwDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDwGONpZFjQZdiFUepNewQfC/wXpmpWWgeIfE16/iO6CobTTYt6wyN03Hacgd+h78CvHl2lhuJC55IGSB9K9c+H1lbeCPCdz8SNZjWW5bdBpFtJw0jn5TIDn/eHToCe4oCx5x4o0X/hHfFGpaOJ1nFnO0QkH8QB4z7+vvWTVnUb+51XUrnULyQyXNzK0srnuzHJqtQAV9CeLbbwR8QRpNvZ/EGy0fTrO1VIbCSIBEPPzEs6gNtwuD6e9fPdFAWPSz4K8CaQ0jal8QrW6dRIqw2Vm8oY7SB843AcnrgiuH1+DRrfVXTQby5u7DapSS5iEb5xyCB71mUUra3Hd2sf/9k=",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAB0ElEQVR4Ae1VO4vCQBDOnaegCKIWYqOCpWBlL/Y+GsHfIfgAe63U8tJpYSWCiL2FIGohgoIIVnY+OhsVH/E+bmFZLsnmLtgcd1uE2e+b+TKTmd0Iwp9eL/zqM5mM2WwOBoPJZBKeoiiORqNGo8GP4rHNZvMuW6vVyuPx8MI4HKu4WCyq1Wqn0yGvKBQKnEBVKhQKXS4XSMznc5/PZ7Va4WoymabTKcByuawaySFisdj1eoWi2+2mbkjwfD5DNBKJUPBnhtfrdTgcbMxsNiPl6xdl5WBns9nT6QTR4XBosVi+sHq20WiUKG42m3A4rCnxqukBB/QNXYKBkej3+98JUfB5MBgm6Xg8ovB6vU7GgCF1mej+fr+H4m638/v9ujRkQWgL6XilUpGRuoB4PE4Gs9frPadwp9M5Ho+fnGapVCKKwkPgp8l2VeOLkMKhy55UxRi56JuiHwvisOIeoMjhcMDWaDTabDaAdrtdTKffP2lkkM/nMX/aorhWqCKMVquFc+VyuVKpFMUNr4a7dMd2u90Wi0XVm7/dbicSCRqmaNxuN0mSQHW73clkAmMwGODXoCoKj1wuhzKJXCAQoKnVarX1eg0cL14ul8Th//kLv8AHHID/TwdR+MgAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAcABwDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD5/pyozDKjPIGM8kn0HWm11vw40hdZ8ZWMcjqLa1Y3t0JRmMRxDdkjPPpjjr15pMat1MvxRoI8Na0dLa68+aOGJ5/3ezy5GQM0fU525xn26CsatPxBqcmreIdUv5EZDd3ck5R+WTLE7c9eM4/CsymDVtAr0PwotvpPwx8W648wjmvFj0u2TKlnLDMo9cYIPHp37+eUUWF0sOkIaV2ByCxIO0L+g4H0ptFFA27u5//Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAABW0lEQVR4Ae1UvYqDQBBO4gnBdBZqZypTSbC0ECF2NnkFXyDPETiw9R0EC58ihEDq2NkoCCISsLBRb7iFxWJZNz/HNbEav/nm229mh53NPt+/T0DTtL7vD4cDxcmCkiOmDMMA0TzPidkHwGHEPR6P9/t9BLwc6rreNE0QBHQlpvax081mIwhCGIZ00ceyl8slTdPVaoXK8GGPqYzZ6/UarihJkjFIjJnaR5W2bS/mi7IsiUJj8Gv8Q4yhx/lvAm6pH/r9955IewY0TbOqquv1ulwuJ+tZ23ccRxRFGGjbtm8T3W63wzBEUfSGG0emFEUpiuJ2u016RASm9j3PkyTpfD5DDYtTJlFVVWGZ6roGUbQJjJYJNGwqyzJY+91uRyCRIJpTZMqyLFmWcS0+CSPPBL7vg03YUI7jGOtpTkEC3iTXdSGAZeq6jlF0gsbz/Ol0iuMY1Ceon/SfTuAHQHhpoqOGqVUAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAcABwDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD5/ruPh98NL/x5dS/6QdPskQ7buSHesknZFGRk8MTg8AGuMt4WuLqKBFZmkcIFUZJJOMD3r6F8b/EeH4a2kPgfwlaZurGBRJPIuRDkB84xhmIJYnpz3OcK4buy3Pn7ULGfTb6a0uY2SSJyp3KRnBxkZ7VWr2/xBu+I/wAGG8Uakdmr6HK8f2hVVI7pSyA9cdsY75GMfNivEKaDVbl/RL5dL1/TtQcMUtbqKdguMkKwbjPfivou/wDAvgXxzr194yuvE0klldGDdHFMsMS7VCbHZhk58scfKR+INfMtFKwap3R678VfiLpOo6Ta+E/CStBpNsx+0MkflpKRjaqgdVzkkkcnB9z5FRRTA//Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAABxElEQVR4Ae2UMY8BURDHdze2oaVFIr4CFUqukPgaIiS+AaVGJBK1L0AlKhoVOiVBIUKiVTpZ/5hkzL3l3t7lkmu8YjOz7z+/nXlvZg3jvf7lBAKBQKfTuV6v8/k8Eon8TQ7xePxyX+CWSiUt1NIqQqFQt9vVyqTAJx23XalUCoVCIpGwffbl8wJBOp22LGuxWEwmE7fe0xvUS4Vz+WSs12vD8URQRcPh0HEccHmdTqftdsuuGqD1M5nMZrNBPGfabrfz+TzKr9Vq9LJYLGo5D0E0Gj0ej4gkKIptNBp+v58U6KrD4YDd8/lcrVZt235EfmPJHhqNRsFgUBGXy2X+ZCwWU3afuwydzWbhcFiK6HqQ7HQ6pTrc0Jd9ir7BSiaTu91OQs27Y5omCfCs1+tS8Np2DLoKqZAt9Jvyl8ulAmUiBgyNwdeIG1POR+bxxXZDebvVatH38ETPpVIp3tIZz8pHDMYBIIYOBgMdSOyvVivcLNbHfe33e3KVARMRHky0NKUDFucFQ7oYMA8kIeGZkRSC4mbG4zF6kwdMxOlMzHiz2QQUfyNOFq6Xn7SGncvl+v0+oL1eL5vNwvXaQBrwe/uHJ3AD6veSkUh4MEgAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAcABwDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD5/rTuNBvbXQLHWZFT7LevKkQB+b92VDMR6ZYDPqO3GY9D04axr+naYZBGLu5jgLn+HcwGf1roPH+rifxRPplvGF0vSSLG1tyCiqIzhm2g9WbeSTz83rSd+hUOVytLb+rHNjTLo6OdVCA2izi3ZgwyHK7gCPcA8+xqpXoviS0j8NfCTw/pLJm91q4OrzOeCkYTZGv0IYn8686pkj4ZpLeeOeF2jljYOjqcFWByCK7GT4qeKJRvkk097njN02nQNMSO5YpyccVxdFAHqfx1uGl8UaLG7kyppETTRlv9XIzuzDb/AAnkcemBwAK8sp800txM008ryyucs7sWZj7k0ykthLY//9k=",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAABy0lEQVR4Ae1UPc/BUBi93lR8JhIJiwiJiTCQGIwMmhgsbP4Bg59gswh/QWyI1SjxAyzCYpAwMViF+EiduHlbaZ+2ad5N3js0zz3n9PQ+H7eM/a9vqEAmk9ntdmQmxWIxHA6T1A+JyqAoig6HQ5L3H0G5XO50Oh+AEhqZCoJQKpWgtTGm9V0sFolEwuPxKGa/kZFpPp/P5XL9fh+O8FUtv98PU7fbrcKNtqlU6nQ6bTYbr9dL6ubz+ePxCAQCJEuDw+Hwcrlks1lO8/TlIuCYkiQ9n08LptVqFVVcrVb0BxnrdrtwnM1mdrtdT6PGR6MRUqvX62rivY9Go8fj8Xa7FQoFUkCAPp9vv9/DlODeULvdBmuQB9F9DGYoFEJN9UxjsRio9XqtJyBwl8uFGVwul+iGlg4Gg6gmVqPR0LIcEbQEmr7dbiuVynQ67fV6siCZTOKMkUgEfQfInzJrHsTj8fF4fD6fUTt5oTmHw+F+v2MwACIhPSPtTVGU6XSal49Dk8kEwWAwqNVqCHCJFekfo1arxc+OK6dnZflrtveCncFIWTZFf0xbRMypXlIcdzqdCK7Xq7HMGosZwN+r2Wxae81ELTELV97E6zvpF4VctD5oC9+HAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAcABwDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD5/p6RPIQEG5iwUKDySemBTK7/AOD2hNrnxAsRk+TZFryXchZAUH7snkZ+cj0/Wkxq3U53xX4S1PwZqsWm6r5H2mSBJ8QybwobPB9CCCCPyyMGsKul8feIX8TeN9X1M8Ry3BWIMuCI0+ROvI+UAketc1TBq2gV6p4EnHh/4U+MfEdsSl5IYtPiYONyhhhj04GXDDHdBzwc+V1KlxOkEkCTSLDIQXjDEKxHTI6HFFhdLDJCGldgcgsSDtC/oOB9KbRRQNu7uf/Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAABXUlEQVR4Ae2UvYqDQBDH/TgRa1Na5gFs0oi1YGHhYwRfwffwASQPYBtbO8HCWhC0ExTsxES9uRuyhNNzJV51xGKdHWd+O//ZXRnm/fzPDliWNY6j4zg8z+9SOD2yZVkuyxKg8EiS9HDve9u2jcTL5cKy7C4YViqKYhzHCDVNcxeRJJ9OJyT2fY9O0hYSgwb3Y74yBe349Xq9orFP/zcjiiJmYrquU1UVoa+PqFHTNNRe1zWVRZePGqGhyPI8jwrdGuD7PlTaNI2iKFtz1uN0Xb/f7wDN8/y3HX8m0OVDNFwkjvuKDMPwD3Yc1yfaobNbKn2uetmGJoJ2OExpmi5HzLxr8slhAu3jNAZBMEt/1XE+n2GLqqo6HA7A2CJ/rVIswzAMMIqiaNsWjC0bRYEKgnA8HoEFt/N2u+Ey1JECBeHwuwNKlmVUFgn4INaiMQyD67rTNCVJshjwds478AlKn5WF35W9SwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAcABwDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD5/AycDrW5rfhPU/D0Fk2oiGOe7h88WqyAzRIQSDInVcgZ/nijwdcaRaeMNLuNdTfpcc4a4GCeOxIHJAODx6d67vxX4Z0rXvEV1r7/ABG0KZL93kAkDtKiZIC+WASCFwADg8cdM0m+g4uPMlI850vQ9Q1mK+ls4laKxgNxcSO4RY0HqSepPAHUms6vTfiElh4J0O18DaNeJdPKReardqq5mfA8pAR0UDLYOfvA15lTEncK774P6LBrXxBtGmi8yLT4XvXhK7zKU+6FH+8y8ex9a4Gp7S+u7CVpbO6nt5GUozwyFCVPUZHb2oC76Gr4ui1ZfE15PrcSw6jdSG4miDKTGXJO0gH5T7Hkd6w6CSTknJooA//Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAB20lEQVR4Ae1Uz6sBURSeXo+SJOXHikRWUmJjx4aNLK1YWFj4M5SysbQQRX5kocjLnrGyQqyxU5QslNXIzPtqMhhz5zW9t3nlLmbO/c53vjn33HOGot7r31fAbDaPx+N8Pm+320mH0ev1sVhMpVKRCE+4wWA4HA4Mw3Q6He7Jc99Acb1en04nl8t1R0mW0WgcDofX67VYLAqcV+lCoQBOOp0WOHJGJBIBG8tkMpF4brebZdler6fT6UicO45SlstlKKZSqTtKUY+ZQnG320E0mUw+coh2q9XiOG46nWq1WhIpk8lAsVarkQhivNlsIs3BYCB5pxqNJpfLHY9HcMSRt/3nzRC/o9Hohbn0v/qlUknwBYPBUCgUCASAdLtdAf/Z8Pv92+0WiWDhjLzBP4XtarVyOp0kLYlMZ7OZx+Pxer30iGY5Ft3aaDT4eJR7uVzCnkwmm82GJKoMdzgcaIL5fC7TasoUwa7X66hDOBxWHEkKiMfjqCmG0ufzkTiKcXQlRNvttuJIUcDjFGGEzufzX6bJj9B+vxd99VfbxWKBK6pWq1DBH8Rms8nIfcj4Xl3QTSQSNE1jUl+9ihE+U36iKpWK1WpVLCERwFGj0SibzVosFrVaLUF4Q7cKfAPKtueqgybMLgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAcABwDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD5/rTg8Pavc6Hda1Dp87aZalRNdbcIpLBQAT1OSOmcZrMr6e0e61HS5tD0FtDsJ/Ao0qKWfUJYi0YLxks5ZuOWJBGOjZOB0TdhPRXPmJgAcBg3AOR/KkrqfiLokOgeONQs7a1ktrVis0EbdAjqG+XgfLkkDIB455zXLUJ3Vx3T1QVsv4m1l/DseiHV7k6bG24WhYhQTnp6j2Pc9O9Y1FNjTtqej6lMvjr4cQ3hlWTXvDcYS47vcWbEYfnklGIB7c5715xVzTdVvtHuJJ7C4aCSWF4JMAEPG4wykHggj+h6iqdAmf/Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAABv0lEQVR4Ae2VPa8BQRSG1ya+ElEQiUIoiIhCFH6CmooQnb+gVyo3u4VE4kayBZVETaejUwoF0Sh8hAQRiZ37MskUl5XsUNzc3CkmM++c88zMOXtmBeG//dkIkPdv5nQ6q9Vqv983m83v026EQqEwn8+v9+Z2uz8A9fl8q9VK0zQwBSK0Wi2Xy/UuV5Zl4CiUHna73ZZKJYvFwokOBAL7/R6s0WjU7XYpFP1yufR6vZzQdDqNM+LWaDabrVgsTqdTKISQ4XD4Og6i3p5WqxX+xHRbP5/PjUYD0LtgOp1Ol8tFzxG6LjSfz2P5q15nzolEAmONaIPB4HA4MN3AIJvN0oBGIpFMJoPUIxSbzQb9er2ORqMGWMwUUUOuwWXZR7pCodB4PIZYq9WYpbFBMpnc7XaII7iKotDqrFQqmM5ms2AwaAzHrMFFiiRJcjgcVLTb7Z1OB4dVVZWZfWCQy+UAXSwWrz8sYzuJooi8gVsul415Umu9Vy4ejx+PR3DD4TAPFz4/0HSKRwAZa7fbiDIn99HN4/FMJhNwY7HY4yq/4vf7AW02m/yIp569Xg8ly1lgT4kQ8bNBIaRSKT2D361/AwxQ8/fNJ4TuAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAcABwDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD5/rZ8N+FtZ8W6ibDRbM3M6rvcb1UIucZJYgY5rZ+GHhCLxp4xjsLnebSCFrqdEOGdFIG0HtksBn3qTxJqPiyx8WX9/Dp+oeHnIWJYLRGhEUIxsTKgAjAHPc80AdQv7PfiGKOJ73WdHtQ+chpWJU4P+yAecdD3ryvUrJtN1S7sHkSRraZ4S6A7WKsRkZAODjuKW8urma5826luJLlT8/2k7zkY67uvOeCPzqpSG1Z7mho2t6j4f1FNQ0q6ktbtBhZY2wRyD06EHGCDkH0r3/4W/Fq88QRX2l67q1pFqu1TYzXUaqkhxhgQu3JyM44OCfSvnCimF9LHqPxv8SaL4h8SWX9lSQXE9rC0V1dW4+SU7sqA3fAz6gbsZOK8uoooEj//2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAB90lEQVR4Ae1Uu6tBcRw/l5vyKCmxSMpoQhaLwaKU0cT/wGZQDEzKRLErNimDJJPCQoo88kgpj0155HGd++3+4vDDcY7u3e5vOd/X5/N9/H7nSxD/57cn8PEGoUQiUSqVCDgej91ud7PZ7PV6jUbjDTbCarXG4/Fut/t1Pu12e7PZII0do1qtDofDq9XqeDye2fAvQVKcjNo3mUzFYpECnaVOp9Nqtc4aYbfbkfx5MWGCVCp1uVylUimXy+33++VyuV6vhUJhPp+HCVar1Xq9vt1uwYgBn6oArtVq0KHNZkNBKpUKBLgfDodzD7tq/d75Y+HxeJlMBhgDgYBAIHgSxcYsEomCwSAwzudzsVj8EPq6LgzmcDiAcTQaKRQKzIWpNNT4gIxGI4DhEiaTCcaCqYzeDcIsFguoFN6zz+fTarUYEUMVz0eS5Ol0QmAQYrFYpVKBS+/3++hJajSacrn8so+b9KFQCCqlP7PZLJVK3cDoFS6XazAYYDsMh8PD4fCMHf5Xr9dLT0V5r+/UbDZbLBZo/yF1Op2mYMwllMDj8QDpbreD+er1+kQigXK8SYrS63S6S6WFQgEah4UElkgkwrw+PJLP5yeTyQsvCLBfoEzYD3goK10ul2ez2el0CoyDwcDv97OC0wU7nc5oNCqTyeiC/n1/NIFvjihnxtmzQL8AAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAcABwDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD5/qSGCW4lWKCJ5ZG4CIpYn8BVvRLSzvtcsbTULsWdnNMqTXB/5ZqTy1fRF3pGtWDrpvw2XQNOtLhAV1N7oTXF30JbdhscnvknkigNLanzjc6fe2dwtvdWdxBM2NscsTKxz0wCM1Wr6b8cX0Wh/DO7s/GerWuq397aIljBGMt5ojCmQOMZXcBJkgY5GTmvmSkgTugr2j4Y6Rp3gzwhdfEjxDbh3UmPSoWYZkbkZA7EnIBPQBjjHNeL10Ou+M9W8Q6Fo2j3phFnpMXlQLEpUsMAAvzgkAAZwP1NDdhN2sUfEGvX3iXXbvVtQlL3FxIWxkkIM8KuegA4ArMoopjP/9k=",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAACDklEQVR4Ae1UO48BYRS1a72CRCOiU5DYCDokGlGISqXSKCi0EhFRiASFRotWoVH4AQodSo8fIF4FIfEK8Zw9u18yIXZm2WyyW+wtJve737ln7j1z73A4//avwK8ooFarLRZLOp3mUJx6ve71ejUaDV0JRXvsDo3T6/W5XG4ymZyvbb/fdzqdbDbL5/PZqa5uDQZDPp+fz+eEbTAYFIvFVCp1OBwajQaCo9Go1+sFAoGrNJYD6OjqKpVKJpMRCoUEX61WtVptrVbbbDbdbvd0Osnlchaq9yskx2IxQFHLeDyOx+Nisfgyp91u63Q6h8NB6/E1qdPpXK1WSBgOhyaT6ZKOy+WqVKpQKISul8slMBRFFQoFHo93CXu5PBAfmSgTPrQzm81utxvN4rjdbl8/bDqdKhQKAkYryWQSSHJkfIpEonK5vF6vQY1CUA7GCGl0s8Q5Ho+lUkmpVN4SPd2GSEQmk0UiEavVOpvN+v2+QCAwGo1Q4/np+UydgcGcRaNRzAYTw11xaEdqXCwWPp8PKt2VxgIKh8OYdkLq8XhYkPde+f1+8q1Bii2CFPdmMuGgI/olNYIaKjMhH4gnEgnCiHmw2WwPZDJBpVLpbrcjpPjcTLAH4hKJBEtFGJvNJr37D1DcQl0uFxl+8Nrt9lvAdyKtVouU+f5v/inDDxSVYrs/3cVvviUYDIIUi/8n7A2KpFWjl5SPpgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "images = []\n",
    "test_data = \"data/MnistDataset/testDataSamples.txt\"\n",
    "with open(test_data, \"r\") as my_file:\n",
    "    for line in my_file:\n",
    "        images.append(line.strip().split(\" \"))\n",
    "\n",
    "explanation_file = \"data/MnistDataset/explanations.txt\"\n",
    "pattern = r'X(\\d+)\\s*([<>]=?)\\s*([\\d.]+)' # Regular expression pattern to match antecedents\n",
    "rules = []\n",
    "with open(explanation_file, \"r\") as my_file:\n",
    "    for line in my_file:\n",
    "        if line.startswith(\"R1: \"):\n",
    "            rules.append(line.strip())\n",
    "        if line.startswith(\"Local rule\"):\n",
    "            # Search next non empty line\n",
    "            next_line = next(my_file, '').strip()\n",
    "            while not next_line:\n",
    "                next_line = next(my_file, '').strip()\n",
    "            rules.append(next_line)\n",
    "    my_file.close()\n",
    "\n",
    "# Find all matches in the input string\n",
    "for id_sample in range(len(rules)):\n",
    "    antecedents = []\n",
    "    matches = re.findall(pattern, rules[id_sample])\n",
    "\n",
    "    # Process each match and store in antecedents\n",
    "    for match in matches:\n",
    "        attribute, inequality, value = match\n",
    "        antecedent = {\n",
    "            \"attribute\": int(attribute),\n",
    "            \"inequality\": inequality,\n",
    "            \"value\": float(value)\n",
    "        }\n",
    "        antecedents.append(antecedent)\n",
    "\n",
    "    colorimage = [[v,v,v] for v in images[id_sample]]\n",
    "    for antecedent in antecedents:\n",
    "                if antecedent[\"inequality\"] == \"<\":\n",
    "                    colorimage[antecedent[\"attribute\"]]=[255,0,0]\n",
    "                else:\n",
    "                    colorimage[antecedent[\"attribute\"]]=[0,255,0]\n",
    "\n",
    "    colorimage_array = np.array(colorimage).reshape(28, 28, 3)\n",
    "    colorimage = Image.fromarray(colorimage_array.astype('uint8'))\n",
    "    image_path = 'data/MnistDataset/images/img_'+ str(id_sample) + '_out.png'\n",
    "    colorimage.save(image_path)\n",
    "    colorimage.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f912a26f-6d11-46b6-bd51-9f52f6f36b95",
   "metadata": {},
   "source": [
    "You can observe the 10 images. To see them better, open them in the folder `data/MnistDataset/images`. The red dots indicate pixels where the rule requires the value to be below a certain threshold, while the green dots represent pixels where the value must be above a threshold. You can observe which pixels are used by the model to decide which digit it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7f3208-c538-40eb-8c76-31e75d687198",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Throughout this notebook, we've learned how to use cnnTrn to train a dataset and get some explaining rules, and we got into the different Fidex algorithms to get some local and global explanations, and some statistics on the model's decisions. We used the example of the MNIST dataset and we saw that the algorithms perform very well. It gives some good explanations of the model's decision. You can try with any image dataset you want, you just have to remember to transform the data in a proper format. <be>\n",
    "\n",
    "We didn't speak about every single parameter, you can try to change every hyperparameter you want to see how it goes. A parameter that can be useful is the seed. It allows you to remove the randomness of the algorithms and get the same result in each execution for the same parameters and data.<br>\n",
    "\n",
    "To go further, you can see the notebook on the Cracks dataset which is another application of CNNs on image classification [INSERER LIEN NOTEBOOK CRACKS]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605dcb45-4862-4268-bef2-068cf96de3d9",
   "metadata": {},
   "source": [
    "# R√©f√©rences\n",
    "\n",
    "Article DimlpBT de Guido\n",
    "Article Fidex de Guido (√† venir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
