{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Random Forest and Fidex rule generation for obesity risk classification\n",
    "\n",
    "**Introduction:**\n",
    "\n",
    "Welcome to HES-Xplain, our interactive platform designed to facilitate explainable artificial intelligence (XAI) techniques. In this use case, we dive into obesity risk classification and showcase another application example of explainability techniques.\n",
    "\n",
    "This notebook is an alternative to the [`Exploring Dimlp and Fidex rule generation for breast cancer classification`](TODO). It aims to be similar but aims to use a different dataset and training model to show the versatility of our explainability tools.  In addition, we will cover how to pre-process a dataset that is not initially usable by a model and convert it to an exploitable dataset.\n",
    "\n",
    "**Objectives:**\n",
    "\n",
    "    1. Observe a different use case where XAI can be used\n",
    "    2. Understand how to pre-process data \n",
    "    3. Understand how to use Dimlp and Fidex.\n",
    "    4. Showcase the versatility of HES-Xplain using a different dataset and training model.\n",
    "    5. Provide practical insights into applying Random Forests and Fidex to breast cancer classifiers through an interactive notebook.\n",
    "    6. Foster a community of XAI enthusiasts and practitioners.\n",
    "\n",
    "**Outline:**\n",
    "\n",
    "    1. Dataset and Problem Statement.\n",
    "    2. Load and pre-process the dataset.\n",
    "    3. Train the Model.\n",
    "    4. Local rules generation - Fidex\n",
    "    5. Global ruleSet generation - FidexGlo\n",
    "    6. Conclusion.\n",
    "\n",
    "Through this use case, we aim to show the users the potential of Random Forests and Fidex as tools for transparent and interpretable classification. With HES-Xplain, we make XAI accessible, helping users build trust in their models and make informed decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and Problem Statement\n",
    "The dataset we'll be working with is called the [obesity or CVD risk](https://www.kaggle.com/datasets/aravindpcoder/obesity-or-cvd-risk-classifyregressorcluster/data) and is accessible on [Kaggle](https://www.kaggle.com). It comprises 2111 records of anonymized data conerning South American individuals and their dietary habits. In this notebook, our focus is on another medical challenge: classifying the risk of obesity based on various factors. These factors, drawn from the dataset, are outlined below with their original names:\n",
    "\n",
    "| **Full name**                             | **Used label** |                                                        **Values/Ranges**                                                       | **Description**                                                                     |\n",
    "|-------------------------------------------|:--------------:|:------------------------------------------------------------------------------------------------------------------------------:|-------------------------------------------------------------------------------------|\n",
    "| Gender                                    |     Gender     |                                                          Male, Female                                                          | Person's biological gender                                                          |\n",
    "| Age                                       |       Age      |                                                             [14:61]                                                            | Person's age in years                                                               |\n",
    "| Height                                    |     Height     |                                                           [1.45:1.98]                                                          | Person's height in meters                                                           |\n",
    "| Weight                                    |     Weight     |                                                            [39:173]                                                            | Person's weight in kilograms                                                        |\n",
    "| Family history with overweight            |      FHWO      |                                                             yes, no                                                            | Whether the person has at least one sibling that suffers or suffered of overweight  |\n",
    "| Frequent consumption of high-caloric food |      FAVC      |                                                             yes, no                                                            | Whether the person is frequently consuming high-caloric food                        |\n",
    "| Frequency of consumption of vegetables    |      FCVC      |                                                              [1:3]                                                             | Leveled frequency of consumption of vegetables                                      |\n",
    "| Number of main meals                      |       NCP      |                                                              [1:4]                                                             | Person's number of main meals during a day                                          |\n",
    "| Consumption of food between meals         |      CAEC      |                                                no, sometimes, frequently, always                                               | Person's consumption of food between main meals frequency per day                   |\n",
    "| Smoker or not                             |      SMOKE     |                                                             yes, no                                                            | Whether the person smokes                                                           |\n",
    "| Consumption of water daily                |      CH20      |                                                              [1:3]                                                             | Numeric representation of water consumption frequency per day                       |\n",
    "| Calories consumption monitoring           |       SCC      |                                                             yes, no                                                            | Whether the person is monitoring his daily calories intake                          |\n",
    "| Physical activity frequency               |       FAF      |                                                              [0:3]                                                             | Numeric representation of physical activity frequency per week                      |\n",
    "| Time using technology devices             |       TUE      |                                                              [0:2]                                                             | Numeric representation of electronic devices use frequency per day                  |\n",
    "| Consumption of alcohol                    |      CALC      |                                                no, sometimes, frequently, always                                               | Frequency of alcohol consumption                                                    |\n",
    "| Transportation used                       |     MTRANS     |                                   Public_Transportation, Automobile, Bike, Motorbike, Walking                                  | Medium usually used to transit                                                      |\n",
    "| Obesity level deducted                    |       OLD      | Insufficient_Weight, Normal_Weight, Overweight_Level_I, Overweight_Level_II, Obesity_Type_I, Obesity_Type_II, Obesity_Type_III | Obesity level observed according to the interpretation of the person's BMI          |\n",
    "\n",
    "In our case, we look forward to training a random forest model to classify the obesity level deducted from all the other features. To do so, we need to slightly modify the original dataset to convert several features to be digestible by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and pre-process the dataset\n",
    "To kick things off, we'll begin by simplifying the names of the columns and taking a look at the CSV file containing the raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>FHWO</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>OLD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>Male</td>\n",
       "      <td>30.575349</td>\n",
       "      <td>1.825449</td>\n",
       "      <td>124.952780</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.016950</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>1.834120</td>\n",
       "      <td>no</td>\n",
       "      <td>0.797209</td>\n",
       "      <td>0.185499</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>Male</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.790000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Insufficient_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>Female</td>\n",
       "      <td>17.767432</td>\n",
       "      <td>1.743790</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.344854</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>no</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Insufficient_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>Male</td>\n",
       "      <td>33.270448</td>\n",
       "      <td>1.733439</td>\n",
       "      <td>84.753830</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.631565</td>\n",
       "      <td>2.627173</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.253422</td>\n",
       "      <td>no</td>\n",
       "      <td>2.690756</td>\n",
       "      <td>0.845774</td>\n",
       "      <td>no</td>\n",
       "      <td>Automobile</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>Male</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.820385</td>\n",
       "      <td>108.395005</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.164839</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.094479</td>\n",
       "      <td>no</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.676557</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_I</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender        Age    Height      Weight FHWO FAVC      FCVC       NCP  \\\n",
       "1765    Male  30.575349  1.825449  124.952780  yes  yes  2.016950  3.000000   \n",
       "279     Male  18.000000  1.790000   52.000000   no   no  3.000000  3.000000   \n",
       "575   Female  17.767432  1.743790   50.000000   no  yes  1.344854  4.000000   \n",
       "1041    Male  33.270448  1.733439   84.753830  yes  yes  2.631565  2.627173   \n",
       "1268    Male  18.000000  1.820385  108.395005  yes  yes  2.000000  2.164839   \n",
       "\n",
       "            CAEC SMOKE      CH2O SCC       FAF       TUE       CALC  \\\n",
       "1765   Sometimes    no  1.834120  no  0.797209  0.185499  Sometimes   \n",
       "279    Sometimes    no  2.000000  no  1.000000  1.000000  Sometimes   \n",
       "575   Frequently    no  1.000000  no  2.000000  1.000000  Sometimes   \n",
       "1041   Sometimes    no  2.253422  no  2.690756  0.845774         no   \n",
       "1268   Sometimes    no  2.094479  no  1.000000  0.676557  Sometimes   \n",
       "\n",
       "                     MTRANS                  OLD  \n",
       "1765  Public_Transportation      Obesity_Type_II  \n",
       "279   Public_Transportation  Insufficient_Weight  \n",
       "575   Public_Transportation  Insufficient_Weight  \n",
       "1041             Automobile  Overweight_Level_II  \n",
       "1268  Public_Transportation       Obesity_Type_I  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from dimlpfidex.fidex import fidex, fidexGloRules, fidexGloStats\n",
    "from trainings.randForestsTrn import randForestsTrn as randomForest\n",
    "\n",
    "# silence warnings concerning replace() method being removed on pandas 3.0\n",
    "pd.set_option(\"future.no_silent_downcasting\", True)\n",
    "\n",
    "\n",
    "# utility function to preview a file entirely or only the first `nlines` lines\n",
    "def previewFile(filepath, nlines=-1):\n",
    "    lines = \"\"\n",
    "\n",
    "    with open(filepath, \"r\") as f:\n",
    "        if nlines == -1:\n",
    "            for line in f:\n",
    "                lines += line\n",
    "        else:\n",
    "            for _ in range(nlines):\n",
    "                try:\n",
    "                    lines += next(f)\n",
    "                except StopIteration:\n",
    "                    break\n",
    "    print(lines)\n",
    "\n",
    "\n",
    "\n",
    "dataset = pd.read_csv(\"data/OCDDataset/ObesityDataSet.csv\")\n",
    "\n",
    "# reducing labels names size\n",
    "dataset.rename(\n",
    "    columns={\n",
    "        \"family_history_with_overweight\": \"FHWO\",\n",
    "        \"NObeyesdad\": \"OLD\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# shuffle the entire dataset\n",
    "dataset = dataset.sample(frac=1)\n",
    "nrows = int(dataset.shape[0] * 0.1)\n",
    "dataset = dataset.iloc[:nrows, :]\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can observe a sample of the dataset. To make the dataset more compatible with machine learning, we'll start by converting features that have \"yes\" or \"no\" values into their boolean representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>FHWO</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>OLD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>Male</td>\n",
       "      <td>30.575349</td>\n",
       "      <td>1.825449</td>\n",
       "      <td>124.952780</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.016950</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>0</td>\n",
       "      <td>1.834120</td>\n",
       "      <td>0</td>\n",
       "      <td>0.797209</td>\n",
       "      <td>0.185499</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>Male</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.790000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Insufficient_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>Female</td>\n",
       "      <td>17.767432</td>\n",
       "      <td>1.743790</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.344854</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Insufficient_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>Male</td>\n",
       "      <td>33.270448</td>\n",
       "      <td>1.733439</td>\n",
       "      <td>84.753830</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.631565</td>\n",
       "      <td>2.627173</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>0</td>\n",
       "      <td>2.253422</td>\n",
       "      <td>0</td>\n",
       "      <td>2.690756</td>\n",
       "      <td>0.845774</td>\n",
       "      <td>no</td>\n",
       "      <td>Automobile</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>Male</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.820385</td>\n",
       "      <td>108.395005</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.164839</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>0</td>\n",
       "      <td>2.094479</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.676557</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_I</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender        Age    Height      Weight  FHWO  FAVC      FCVC       NCP  \\\n",
       "1765    Male  30.575349  1.825449  124.952780     1     1  2.016950  3.000000   \n",
       "279     Male  18.000000  1.790000   52.000000     0     0  3.000000  3.000000   \n",
       "575   Female  17.767432  1.743790   50.000000     0     1  1.344854  4.000000   \n",
       "1041    Male  33.270448  1.733439   84.753830     1     1  2.631565  2.627173   \n",
       "1268    Male  18.000000  1.820385  108.395005     1     1  2.000000  2.164839   \n",
       "\n",
       "            CAEC  SMOKE      CH2O  SCC       FAF       TUE       CALC  \\\n",
       "1765   Sometimes      0  1.834120    0  0.797209  0.185499  Sometimes   \n",
       "279    Sometimes      0  2.000000    0  1.000000  1.000000  Sometimes   \n",
       "575   Frequently      0  1.000000    0  2.000000  1.000000  Sometimes   \n",
       "1041   Sometimes      0  2.253422    0  2.690756  0.845774         no   \n",
       "1268   Sometimes      0  2.094479    0  1.000000  0.676557  Sometimes   \n",
       "\n",
       "                     MTRANS                  OLD  \n",
       "1765  Public_Transportation      Obesity_Type_II  \n",
       "279   Public_Transportation  Insufficient_Weight  \n",
       "575   Public_Transportation  Insufficient_Weight  \n",
       "1041             Automobile  Overweight_Level_II  \n",
       "1268  Public_Transportation       Obesity_Type_I  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strToBinDict = {\"yes\": 1, \"no\": 0}\n",
    "dataset[\"FHWO\"] = dataset[\"FHWO\"].replace(strToBinDict).astype(\"int8\")\n",
    "dataset[\"FAVC\"] = dataset[\"FAVC\"].replace(strToBinDict).astype(\"int8\")\n",
    "dataset[\"SMOKE\"] = dataset[\"SMOKE\"].replace(strToBinDict).astype(\"int8\")\n",
    "dataset[\"SCC\"] = dataset[\"SCC\"].replace(strToBinDict).astype(\"int8\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will convert the `CAEC` and `CALC` columns, which contain the values \"Always,\" \"Frequently,\" \"Sometimes,\" and \"no,\" into a numerical scale from 0.00 to 1.00 based on their frequency. Here's the conversion table:\n",
    "\n",
    "| **Adjective** | **Conversion Value** |\n",
    "|---------------|:--------------------:|\n",
    "| Always        |         1.00         |\n",
    "| Frequently    |         0.66         |\n",
    "| Sometimes     |         0.33         |\n",
    "| no            |         0.00         |\n",
    "\n",
    "We'll apply a similar procedure as before to achieve this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>FHWO</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>OLD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>Male</td>\n",
       "      <td>30.575349</td>\n",
       "      <td>1.825449</td>\n",
       "      <td>124.952780</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.016950</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "      <td>1.834120</td>\n",
       "      <td>0</td>\n",
       "      <td>0.797209</td>\n",
       "      <td>0.185499</td>\n",
       "      <td>0.33</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>Male</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.790000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.33</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Insufficient_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>Female</td>\n",
       "      <td>17.767432</td>\n",
       "      <td>1.743790</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.344854</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.33</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Insufficient_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>Male</td>\n",
       "      <td>33.270448</td>\n",
       "      <td>1.733439</td>\n",
       "      <td>84.753830</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.631565</td>\n",
       "      <td>2.627173</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "      <td>2.253422</td>\n",
       "      <td>0</td>\n",
       "      <td>2.690756</td>\n",
       "      <td>0.845774</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Automobile</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>Male</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.820385</td>\n",
       "      <td>108.395005</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.164839</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "      <td>2.094479</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.676557</td>\n",
       "      <td>0.33</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_I</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender        Age    Height      Weight  FHWO  FAVC      FCVC       NCP  \\\n",
       "1765    Male  30.575349  1.825449  124.952780     1     1  2.016950  3.000000   \n",
       "279     Male  18.000000  1.790000   52.000000     0     0  3.000000  3.000000   \n",
       "575   Female  17.767432  1.743790   50.000000     0     1  1.344854  4.000000   \n",
       "1041    Male  33.270448  1.733439   84.753830     1     1  2.631565  2.627173   \n",
       "1268    Male  18.000000  1.820385  108.395005     1     1  2.000000  2.164839   \n",
       "\n",
       "      CAEC  SMOKE      CH2O  SCC       FAF       TUE  CALC  \\\n",
       "1765  0.33      0  1.834120    0  0.797209  0.185499  0.33   \n",
       "279   0.33      0  2.000000    0  1.000000  1.000000  0.33   \n",
       "575   0.66      0  1.000000    0  2.000000  1.000000  0.33   \n",
       "1041  0.33      0  2.253422    0  2.690756  0.845774  0.00   \n",
       "1268  0.33      0  2.094479    0  1.000000  0.676557  0.33   \n",
       "\n",
       "                     MTRANS                  OLD  \n",
       "1765  Public_Transportation      Obesity_Type_II  \n",
       "279   Public_Transportation  Insufficient_Weight  \n",
       "575   Public_Transportation  Insufficient_Weight  \n",
       "1041             Automobile  Overweight_Level_II  \n",
       "1268  Public_Transportation       Obesity_Type_I  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjToValDict = {\"Always\": 1.0, \"Frequently\": 0.66, \"Sometimes\": 0.33, \"no\": 0.0}\n",
    "dataset[\"CAEC\"] = dataset[\"CAEC\"].replace(adjToValDict).astype('float64')\n",
    "dataset[\"CALC\"] = dataset[\"CALC\"].replace(adjToValDict).astype('float64')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll address three additional columns named `Gender`, `MTRANS`, and `OLD`, which currently contain non-numerical values. These values represent individual options and cannot be quantified using a scale like before. Instead, we'll encode them using a technique called \"one hot encoding.\" This technique will assign a binary value to each option, representing its presence or absence. Let's proceed with applying one hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>FHWO</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>...</th>\n",
       "      <th>MTRANS_Motorbike</th>\n",
       "      <th>MTRANS_Public_Transportation</th>\n",
       "      <th>MTRANS_Walking</th>\n",
       "      <th>OLD_Insufficient_Weight</th>\n",
       "      <th>OLD_Normal_Weight</th>\n",
       "      <th>OLD_Obesity_Type_I</th>\n",
       "      <th>OLD_Obesity_Type_II</th>\n",
       "      <th>OLD_Obesity_Type_III</th>\n",
       "      <th>OLD_Overweight_Level_I</th>\n",
       "      <th>OLD_Overweight_Level_II</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.575349</td>\n",
       "      <td>1.825449</td>\n",
       "      <td>124.952780</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.016950</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.790000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17.767432</td>\n",
       "      <td>1.743790</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.344854</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.66</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.270448</td>\n",
       "      <td>1.733439</td>\n",
       "      <td>84.753830</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.631565</td>\n",
       "      <td>2.627173</td>\n",
       "      <td>0.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.820385</td>\n",
       "      <td>108.395005</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.164839</td>\n",
       "      <td>0.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender_Female  Gender_Male        Age    Height      Weight  FHWO  FAVC  \\\n",
       "1765              0            1  30.575349  1.825449  124.952780     1     1   \n",
       "279               0            1  18.000000  1.790000   52.000000     0     0   \n",
       "575               1            0  17.767432  1.743790   50.000000     0     1   \n",
       "1041              0            1  33.270448  1.733439   84.753830     1     1   \n",
       "1268              0            1  18.000000  1.820385  108.395005     1     1   \n",
       "\n",
       "          FCVC       NCP  CAEC  ...  MTRANS_Motorbike  \\\n",
       "1765  2.016950  3.000000  0.33  ...                 0   \n",
       "279   3.000000  3.000000  0.33  ...                 0   \n",
       "575   1.344854  4.000000  0.66  ...                 0   \n",
       "1041  2.631565  2.627173  0.33  ...                 0   \n",
       "1268  2.000000  2.164839  0.33  ...                 0   \n",
       "\n",
       "      MTRANS_Public_Transportation  MTRANS_Walking  OLD_Insufficient_Weight  \\\n",
       "1765                             1               0                        0   \n",
       "279                              1               0                        1   \n",
       "575                              1               0                        1   \n",
       "1041                             0               0                        0   \n",
       "1268                             1               0                        0   \n",
       "\n",
       "      OLD_Normal_Weight  OLD_Obesity_Type_I  OLD_Obesity_Type_II  \\\n",
       "1765                  0                   0                    1   \n",
       "279                   0                   0                    0   \n",
       "575                   0                   0                    0   \n",
       "1041                  0                   0                    0   \n",
       "1268                  0                   1                    0   \n",
       "\n",
       "      OLD_Obesity_Type_III  OLD_Overweight_Level_I  OLD_Overweight_Level_II  \n",
       "1765                     0                       0                        0  \n",
       "279                      0                       0                        0  \n",
       "575                      0                       0                        0  \n",
       "1041                     0                       0                        1  \n",
       "1268                     0                       0                        0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genderCols = pd.get_dummies(dataset[\"Gender\"], prefix=\"Gender\",prefix_sep='_', dtype='int8')\n",
    "mtransCols = pd.get_dummies(dataset[\"MTRANS\"], prefix=\"MTRANS\",prefix_sep='_', dtype='int8')\n",
    "oldCols = pd.get_dummies(dataset[\"OLD\"], prefix=\"OLD\",prefix_sep='_', dtype='int8')\n",
    "dataset = pd.concat([genderCols, dataset.iloc[:,:16], mtransCols,  dataset.iloc[:,16:], oldCols], axis=1)\n",
    "dataset.drop([\"Gender\", \"MTRANS\", \"OLD\"], axis=1, inplace=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our dataset is prepared to be used, let's ensure the data's integrity by verifying some information, starting with a general overview of our columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 211 entries, 1765 to 277\n",
      "Data columns (total 27 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Gender_Female                 211 non-null    int8   \n",
      " 1   Gender_Male                   211 non-null    int8   \n",
      " 2   Age                           211 non-null    float64\n",
      " 3   Height                        211 non-null    float64\n",
      " 4   Weight                        211 non-null    float64\n",
      " 5   FHWO                          211 non-null    int8   \n",
      " 6   FAVC                          211 non-null    int8   \n",
      " 7   FCVC                          211 non-null    float64\n",
      " 8   NCP                           211 non-null    float64\n",
      " 9   CAEC                          211 non-null    float64\n",
      " 10  SMOKE                         211 non-null    int8   \n",
      " 11  CH2O                          211 non-null    float64\n",
      " 12  SCC                           211 non-null    int8   \n",
      " 13  FAF                           211 non-null    float64\n",
      " 14  TUE                           211 non-null    float64\n",
      " 15  CALC                          211 non-null    float64\n",
      " 16  MTRANS_Automobile             211 non-null    int8   \n",
      " 17  MTRANS_Motorbike              211 non-null    int8   \n",
      " 18  MTRANS_Public_Transportation  211 non-null    int8   \n",
      " 19  MTRANS_Walking                211 non-null    int8   \n",
      " 20  OLD_Insufficient_Weight       211 non-null    int8   \n",
      " 21  OLD_Normal_Weight             211 non-null    int8   \n",
      " 22  OLD_Obesity_Type_I            211 non-null    int8   \n",
      " 23  OLD_Obesity_Type_II           211 non-null    int8   \n",
      " 24  OLD_Obesity_Type_III          211 non-null    int8   \n",
      " 25  OLD_Overweight_Level_I        211 non-null    int8   \n",
      " 26  OLD_Overweight_Level_II       211 non-null    int8   \n",
      "dtypes: float64(10), int8(17)\n",
      "memory usage: 21.6 KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's verify that there are no missing values in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender_Female                   0\n",
       "Gender_Male                     0\n",
       "Age                             0\n",
       "Height                          0\n",
       "Weight                          0\n",
       "FHWO                            0\n",
       "FAVC                            0\n",
       "FCVC                            0\n",
       "NCP                             0\n",
       "CAEC                            0\n",
       "SMOKE                           0\n",
       "CH2O                            0\n",
       "SCC                             0\n",
       "FAF                             0\n",
       "TUE                             0\n",
       "CALC                            0\n",
       "MTRANS_Automobile               0\n",
       "MTRANS_Motorbike                0\n",
       "MTRANS_Public_Transportation    0\n",
       "MTRANS_Walking                  0\n",
       "OLD_Insufficient_Weight         0\n",
       "OLD_Normal_Weight               0\n",
       "OLD_Obesity_Type_I              0\n",
       "OLD_Obesity_Type_II             0\n",
       "OLD_Obesity_Type_III            0\n",
       "OLD_Overweight_Level_I          0\n",
       "OLD_Overweight_Level_II         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll ensure that there are no duplicated records in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.drop_duplicates()\n",
    "dataset.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we need to split our dataset into two distinct datasets, one for the training process and the other for the tests process. Then write them in separate files to allow them to be used by the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of records:\t207\n",
      "Number of records for training:\t155\n",
      "Number of records for testing:\t52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nRecords = dataset.shape[0]\n",
    "trainSplit = int(0.75 * nRecords)\n",
    "\n",
    "trainds = dataset.iloc[:trainSplit, :]\n",
    "testds = dataset.iloc[trainSplit:, :]\n",
    "\n",
    "print(\n",
    "f\"\"\"\n",
    "Total number of records:\\t{nRecords}\n",
    "Number of records for training:\\t{trainds.shape[0]}\n",
    "Number of records for testing:\\t{testds.shape[0]}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# We are writing TXT format to comply with our random forest algorithm\n",
    "rootDir = \"data/OCDDataset/\"\n",
    "trainDataFile = \"train_dataset.txt\"\n",
    "testDataFile = \"test_dataset.txt\"\n",
    "\n",
    "trainds.to_csv(rootDir + trainDataFile, header=False, index=False)\n",
    "testds.to_csv(rootDir + testDataFile, header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data is ready and checked for any missing or duplicate values, we're all set to move on to the next step. In the upcoming chapter, we'll use our prepared dataset to train our Random Forest model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's dig into the main part of our task: training our model. To do so, we're going to use a type of model called random forests. Random forests are a type of machine learning model that works by creating a multitude of decision trees during training. Each tree independently makes predictions, and the final prediction is determined by averaging the predictions of all the trees (for regression tasks) or taking a majority vote (for classification tasks). \n",
    "\n",
    "In this case, we are going to use our Python program called [randForestsTrn](https://github.com/HES-XPLAIN/dimlpfidex/blob/main/trainings/randForestsTrn.py). Let's begin with importing the script and printing its help message to observe every option available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: \n",
      "--train_data_file <str> --test_data_file <str> --nb_attributes <int [1,inf[> --nb_classes <int [1,inf[> [-h, --help] [--json_config_file <str>] [--root_folder <str>] [--train_class_file <str>] [--train_pred_outfile <str>] [--test_class_file <str>] [--test_pred_outfile <str>] [--console_file <str>] [--stats_file <str>] [--rules_outfile <str>] [--n_estimators <int [1,inf[>] [--criterion <{gini, entropy, log_loss}>] [--max_depth <int [1,inf[>] [--min_samples_split <int [2,inf[ U float]0,1.0]>] [--min_samples_leaf <int [1,inf[ U float]0,1[>] [--min_weight_fraction_leaf <float [0,0.5]>] [--max_features <{sqrt, log2, all, float ]0,1[, int [1,inf[}>] [--max_leaf_nodes <int [2,inf[>] [--min_impurity_decrease <float [0,inf[>] [--bootstrap <bool>] [--oob_score <bool>] [--n_jobs <int>] [--seed <{int [0,inf[}>] [--verbose <int [0,inf[>] [--warm_start <bool>] [--class_weight <{balanced, dict}>] [--ccp_alpha <float [0,inf[>] [--max_samples <int [1,inf[ U float]0,1.0]>]\n",
      "\n",
      "This is a parser for randForestsTrn\n",
      "\n",
      "\n",
      "Parameters:\n",
      "\n",
      "  ---------------------------------------------------------------------\n",
      "\n",
      "  Warning! The files are localised with respect to root folder dimlpfidex.\n",
      "\n",
      "  The arguments can be specified in the command or in a json configuration file with --json_config_file your_config_file.json.\n",
      "\n",
      "  ----------------------------\n",
      "\n",
      "  Required parameters:\n",
      "\n",
      "  --train_data_file <str>                                   Train data file\n",
      "  --test_data_file <str>                                    Test data file\n",
      "  --nb_attributes <int [1,inf[>                             Number of attributes in dataset\n",
      "  --nb_classes <int [1,inf[>                                Number of classes in dataset\n",
      "\n",
      "  ----------------------------\n",
      "\n",
      "  Optional parameters:\n",
      "\n",
      "  -h --help                                                 show this help message and exit\n",
      "  --json_config_file <str>                                  JSON file to configure all parameters. If used, this must be the sole argument and must\n",
      "                                                            specify the file's relative path\n",
      "  --root_folder <str>                                       Folder based on main folder dimlpfidex(default folder) containg all used files and where\n",
      "                                                            generated files will be saved. If a file name is specified with another option, his path\n",
      "                                                            will be configured with respect to this root folder> (default: \"\")\n",
      "  --train_class_file <str>                                  Train class file, mandatory if classes are not specified in train_data_file\n",
      "  --train_pred_outfile <str>                                Output train prediction file name (default: predTrain.out)\n",
      "  --test_class_file <str>                                   Test class file, mandatory if classes are not specified in test_data_file\n",
      "  --test_pred_outfile <str>                                 Output test prediction file name (default: predTest.out)\n",
      "  --console_file <str>                                      File with console logs redirection\n",
      "  --stats_file <str>                                        Output statistic file name with train and test accuracy (default: stats.txt)\n",
      "  --rules_outfile <str>                                     Output random forests rules file (default: RF_rules.rls)\n",
      "\n",
      "  ----------------------------\n",
      "\n",
      "  RF parameters (optional):\n",
      "\n",
      "  --n_estimators <int [1,inf[>                              Number of generated trees in the forest (default: 100)\n",
      "  --criterion <{gini, entropy, log_loss}>                   Function to measure split quality (default: gini)\n",
      "  --max_depth <int [1,inf[>                                 Maximum depth of the tree\n",
      "  --min_samples_split <int [2,inf[ U float]0,1.0]>          Minimum number of samples required to split an internal node, if float, it is a fraction\n",
      "                                                            of the number of samples. (default: 2)\n",
      "  --min_samples_leaf <int [1,inf[ U float]0,1[>             Minimum number of samples required to be at a leaf node, if float, it is a fraction of the\n",
      "                                                            number of samples (default: 1)\n",
      "  --min_weight_fraction_leaf <float [0,0.5]>                Minimum weighted fraction of the sum total of input samples weights required to be at a\n",
      "                                                            leaf node (default: 0.0)\n",
      "  --max_features <{sqrt, log2, all, float ]0,1[, int [1,inf[}>\n",
      "                                                            Number of features to consider when looking for the best splitif float, it is a fraction\n",
      "                                                            of the number of features. 1 stands for 1 feature, for all features put 'all', not 1.0\n",
      "                                                            (default: sqrt)\n",
      "  --max_leaf_nodes <int [2,inf[>                            Grow trees with max_leaf_nodes in best-first fashion\n",
      "  --min_impurity_decrease <float [0,inf[>                   A node will be split if this split induces a decrease of the impurity greater than or\n",
      "                                                            equal to this value (default: 0.0)\n",
      "  --bootstrap <bool>                                        Whether bootstrap samples are used when building trees (default: True)\n",
      "  --oob_score <bool>                                        Whether to use out-of-bag samples to estimate the generalization score (default: False)\n",
      "  --n_jobs <int>                                            Number of jobs to run in parallel, -1 = using all processors (default: 1)\n",
      "  --seed <{int [0,inf[}>                                    Random seed\n",
      "  --verbose <int [0,inf[>                                   Controls the verbosity when fitting and predicting (default: 0)\n",
      "  --warm_start <bool>                                       Whether to reuse the solution of the previous call to fit and add more estimators to the\n",
      "                                                            ensemble (default: False)\n",
      "  --class_weight <{balanced, dict}>                         Class balance, for exemple with a dictionnary and 2 classes : {0:1.2, 1:3.5}\n",
      "  --ccp_alpha <float [0,inf[>                               Complexity parameter used for Minimal Cost-Complexity Pruning (default: 0.0)\n",
      "  --max_samples <int [1,inf[ U float]0,1.0]>                Number of samples to draw to train each base estimator for bootstrap, if float, it is a\n",
      "                                                            fraction of the number of samples\n",
      "\n",
      "  ----------------------------\n",
      "\n",
      "Execution example :\n",
      "\n",
      "randForestsTrn('--train_data_file datanormTrain.txt --train_class_file dataclass2Train.txt --test_data_file datanormTest.txt --test_class_file dataclass2Test.txt --stats_file rf/stats.txt --train_pred_outfile rf/predTrain.out --test_pred_outfile rf/predTest.out --rules_outfile rf/RF_rules.rls --nb_attributes 16 --nb_classes 2 --root_folder dimlp/datafiles')\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "status = randomForest(\"--help\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output shows several options available. From all those, we're going to focus on the required parameters (and the `--root_folder` for convenience purposes) only. We already have the train and test data files (generated in the last chapter). Now we just have to get the number of attributes and number of classes. As we know, the original class is `OLD`, as it has been one hotted. We need to count the number of labels with the `OLD` prefix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# attributes:\t20\n",
      "# classes:\t7\n"
     ]
    }
   ],
   "source": [
    "labels = list(dataset.columns)\n",
    "\n",
    "nclasses = sum(1 for label in labels if label.startswith(\"OLD_\"))\n",
    "nattributes = len(labels) - nclasses\n",
    "attributesFile = \"attributes_file.txt\" \n",
    "\n",
    "\n",
    "with open(rootDir+attributesFile, 'w') as af:\n",
    "    for label in dataset.columns:\n",
    "        af.write(label+'\\n')\n",
    "\n",
    "print(f\"# attributes:\\t{nattributes}\\n# classes:\\t{nclasses}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now, let's gather the elements we have to run the model:\n",
    "\n",
    "| **Parameter name** | **Input**           |\n",
    "|--------------------|:-------------------:|\n",
    "| --root_folder      | data/OCDDataset/    |\n",
    "| --train_data_file  | train_dataset.txt   |\n",
    "| --test_data_file   | test_dataset.txt    |\n",
    "| --nb_attributes    | 21\\*                |\n",
    "| --nb_classes       | 7\\*                 |\n",
    "\n",
    "<br>\n",
    "\n",
    "> *\\*these values depend on the portion of the dataset used and therefore can vary.*\n",
    "\n",
    "We can now try to run our random forest model with it and let the rest of the options be decided be the defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters list:\n",
      " - root_folder                                                   data/OCDDataset/\n",
      " - train_data_file                                               data/OCDDataset/train_dataset.txt\n",
      " - train_pred_outfile                                            data/OCDDataset/predTrain.out\n",
      " - test_data_file                                                data/OCDDataset/test_dataset.txt\n",
      " - test_pred_outfile                                             data/OCDDataset/predTest.out\n",
      " - stats_file                                                    data/OCDDataset/stats.txt\n",
      " - nb_attributes                                                 20\n",
      " - nb_classes                                                    7\n",
      " - rules_outfile                                                 data/OCDDataset/RF_rules.rls\n",
      " - n_estimators                                                  100\n",
      " - criterion                                                     gini\n",
      " - min_samples_split                                             2\n",
      " - min_samples_leaf                                              1\n",
      " - min_weight_fraction_leaf                                      0.0\n",
      " - max_features                                                  sqrt\n",
      " - min_impurity_decrease                                         0.0\n",
      " - bootstrap                                                     True\n",
      " - oob_score                                                     False\n",
      " - n_jobs                                                        1\n",
      " - verbose                                                       0\n",
      " - warm_start                                                    False\n",
      " - ccp_alpha                                                     0.0\n",
      "End of Parameters list. \n",
      "\n",
      "Training accuracy : 100%.\n",
      "Testing accuracy : 78.846154%.\n",
      "\n",
      "Full execution time = 0.19473 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = f\"\"\"\n",
    "        --root_folder {rootDir} \n",
    "        --train_data_file {trainDataFile} \n",
    "        --test_data_file {testDataFile} \n",
    "        --nb_attributes {nattributes} \n",
    "        --nb_classes {nclasses}\n",
    "        \"\"\"\n",
    "\n",
    "randomForest(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm ended and generated a `rule_outfile` file. It contains all rules generated by each tree from the random forest. Lets visualize some of the first tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "Tree 1\n",
      "-------------------\n",
      "Rule 1: X14<=0.9830904901027679 X1<=0.5 X2<=27.381468772888184 X12<=0.5 X6<=0.5 -> class 0 Covering: [1, 0, 0, 0, 0, 0, 0]\n",
      "Rule 2: X14<=0.9830904901027679 X1<=0.5 X2<=27.381468772888184 X12<=0.5 X6>0.5 X14<=0.1172655001282692 X4<=67.45890808105469 -> class 0 Covering: [1, 0, 0, 0, 0, 0, 0]\n",
      "Rule 3: X14<=0.9830904901027679 X1<=0.5 X2<=27.381468772888184 X12<=0.5 X6>0.5 X14<=0.1172655001282692 X4>67.45890808105469 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 4: X14<=0.9830904901027679 X1<=0.5 X2<=27.381468772888184 X12<=0.5 X6>0.5 X14>0.1172655001282692 X13<=2.223442018032074 X4<=97.435546875 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 5: X14<=0.9830904901027679 X1<=0.5 X2<=27.381468772888184 X12<=0.5 X6>0.5 X14>0.1172655001282692 X13<=2.223442018032074 X4>97.435546875 -> class 4 Covering: [0, 0, 0, 0, 1, 0, 0]\n",
      "Rule 6: X14<=0.9830904901027679 X1<=0.5 X2<=27.381468772888184 X12<=0.5 X6>0.5 X14>0.1172655001282692 X13>2.223442018032074 -> class 0 Covering: [1, 0, 0, 0, 0, 0, 0]\n",
      "Rule 7: X14<=0.9830904901027679 X1<=0.5 X2<=27.381468772888184 X12>0.5 X11<=1.5 -> class 0 Covering: [1, 0, 0, 0, 0, 0, 0]\n",
      "Rule 8: X14<=0.9830904901027679 X1<=0.5 X2<=27.381468772888184 X12>0.5 X11>1.5 -> class 1 Covering: [0, 1, 0, 0, 0, 0, 0]\n",
      "Rule 9: X14<=0.9830904901027679 X1<=0.5 X2>27.381468772888184 X11<=1.234495997428894 -> class 5 Covering: [0, 0, 0, 0, 0, 1, 0]\n",
      "Rule 10: X14<=0.9830904901027679 X1<=0.5 X2>27.381468772888184 X11>1.234495997428894 X10<=0.5 X8<=1.7912955284118652 X18<=0.5 -> class 6 Covering: [0, 0, 0, 0, 0, 0, 1]\n",
      "Rule 11: X14<=0.9830904901027679 X1<=0.5 X2>27.381468772888184 X11>1.234495997428894 X10<=0.5 X8<=1.7912955284118652 X18>0.5 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 12: X14<=0.9830904901027679 X1<=0.5 X2>27.381468772888184 X11>1.234495997428894 X10<=0.5 X8>1.7912955284118652 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 13: X14<=0.9830904901027679 X1<=0.5 X2>27.381468772888184 X11>1.234495997428894 X10>0.5 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 14: X14<=0.9830904901027679 X1>0.5 X9<=0.16500000655651093 -> class 5 Covering: [0, 0, 0, 0, 0, 1, 0]\n",
      "Rule 15: X14<=0.9830904901027679 X1>0.5 X9>0.16500000655651093 X8<=3.8779879808425903 X7<=2.227868437767029 X15<=0.16500000655651093 X2<=24.39688491821289 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 16: X14<=0.9830904901027679 X1>0.5 X9>0.16500000655651093 X8<=3.8779879808425903 X7<=2.227868437767029 X15<=0.16500000655651093 X2>24.39688491821289 X13<=1.355947494506836 -> class 6 Covering: [0, 0, 0, 0, 0, 0, 1]\n",
      "Rule 17: X14<=0.9830904901027679 X1>0.5 X9>0.16500000655651093 X8<=3.8779879808425903 X7<=2.227868437767029 X15<=0.16500000655651093 X2>24.39688491821289 X13>1.355947494506836 -> class 3 Covering: [0, 0, 0, 1, 0, 0, 0]\n",
      "Rule 18: X14<=0.9830904901027679 X1>0.5 X9>0.16500000655651093 X8<=3.8779879808425903 X7<=2.227868437767029 X15>0.16500000655651093 X8<=2.9502545595169067 X4<=101.00462341308594 -> class 6 Covering: [0, 0, 0, 0, 0, 0, 1]\n",
      "Rule 19: X14<=0.9830904901027679 X1>0.5 X9>0.16500000655651093 X8<=3.8779879808425903 X7<=2.227868437767029 X15>0.16500000655651093 X8<=2.9502545595169067 X4>101.00462341308594 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 20: X14<=0.9830904901027679 X1>0.5 X9>0.16500000655651093 X8<=3.8779879808425903 X7<=2.227868437767029 X15>0.16500000655651093 X8>2.9502545595169067 X15<=0.4950000196695328 X7<=2.0475159883499146 X2<=35.44656848907471 -> class 3 Covering: [0, 0, 0, 1, 0, 0, 0]\n",
      "Rule 21: X14<=0.9830904901027679 X1>0.5 X9>0.16500000655651093 X8<=3.8779879808425903 X7<=2.227868437767029 X15>0.16500000655651093 X8>2.9502545595169067 X15<=0.4950000196695328 X7<=2.0475159883499146 X2>35.44656848907471 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 22: X14<=0.9830904901027679 X1>0.5 X9>0.16500000655651093 X8<=3.8779879808425903 X7<=2.227868437767029 X15>0.16500000655651093 X8>2.9502545595169067 X15<=0.4950000196695328 X7>2.0475159883499146 X4<=95.362548828125 -> class 5 Covering: [0, 0, 0, 0, 0, 1, 0]\n",
      "Rule 23: X14<=0.9830904901027679 X1>0.5 X9>0.16500000655651093 X8<=3.8779879808425903 X7<=2.227868437767029 X15>0.16500000655651093 X8>2.9502545595169067 X15<=0.4950000196695328 X7>2.0475159883499146 X4>95.362548828125 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 24: X14<=0.9830904901027679 X1>0.5 X9>0.16500000655651093 X8<=3.8779879808425903 X7<=2.227868437767029 X15>0.16500000655651093 X8>2.9502545595169067 X15>0.4950000196695328 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 25: X14<=0.9830904901027679 X1>0.5 X9>0.16500000655651093 X8<=3.8779879808425903 X7>2.227868437767029 X4<=92.99563598632812 X17<=0.5 X14<=0.0446770004928112 -> class 1 Covering: [0, 1, 0, 0, 0, 0, 0]\n",
      "Rule 26: X14<=0.9830904901027679 X1>0.5 X9>0.16500000655651093 X8<=3.8779879808425903 X7>2.227868437767029 X4<=92.99563598632812 X17<=0.5 X14>0.0446770004928112 -> class 6 Covering: [0, 0, 0, 0, 0, 0, 1]\n",
      "Rule 27: X14<=0.9830904901027679 X1>0.5 X9>0.16500000655651093 X8<=3.8779879808425903 X7>2.227868437767029 X4<=92.99563598632812 X17>0.5 -> class 1 Covering: [0, 1, 0, 0, 0, 0, 0]\n",
      "Rule 28: X14<=0.9830904901027679 X1>0.5 X9>0.16500000655651093 X8<=3.8779879808425903 X7>2.227868437767029 X4>92.99563598632812 X11<=2.8202414512634277 -> class 3 Covering: [0, 0, 0, 1, 0, 0, 0]\n",
      "Rule 29: X14<=0.9830904901027679 X1>0.5 X9>0.16500000655651093 X8<=3.8779879808425903 X7>2.227868437767029 X4>92.99563598632812 X11>2.8202414512634277 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 30: X14<=0.9830904901027679 X1>0.5 X9>0.16500000655651093 X8>3.8779879808425903 -> class 0 Covering: [1, 0, 0, 0, 0, 0, 0]\n",
      "Rule 31: X14>0.9830904901027679 X2<=20.621118545532227 X3<=1.655701458454132 X11<=1.6524549722671509 X4<=61.834672927856445 -> class 0 Covering: [1, 0, 0, 0, 0, 0, 0]\n",
      "Rule 32: X14>0.9830904901027679 X2<=20.621118545532227 X3<=1.655701458454132 X11<=1.6524549722671509 X4>61.834672927856445 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 33: X14>0.9830904901027679 X2<=20.621118545532227 X3<=1.655701458454132 X11>1.6524549722671509 -> class 1 Covering: [0, 1, 0, 0, 0, 0, 0]\n",
      "Rule 34: X14>0.9830904901027679 X2<=20.621118545532227 X3>1.655701458454132 X11<=2.9765959978103638 X3<=1.8450340032577515 X14<=1.9412695169448853 X12<=0.5 X2<=19.202280044555664 X4<=72.67442321777344 -> class 0 Covering: [1, 0, 0, 0, 0, 0, 0]\n",
      "Rule 35: X14>0.9830904901027679 X2<=20.621118545532227 X3>1.655701458454132 X11<=2.9765959978103638 X3<=1.8450340032577515 X14<=1.9412695169448853 X12<=0.5 X2<=19.202280044555664 X4>72.67442321777344 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 36: X14>0.9830904901027679 X2<=20.621118545532227 X3>1.655701458454132 X11<=2.9765959978103638 X3<=1.8450340032577515 X14<=1.9412695169448853 X12<=0.5 X2>19.202280044555664 -> class 0 Covering: [1, 0, 0, 0, 0, 0, 0]\n",
      "Rule 37: X14>0.9830904901027679 X2<=20.621118545532227 X3>1.655701458454132 X11<=2.9765959978103638 X3<=1.8450340032577515 X14<=1.9412695169448853 X12>0.5 -> class 1 Covering: [0, 1, 0, 0, 0, 0, 0]\n",
      "Rule 38: X14>0.9830904901027679 X2<=20.621118545532227 X3>1.655701458454132 X11<=2.9765959978103638 X3<=1.8450340032577515 X14>1.9412695169448853 -> class 0 Covering: [1, 0, 0, 0, 0, 0, 0]\n",
      "Rule 39: X14>0.9830904901027679 X2<=20.621118545532227 X3>1.655701458454132 X11<=2.9765959978103638 X3>1.8450340032577515 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 40: X14>0.9830904901027679 X2<=20.621118545532227 X3>1.655701458454132 X11>2.9765959978103638 -> class 5 Covering: [0, 0, 0, 0, 0, 1, 0]\n",
      "Rule 41: X14>0.9830904901027679 X2>20.621118545532227 X4<=77.0 X13<=0.5 -> class 5 Covering: [0, 0, 0, 0, 0, 1, 0]\n",
      "Rule 42: X14>0.9830904901027679 X2>20.621118545532227 X4<=77.0 X13>0.5 -> class 1 Covering: [0, 1, 0, 0, 0, 0, 0]\n",
      "Rule 43: X14>0.9830904901027679 X2>20.621118545532227 X4>77.0 X7<=1.5 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 44: X14>0.9830904901027679 X2>20.621118545532227 X4>77.0 X7>1.5 X2<=28.972684860229492 X15<=0.4950000196695328 X3<=1.706081509590149 -> class 6 Covering: [0, 0, 0, 0, 0, 0, 1]\n",
      "Rule 45: X14>0.9830904901027679 X2>20.621118545532227 X4>77.0 X7>1.5 X2<=28.972684860229492 X15<=0.4950000196695328 X3>1.706081509590149 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 46: X14>0.9830904901027679 X2>20.621118545532227 X4>77.0 X7>1.5 X2<=28.972684860229492 X15>0.4950000196695328 -> class 6 Covering: [0, 0, 0, 0, 0, 0, 1]\n",
      "Rule 47: X14>0.9830904901027679 X2>20.621118545532227 X4>77.0 X7>1.5 X2>28.972684860229492 -> class 3 Covering: [0, 0, 0, 1, 0, 0, 0]\n",
      "-------------------\n",
      "Tree 2\n",
      "-------------------\n",
      "Rule 1: X5<=0.5 X9<=0.4950000196695328 X0<=0.5 X4<=77.0 -> class 5 Covering: [0, 0, 0, 0, 0, 1, 0]\n",
      "Rule 2: X5<=0.5 X9<=0.4950000196695328 X0<=0.5 X4>77.0 -> class 6 Covering: [0, 0, 0, 0, 0, 0, 1]\n",
      "Rule 3: X5<=0.5 X9<=0.4950000196695328 X0>0.5 X2<=19.70449924468994 -> class 0 Covering: [1, 0, 0, 0, 0, 0, 0]\n",
      "Rule 4: X5<=0.5 X9<=0.4950000196695328 X0>0.5 X2>19.70449924468994 X18<=0.5 X2<=23.5 -> class 1 Covering: [0, 1, 0, 0, 0, 0, 0]\n",
      "Rule 5: X5<=0.5 X9<=0.4950000196695328 X0>0.5 X2>19.70449924468994 X18<=0.5 X2>23.5 -> class 5 Covering: [0, 0, 0, 0, 0, 1, 0]\n",
      "Rule 6: X5<=0.5 X9<=0.4950000196695328 X0>0.5 X2>19.70449924468994 X18>0.5 -> class 1 Covering: [0, 1, 0, 0, 0, 0, 0]\n",
      "Rule 7: X5<=0.5 X9>0.4950000196695328 -> class 0 Covering: [1, 0, 0, 0, 0, 0, 0]\n",
      "Rule 8: X5>0.5 X7<=2.9774980545043945 X3<=1.6715120077133179 X8<=3.0351929664611816 X4<=69.40536499023438 -> class 1 Covering: [0, 1, 0, 0, 0, 0, 0]\n",
      "Rule 9: X5>0.5 X7<=2.9774980545043945 X3<=1.6715120077133179 X8<=3.0351929664611816 X4>69.40536499023438 X15<=0.16500000655651093 X4<=80.04326248168945 X0<=0.5 -> class 6 Covering: [0, 0, 0, 0, 0, 0, 1]\n",
      "Rule 10: X5>0.5 X7<=2.9774980545043945 X3<=1.6715120077133179 X8<=3.0351929664611816 X4>69.40536499023438 X15<=0.16500000655651093 X4<=80.04326248168945 X0>0.5 X8<=1.9545584917068481 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 11: X5>0.5 X7<=2.9774980545043945 X3<=1.6715120077133179 X8<=3.0351929664611816 X4>69.40536499023438 X15<=0.16500000655651093 X4<=80.04326248168945 X0>0.5 X8>1.9545584917068481 -> class 6 Covering: [0, 0, 0, 0, 0, 0, 1]\n",
      "Rule 12: X5>0.5 X7<=2.9774980545043945 X3<=1.6715120077133179 X8<=3.0351929664611816 X4>69.40536499023438 X15<=0.16500000655651093 X4>80.04326248168945 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 13: X5>0.5 X7<=2.9774980545043945 X3<=1.6715120077133179 X8<=3.0351929664611816 X4>69.40536499023438 X15>0.16500000655651093 X4<=74.61068725585938 -> class 5 Covering: [0, 0, 0, 0, 0, 1, 0]\n",
      "Rule 14: X5>0.5 X7<=2.9774980545043945 X3<=1.6715120077133179 X8<=3.0351929664611816 X4>69.40536499023438 X15>0.16500000655651093 X4>74.61068725585938 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 15: X5>0.5 X7<=2.9774980545043945 X3<=1.6715120077133179 X8>3.0351929664611816 -> class 6 Covering: [0, 0, 0, 0, 0, 0, 1]\n",
      "Rule 16: X5>0.5 X7<=2.9774980545043945 X3>1.6715120077133179 X10<=0.5 X14<=1.3208835124969482 X8<=1.0896474719047546 X4<=76.5 -> class 1 Covering: [0, 1, 0, 0, 0, 0, 0]\n",
      "Rule 17: X5>0.5 X7<=2.9774980545043945 X3>1.6715120077133179 X10<=0.5 X14<=1.3208835124969482 X8<=1.0896474719047546 X4>76.5 -> class 6 Covering: [0, 0, 0, 0, 0, 0, 1]\n",
      "Rule 18: X5>0.5 X7<=2.9774980545043945 X3>1.6715120077133179 X10<=0.5 X14<=1.3208835124969482 X8>1.0896474719047546 X7<=2.0013920068740845 X13<=1.2705360054969788 X8<=2.8276325464248657 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 19: X5>0.5 X7<=2.9774980545043945 X3>1.6715120077133179 X10<=0.5 X14<=1.3208835124969482 X8>1.0896474719047546 X7<=2.0013920068740845 X13<=1.2705360054969788 X8>2.8276325464248657 X4<=100.43563842773438 X2<=36.0 -> class 6 Covering: [0, 0, 0, 0, 0, 0, 1]\n",
      "Rule 20: X5>0.5 X7<=2.9774980545043945 X3>1.6715120077133179 X10<=0.5 X14<=1.3208835124969482 X8>1.0896474719047546 X7<=2.0013920068740845 X13<=1.2705360054969788 X8>2.8276325464248657 X4<=100.43563842773438 X2>36.0 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 21: X5>0.5 X7<=2.9774980545043945 X3>1.6715120077133179 X10<=0.5 X14<=1.3208835124969482 X8>1.0896474719047546 X7<=2.0013920068740845 X13<=1.2705360054969788 X8>2.8276325464248657 X4>100.43563842773438 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 22: X5>0.5 X7<=2.9774980545043945 X3>1.6715120077133179 X10<=0.5 X14<=1.3208835124969482 X8>1.0896474719047546 X7<=2.0013920068740845 X13>1.2705360054969788 -> class 3 Covering: [0, 0, 0, 1, 0, 0, 0]\n",
      "Rule 23: X5>0.5 X7<=2.9774980545043945 X3>1.6715120077133179 X10<=0.5 X14<=1.3208835124969482 X8>1.0896474719047546 X7>2.0013920068740845 X9<=0.4950000196695328 X16<=0.5 X7<=2.229333996772766 X3<=1.7275710105895996 -> class 6 Covering: [0, 0, 0, 0, 0, 0, 1]\n",
      "Rule 24: X5>0.5 X7<=2.9774980545043945 X3>1.6715120077133179 X10<=0.5 X14<=1.3208835124969482 X8>1.0896474719047546 X7>2.0013920068740845 X9<=0.4950000196695328 X16<=0.5 X7<=2.229333996772766 X3>1.7275710105895996 X11<=1.6381794810295105 -> class 6 Covering: [0, 0, 0, 0, 0, 0, 1]\n",
      "Rule 25: X5>0.5 X7<=2.9774980545043945 X3>1.6715120077133179 X10<=0.5 X14<=1.3208835124969482 X8>1.0896474719047546 X7>2.0013920068740845 X9<=0.4950000196695328 X16<=0.5 X7<=2.229333996772766 X3>1.7275710105895996 X11>1.6381794810295105 -> class 3 Covering: [0, 0, 0, 1, 0, 0, 0]\n",
      "Rule 26: X5>0.5 X7<=2.9774980545043945 X3>1.6715120077133179 X10<=0.5 X14<=1.3208835124969482 X8>1.0896474719047546 X7>2.0013920068740845 X9<=0.4950000196695328 X16<=0.5 X7>2.229333996772766 -> class 3 Covering: [0, 0, 0, 1, 0, 0, 0]\n",
      "Rule 27: X5>0.5 X7<=2.9774980545043945 X3>1.6715120077133179 X10<=0.5 X14<=1.3208835124969482 X8>1.0896474719047546 X7>2.0013920068740845 X9<=0.4950000196695328 X16>0.5 X4<=105.28703308105469 X7<=2.5998140573501587 -> class 0 Covering: [1, 0, 0, 0, 0, 0, 0]\n",
      "Rule 28: X5>0.5 X7<=2.9774980545043945 X3>1.6715120077133179 X10<=0.5 X14<=1.3208835124969482 X8>1.0896474719047546 X7>2.0013920068740845 X9<=0.4950000196695328 X16>0.5 X4<=105.28703308105469 X7>2.5998140573501587 X14<=0.7089794874191284 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 29: X5>0.5 X7<=2.9774980545043945 X3>1.6715120077133179 X10<=0.5 X14<=1.3208835124969482 X8>1.0896474719047546 X7>2.0013920068740845 X9<=0.4950000196695328 X16>0.5 X4<=105.28703308105469 X7>2.5998140573501587 X14>0.7089794874191284 -> class 6 Covering: [0, 0, 0, 0, 0, 0, 1]\n",
      "Rule 30: X5>0.5 X7<=2.9774980545043945 X3>1.6715120077133179 X10<=0.5 X14<=1.3208835124969482 X8>1.0896474719047546 X7>2.0013920068740845 X9<=0.4950000196695328 X16>0.5 X4>105.28703308105469 X13<=1.7001954913139343 -> class 3 Covering: [0, 0, 0, 1, 0, 0, 0]\n",
      "Rule 31: X5>0.5 X7<=2.9774980545043945 X3>1.6715120077133179 X10<=0.5 X14<=1.3208835124969482 X8>1.0896474719047546 X7>2.0013920068740845 X9<=0.4950000196695328 X16>0.5 X4>105.28703308105469 X13>1.7001954913139343 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 32: X5>0.5 X7<=2.9774980545043945 X3>1.6715120077133179 X10<=0.5 X14<=1.3208835124969482 X8>1.0896474719047546 X7>2.0013920068740845 X9>0.4950000196695328 -> class 0 Covering: [1, 0, 0, 0, 0, 0, 0]\n",
      "Rule 33: X5>0.5 X7<=2.9774980545043945 X3>1.6715120077133179 X10<=0.5 X14>1.3208835124969482 X8<=2.7135684490203857 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 34: X5>0.5 X7<=2.9774980545043945 X3>1.6715120077133179 X10<=0.5 X14>1.3208835124969482 X8>2.7135684490203857 X15<=0.4950000196695328 -> class 0 Covering: [1, 0, 0, 0, 0, 0, 0]\n",
      "Rule 35: X5>0.5 X7<=2.9774980545043945 X3>1.6715120077133179 X10<=0.5 X14>1.3208835124969482 X8>2.7135684490203857 X15>0.4950000196695328 -> class 5 Covering: [0, 0, 0, 0, 0, 1, 0]\n",
      "Rule 36: X5>0.5 X7<=2.9774980545043945 X3>1.6715120077133179 X10>0.5 X2<=24.597161293029785 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 37: X5>0.5 X7<=2.9774980545043945 X3>1.6715120077133179 X10>0.5 X2>24.597161293029785 -> class 3 Covering: [0, 0, 0, 1, 0, 0, 0]\n",
      "Rule 38: X5>0.5 X7>2.9774980545043945 X11<=2.26488196849823 X10<=0.5 X13<=1.9085935354232788 X19<=0.5 X15<=0.4950000196695328 X8<=2.0685750246047974 -> class 5 Covering: [0, 0, 0, 0, 0, 1, 0]\n",
      "Rule 39: X5>0.5 X7>2.9774980545043945 X11<=2.26488196849823 X10<=0.5 X13<=1.9085935354232788 X19<=0.5 X15<=0.4950000196695328 X8>2.0685750246047974 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 40: X5>0.5 X7>2.9774980545043945 X11<=2.26488196849823 X10<=0.5 X13<=1.9085935354232788 X19<=0.5 X15>0.4950000196695328 -> class 1 Covering: [0, 1, 0, 0, 0, 0, 0]\n",
      "Rule 41: X5>0.5 X7>2.9774980545043945 X11<=2.26488196849823 X10<=0.5 X13<=1.9085935354232788 X19>0.5 -> class 1 Covering: [0, 1, 0, 0, 0, 0, 0]\n",
      "Rule 42: X5>0.5 X7>2.9774980545043945 X11<=2.26488196849823 X10<=0.5 X13>1.9085935354232788 X4<=101.88236236572266 -> class 1 Covering: [0, 1, 0, 0, 0, 0, 0]\n",
      "Rule 43: X5>0.5 X7>2.9774980545043945 X11<=2.26488196849823 X10<=0.5 X13>1.9085935354232788 X4>101.88236236572266 -> class 4 Covering: [0, 0, 0, 0, 1, 0, 0]\n",
      "Rule 44: X5>0.5 X7>2.9774980545043945 X11<=2.26488196849823 X10>0.5 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 45: X5>0.5 X7>2.9774980545043945 X11>2.26488196849823 X9<=0.4950000196695328 -> class 4 Covering: [0, 0, 0, 0, 1, 0, 0]\n",
      "Rule 46: X5>0.5 X7>2.9774980545043945 X11>2.26488196849823 X9>0.4950000196695328 -> class 0 Covering: [1, 0, 0, 0, 0, 0, 0]\n",
      "-------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rulesFile = \"RF_rules.rls\" # if you used the --rules_outfile option when running randomForest(), please don't forget to adapt this according to your input\n",
    "previewFile(rootDir+rulesFile, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output shows us a portion of the newly generated file. It contains all rules generated by each tree of the random forest algorithm. All rules generated seem to be quite similar between them in a single tree. This is totaly normal. (TODO complete and adapt this)\n",
    "\n",
    "Now we trained and generated our set of rules, let's use Fidex to sort them (TODO complete this)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local rules generation - Fidex\n",
    "\n",
    "Now we can generate some `local` rules to explain the model's results. We can start with launching Fidex on one test sample. This will generate a rule explaining the sample locally. It is `local` because the algorithm searches a rule only for one sample.\n",
    "\n",
    "Fidex is located in the fidex module. First of all, let's take a look at the parameters :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "Warning! The files are localised with respect to root folder dimlpfidex.\n",
      "The arguments can be specified in the command or in a json configuration file with --json_config_file your_config_file.json.\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Required parameters:\n",
      "\n",
      "--train_data_file <str>       Train data file\n",
      "--train_pred_file <str>       Train prediction file\n",
      "--train_class_file <str>      Train true class file, not mandatory if classes are specified in train data file\n",
      "--test_data_file <str>        Test sample(s) data file with data, prediction(if no --test_pred_file) and true class(if no --test_class_file)\n",
      "--weights_file <str>          Weights file (not mandatory if a rules file is given with --rules_file)\n",
      "--rules_file <str>            Rules file to be converted to hyperlocus (not mandatory if a weights file is given with --weights_file)\n",
      "--rules_outfile <str>         Rule(s) output file. If a .json filename is given, rules are saved in a special json format\n",
      "--nb_attributes <int [1,inf[> Number of attributes in dataset\n",
      "--nb_classes <int [2,inf[>    Number of classes in dataset\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Optional parameters: \n",
      "\n",
      "--json_config_file <str>      JSON file to configure all parameters. If used, this must be the sole argument and must specify the file's relative path\n",
      "--root_folder <str>           Folder based on main folder dimlpfidex(default folder) containg all used files and where generated files will be saved. If a file name is specified with another option, his path will be configured with respect to this root folder\n",
      "--test_pred_file <str>        Test prediction file\n",
      "--test_class_file <str>       Test true class file. If at least --test_pred_file is specified, --test_data_file needs to have only test datas and eventually classes on same line (don't add --test_class_file in this case)\n",
      "--attributes_file <str>       File of attributes\n",
      "--stats_file <str>            Output statistic file name\n",
      "--console_file <str>          File with console logs redirection\n",
      "--max_iterations <int [1,inf[>\n",
      "                              Max iteration number, also the max possible number of attributs in a rule, should be 25 if working with images (default: 10)\n",
      "--min_covering <int [1,inf[>  Minimum covering number (default: 2)\n",
      "--covering_strategy <bool>    Whether to use this strategy : if no rule is found with min_covering, find best rule with best covering using dichotomic search. Decreases min_fidelity if needed (default: True)\n",
      "--max_failed_attempts <int [0,inf[>\n",
      "                              Maximum number of failed attempts to find Fidex rule when covering is 1 and covering strategy is used (default: 30)\n",
      "--min_fidelity <float [0,1]>  Minimal rule fidelity accepted when generating a rule (default: 1.0)\n",
      "--lowest_min_fidelity <float [0,1]>\n",
      "                              Minimal min_fidelity to which we agree to go down during covering_strategy (default: 0.75)\n",
      "--dropout_dim <float [0,1]>   Dimension dropout parameter (default: 0.0)\n",
      "--dropout_hyp <float [0,1]>   Hyperplan dropout parameter (default: 0.0)\n",
      "--nb_quant_levels <int [3,inf[>\n",
      "                              Number of stairs in staircase activation function (default: 50)\n",
      "--decision_threshold <float [0,1]>\n",
      "                              Decision threshold for predictions, you need to specify the index of positive class if you want to use it\n",
      "--positive_class_index <int [0,nb_classes-1]>\n",
      "                              Index of positive class for the usage of decision threshold, index starts at 0\n",
      "--normalization_file <str>    File containing the mean and std of some attributes. Used to denormalize the rules if specified\n",
      "--mus <list<float ]inf,inf[>> Mean or median of each attribute index to denormalize in the rules\n",
      "--sigmas <list<float ]inf,inf[>>\n",
      "                              Standard deviation of each attribute index to denormalize in the rules\n",
      "--normalization_indices <list<int [0,nb_attributes-1]>>\n",
      "                              Attribute indices to denormalize in the rules, only used when no normalization_file is given, index starts at 0 (default: [0,...,nb_attributes-1])\n",
      "--seed <int [0,inf[>          Seed, 0=random (default: 0)\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Execution example :\n",
      "\n",
      "fidex.fidex(\"--train_data_file datanormTrain.txt --train_pred_file predTrain.out --train_class_file dataclass2Train.txt --test_data_file testSampleDataCombine.txt --nb_attributes 16 --nb_classes 2 --weights_file weights.wts --rules_outfile rules.rls --stats_file stats.txt --root_folder dimlp/datafiles\")\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "status = fidex(\"--help\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a closer look at the Fidex help output. We can observe that there are `required parameters`. Let's have a look on them:\n",
    "\n",
    "- `--train_data_file`: a file containing features from the training portion of the dataset\n",
    "- `--train_pred_file`: a file containing predictions from the training portion of the dataset\n",
    "- `--train_class_file`: a file containing classes from the training portion of the dataset\n",
    "- `--test_data_file`: a file containing samples to be used when generating a local rule\n",
    "- `--weights_file`: a file containing weights from a model training (in our case, we don't need it because we already have a `rules file` from the RF training)\n",
    "- `--rules_file`: a file containing the rules generated by a model training \n",
    "- `--rules_outfile`: a file name that will contain the output of the Fidex algorithm\n",
    "- `--nb_attributes`: the number of attributes present in the dataset\n",
    "- `--nb_classes`: the number of classes present in the dataset\n",
    "\n",
    "There are also optional arguments that we are going to use:\n",
    "- `--root_folder`: path defining the root directory where every other path specified in other arguments begins\n",
    "- `--attributes_file`: a file containing all attributes and class names\n",
    "\n",
    "All steps done until now will allow us to run the Fidex program. To see what happens, we launch it with just one sample, and we save beforehand the test data sample in a file with its classes and predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters list:\n",
      " - train_data_file                                                    data/OCDDataset/train_dataset.txt\n",
      " - train_pred_file                                                        data/OCDDataset/predTrain.out\n",
      " - test_data_file                                                       data/OCDDataset/test_sample.txt\n",
      " - rules_file                                                              data/OCDDataset/RF_rules.rls\n",
      " - rules_outfile                                                        data/OCDDataset/fidex_rules.rls\n",
      " - root_folder                                                                         data/OCDDataset/\n",
      " - attributes_file                                                  data/OCDDataset/attributes_file.txt\n",
      " - nb_attributes                                                                                     20\n",
      " - nb_classes                                                                                         7\n",
      " - nb_quant_levels                                                                                   50\n",
      " - max_iterations                                                                                    10\n",
      " - min_covering                                                                                       2\n",
      " - max_failed_attempts                                                                               30\n",
      " - positive_class_index                                                                              -1\n",
      " - seed                                                                                               0\n",
      " - decision_threshold                                                                         -1.000000\n",
      " - hi_knot                                                                                     5.000000\n",
      " - dropout_hyp                                                                                 0.000000\n",
      " - dropout_dim                                                                                 0.000000\n",
      " - min_fidelity                                                                                1.000000\n",
      " - lowest_min_fidelity                                                                         0.750000\n",
      " - covering_strategy                                                                                  1\n",
      "End of Parameters list.\n",
      "\n",
      "Import files...\n",
      "\n",
      "Import time = 0.041146 sec\n",
      "Files imported\n",
      "\n",
      "----------------------------------------------\n",
      "\n",
      "Creation of hyperspace...\n",
      "Hyperspace created\n",
      "\n",
      "Searching for discriminating hyperplans...\n",
      "Initial fidelity : 0.206452\n",
      "Final fidelity : 1\n",
      "Discriminating hyperplans generated.\n",
      "\n",
      "\n",
      "Extracted rule :\n",
      "Height>=1.779662 Height<1.78706 Height>=1.780288 -> OLD_Obesity_Type_I\n",
      "   Train Covering size : 3\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.7675\n",
      "\n",
      "Result found after 3 iterations.\n",
      "-------------------------------------------------\n",
      "\n",
      "Time without data import = 0.109829 sec\n",
      "\n",
      "Full execution time = 0.153752 sec\n"
     ]
    }
   ],
   "source": [
    "localRuleOutFileName = \"fidex_rules.rls\"\n",
    "trainClassesFile = \"train_classes.txt\"\n",
    "trainPredsFile = \"predTrain.out\" # generated by the RF\n",
    "testPredsFile = \"predTest.out\" # generated by the RF\n",
    "testSampleFile = \"test_sample.txt\"\n",
    "\n",
    "sampleSelected = 0\n",
    "assert(sampleSelected < nrows)\n",
    "\n",
    "\n",
    "# extract a sample to generate local rule\n",
    "testPreds = pd.read_csv(rootDir+testPredsFile, sep=\" \", header=None, index_col=None).iloc[:, :nclasses]\n",
    "sampleData = testds.iloc[sampleSelected, :nattributes].to_list()\n",
    "samplePred = testPreds.iloc[sampleSelected, :].to_list()\n",
    "sampleClasses = testds.iloc[sampleSelected, nattributes:].to_list()\n",
    "\n",
    "# write the sample, classes and predictions in the testSampleFile file (file writing format must be respected)\n",
    "with open(rootDir+testSampleFile, 'w') as f:\n",
    "    f.write(\" \".join(str(x) for x in sampleData) + '\\n')\n",
    "    f.write(\" \".join(str(x) for x in samplePred) + '\\n')\n",
    "    f.write(\" \".join(str(x) for x in sampleClasses) + '\\n')\n",
    "\n",
    "args = f\"\"\"\n",
    "        --root_folder {rootDir} \n",
    "        --train_data_file {trainDataFile} \n",
    "        --train_pred_file {trainPredsFile} \n",
    "        --test_data_file {testSampleFile}  \n",
    "        --rules_file {rulesFile} \n",
    "        --rules_outfile {localRuleOutFileName} \n",
    "        --nb_attributes {nattributes} \n",
    "        --attributes_file {attributesFile} \n",
    "        --nb_classes {nclasses}\n",
    "        \"\"\"\n",
    "\n",
    "status = fidex(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the algorithm shows us, in the terminal, a walkthrough of the process. At the end of it, you can observe the generated rule. Let's have a closer look to it by extracting the freshly written rule file: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No decision threshold is used.\n",
      "\n",
      "Rule for sample 0 :\n",
      "\n",
      "Height>=1.779662 Height<1.78706 Height>=1.780288 -> OLD_Obesity_Type_I\n",
      "   Train Covering size : 3\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.7675\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "previewFile(rootDir+localRuleOutFileName, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A rule is composed of several properties:\n",
    "- The index of the sample from which the rule has been generated\n",
    "- The rule itself, composed of a single or list of antecedents\n",
    "- The number of samples, in the training dataset, covered by the rule\n",
    "- The fidelity of the rule according to the model's predictions\n",
    "- The accuracy of the rule\n",
    "- The confidence of the rule with its choices, concerning the prediction values\n",
    "\n",
    "Let's try to run Fidex again, but this time, with all the samples (please take note that this process can take some time and highly varies depending on the dataset size):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters list:\n",
      " - train_data_file                                                    data/OCDDataset/train_dataset.txt\n",
      " - train_pred_file                                                        data/OCDDataset/predTrain.out\n",
      " - test_data_file                                                      data/OCDDataset/test_dataset.txt\n",
      " - test_pred_file                                                          data/OCDDataset/predTest.out\n",
      " - rules_file                                                              data/OCDDataset/RF_rules.rls\n",
      " - rules_outfile                                                        data/OCDDataset/fidex_rules.rls\n",
      " - root_folder                                                                         data/OCDDataset/\n",
      " - attributes_file                                                  data/OCDDataset/attributes_file.txt\n",
      " - nb_attributes                                                                                     20\n",
      " - nb_classes                                                                                         7\n",
      " - nb_quant_levels                                                                                   50\n",
      " - max_iterations                                                                                    10\n",
      " - min_covering                                                                                       2\n",
      " - max_failed_attempts                                                                               30\n",
      " - positive_class_index                                                                              -1\n",
      " - seed                                                                                               0\n",
      " - decision_threshold                                                                         -1.000000\n",
      " - hi_knot                                                                                     5.000000\n",
      " - dropout_hyp                                                                                 0.000000\n",
      " - dropout_dim                                                                                 0.000000\n",
      " - min_fidelity                                                                                1.000000\n",
      " - lowest_min_fidelity                                                                         0.750000\n",
      " - covering_strategy                                                                                  1\n",
      "End of Parameters list.\n",
      "\n",
      "Import files...\n",
      "\n",
      "Import time = 0.029887 sec\n",
      "Files imported\n",
      "\n",
      "----------------------------------------------\n",
      "\n",
      "Creation of hyperspace...\n",
      "Hyperspace created\n",
      "\n",
      "Computation of rule for sample 0 : \n",
      "\n",
      "Initial fidelity : 0.206452\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Height>=1.779662 Height<1.78706 Age>=24.133848 -> OLD_Obesity_Type_I\n",
      "   Train Covering size : 3\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.68\n",
      "\n",
      "Result found after 3 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 1 : \n",
      "\n",
      "Initial fidelity : 0.141935\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight>=130.606071 -> OLD_Obesity_Type_III\n",
      "   Train Covering size : 10\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.977273\n",
      "\n",
      "Result found after 1 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 2 : \n",
      "\n",
      "Initial fidelity : 0.109677\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight<98.18383 Weight>=74.931774 Gender_Female<0.5 Height<1.737498 Age<21.5 -> OLD_Overweight_Level_II\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.586667\n",
      "\n",
      "Result found after 5 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 3 : \n",
      "\n",
      "Initial fidelity : 0.0774194\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "FHWO<0.5 Age>=27.081763 -> OLD_Overweight_Level_I\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.623333\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 4 : \n",
      "\n",
      "Initial fidelity : 0.109677\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Age>=32.5 Age<37.315884 Age>=35.446568 -> OLD_Overweight_Level_II\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.59\n",
      "\n",
      "Result found after 3 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 5 : \n",
      "\n",
      "Initial fidelity : 0.141935\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight>=130.606071 -> OLD_Obesity_Type_III\n",
      "   Train Covering size : 10\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.972727\n",
      "\n",
      "Result found after 1 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 6 : \n",
      "\n",
      "Initial fidelity : 0.141935\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "FCVC>=2.969344 Weight>=95.729191 Gender_Male<0.5 -> OLD_Obesity_Type_III\n",
      "   Train Covering size : 22\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.953043\n",
      "\n",
      "Result found after 3 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 7 : \n",
      "\n",
      "Initial fidelity : 0.206452\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "CH2O>=2.86525 Weight>=85.601612 TUE>=0.180132 -> OLD_Obesity_Type_I\n",
      "   Train Covering size : 4\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.764\n",
      "\n",
      "Result found after 3 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 8 : \n",
      "\n",
      "Initial fidelity : 0.109677\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "MTRANS_Walking>=0.5 Height<1.68 TUE<1.000703 -> OLD_Normal_Weight\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.66\n",
      "\n",
      "Result found after 3 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 9 : \n",
      "\n",
      "Initial fidelity : 0.206452\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "TUE>=1.273543 Weight>=80.5 -> OLD_Obesity_Type_I\n",
      "   Train Covering size : 8\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.878889\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 10 : \n",
      "\n",
      "Initial fidelity : 0.109677\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "CH2O>=2.994694 Age>=22.481475 Weight<85.405804 -> OLD_Overweight_Level_II\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.653333\n",
      "\n",
      "Result found after 3 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 11 : \n",
      "\n",
      "Initial fidelity : 0.206452\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "FCVC<2.001392 Weight>=80.5 Age<23.675585 -> OLD_Obesity_Type_I\n",
      "   Train Covering size : 15\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.87625\n",
      "\n",
      "Result found after 3 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 12 : \n",
      "\n",
      "Initial fidelity : 0.109677\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Age>=32.5 CALC<0.165 FCVC<2.001392 -> OLD_Overweight_Level_II\n",
      "   Train Covering size : 4\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.748\n",
      "\n",
      "Result found after 3 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 13 : \n",
      "\n",
      "Initial fidelity : 0.206452\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Age>=38.324472 Weight<87.5 -> OLD_Obesity_Type_I\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.613333\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 14 : \n",
      "\n",
      "Initial fidelity : 0.141935\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "FCVC>=2.969344 Weight>=97.212196 Height<1.626655 -> OLD_Obesity_Type_III\n",
      "   Train Covering size : 3\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.98\n",
      "\n",
      "Result found after 3 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 15 : \n",
      "\n",
      "Initial fidelity : 0.141935\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight>=130.606071 -> OLD_Obesity_Type_III\n",
      "   Train Covering size : 10\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.972727\n",
      "\n",
      "Result found after 1 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 16 : \n",
      "\n",
      "Initial fidelity : 0.154839\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight>=112.993652 TUE<0.180132 -> OLD_Obesity_Type_II\n",
      "   Train Covering size : 12\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.903846\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 17 : \n",
      "\n",
      "Initial fidelity : 0.109677\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight<98.18383 Weight>=74.931774 Gender_Male>=0.5 Height<1.737498 TUE<0.144609 -> OLD_Overweight_Level_II\n",
      "   Train Covering size : 3\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.6625\n",
      "\n",
      "Result found after 5 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 18 : \n",
      "\n",
      "Initial fidelity : 0.141935\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight>=130.606071 -> OLD_Obesity_Type_III\n",
      "   Train Covering size : 10\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.981818\n",
      "\n",
      "Result found after 1 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 19 : \n",
      "\n",
      "Initial fidelity : 0.141935\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "FCVC>=2.969344 Weight>=105.263416 Weight<110.321526 -> OLD_Obesity_Type_III\n",
      "   Train Covering size : 4\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.96\n",
      "\n",
      "Result found after 3 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 20 : \n",
      "\n",
      "Initial fidelity : 0.206452\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "FCVC<2.001392 Weight>=80.5 Age<23.081763 -> OLD_Obesity_Type_I\n",
      "   Train Covering size : 14\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.885333\n",
      "\n",
      "Result found after 3 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 21 : \n",
      "\n",
      "Initial fidelity : 0.2\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight<50.5 MTRANS_Public_Transportation>=0.5 -> OLD_Insufficient_Weight\n",
      "   Train Covering size : 19\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.914\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 22 : \n",
      "\n",
      "Initial fidelity : 0.141935\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight>=130.606071 -> OLD_Obesity_Type_III\n",
      "   Train Covering size : 10\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.980909\n",
      "\n",
      "Result found after 1 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 23 : \n",
      "\n",
      "Initial fidelity : 0.206452\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "CH2O>=2.86525 Weight>=90.885717 NCP<2.482726 -> OLD_Obesity_Type_I\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.88\n",
      "\n",
      "Result found after 3 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 24 : \n",
      "\n",
      "Initial fidelity : 0.109677\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "SCC>=0.5 Age>=19.15547 -> OLD_Normal_Weight\n",
      "   Train Covering size : 3\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.7075\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 25 : \n",
      "\n",
      "Initial fidelity : 0.206452\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Age>=38.324472 Gender_Female>=0.5 -> OLD_Obesity_Type_I\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.626667\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 26 : \n",
      "\n",
      "Initial fidelity : 0.141935\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "FCVC>=2.969344 Weight>=105.263416 NCP>=2.569188 -> OLD_Obesity_Type_III\n",
      "   Train Covering size : 18\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.965789\n",
      "\n",
      "Result found after 3 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 27 : \n",
      "\n",
      "Initial fidelity : 0.2\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight<50.5 MTRANS_Automobile<0.5 -> OLD_Insufficient_Weight\n",
      "   Train Covering size : 20\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.898095\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 28 : \n",
      "\n",
      "Initial fidelity : 0.109677\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "SCC>=0.5 FHWO>=0.5 -> OLD_Normal_Weight\n",
      "   Train Covering size : 3\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.7325\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 29 : \n",
      "\n",
      "Initial fidelity : 0.154839\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight>=112.993652 FCVC<1.486749 -> OLD_Obesity_Type_II\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.846667\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 30 : \n",
      "\n",
      "Initial fidelity : 0.154839\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight>=100.225933 CH2O<1.000654 -> OLD_Obesity_Type_II\n",
      "   Train Covering size : 4\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.79\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 31 : \n",
      "\n",
      "Initial fidelity : 0.141935\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "FCVC>=2.969344 Weight>=105.263416 NCP>=2.569188 -> OLD_Obesity_Type_III\n",
      "   Train Covering size : 18\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.966842\n",
      "\n",
      "Result found after 3 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 32 : \n",
      "\n",
      "Initial fidelity : 0.206452\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Height>=1.779662 FCVC<2.335054 FAF<0.58558 -> OLD_Obesity_Type_I\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.736667\n",
      "\n",
      "Result found after 3 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 33 : \n",
      "\n",
      "Initial fidelity : 0.141935\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "FCVC>=2.969344 Weight>=105.263416 Gender_Male<0.5 -> OLD_Obesity_Type_III\n",
      "   Train Covering size : 18\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.968947\n",
      "\n",
      "Result found after 3 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 34 : \n",
      "\n",
      "Initial fidelity : 0.206452\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "FCVC<2.001392 Weight>=77 Height<1.601065 -> OLD_Obesity_Type_I\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.706667\n",
      "\n",
      "Result found after 3 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 35 : \n",
      "\n",
      "Initial fidelity : 0.2\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "NCP>=3.870613 -> OLD_Insufficient_Weight\n",
      "   Train Covering size : 6\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.908571\n",
      "\n",
      "Result found after 1 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 36 : \n",
      "\n",
      "Initial fidelity : 0.2\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "NCP>=3.114944 Age<17.435897 -> OLD_Insufficient_Weight\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.956667\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 37 : \n",
      "\n",
      "Initial fidelity : 0.141935\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight>=126.79108 Gender_Female>=0.5 -> OLD_Obesity_Type_III\n",
      "   Train Covering size : 11\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.965\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 38 : \n",
      "\n",
      "Initial fidelity : 0.2\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight<57.511965 NCP>=3.019184 -> OLD_Insufficient_Weight\n",
      "   Train Covering size : 9\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.921\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 39 : \n",
      "\n",
      "Initial fidelity : 0.109677\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Age>=23.5 Age<23.999354 FCVC<2.428203 -> OLD_Overweight_Level_II\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.626667\n",
      "\n",
      "Result found after 3 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 40 : \n",
      "\n",
      "Initial fidelity : 0.109677\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Age>=23.5 Age<23.999354 FCVC<2.428203 -> OLD_Overweight_Level_II\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.673333\n",
      "\n",
      "Result found after 3 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 41 : \n",
      "\n",
      "Initial fidelity : 0.2\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight<57.511965 CH2O>=1.000347 -> OLD_Insufficient_Weight\n",
      "   Train Covering size : 19\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.874\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 42 : \n",
      "\n",
      "Initial fidelity : 0.2\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight<56.578854 Height>=1.633615 -> OLD_Insufficient_Weight\n",
      "   Train Covering size : 16\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.857059\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 43 : \n",
      "\n",
      "Initial fidelity : 0.2\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight<58.621754 Gender_Male>=0.5 -> OLD_Insufficient_Weight\n",
      "   Train Covering size : 6\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.791429\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 44 : \n",
      "\n",
      "Initial fidelity : 0.206452\n",
      "Final fidelity : 0.5\n",
      "Fidelity is too low. Restarting fidex with a minimum covering of 1 and a minimum accepted fidelity of 1.\n",
      "Final fidelity : 1\n",
      "\n",
      "\n",
      "Extracted rule :\n",
      "Height>=1.90976 -> OLD_Obesity_Type_I\n",
      "   Train Covering size : 1\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.83\n",
      "\n",
      "The minimum covering of 2 is not achieved.\n",
      "Result found after 1 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 45 : \n",
      "\n",
      "Initial fidelity : 0.109677\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight<72.926708 Weight>=61.834673 FAF>=1.170991 -> OLD_Normal_Weight\n",
      "   Train Covering size : 3\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.68\n",
      "\n",
      "Result found after 3 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 46 : \n",
      "\n",
      "Initial fidelity : 0.141935\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "FCVC>=2.969344 Weight>=97.212196 Height<1.686895 -> OLD_Obesity_Type_III\n",
      "   Train Covering size : 11\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.965833\n",
      "\n",
      "Result found after 3 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 47 : \n",
      "\n",
      "Initial fidelity : 0.141935\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "FCVC>=2.969344 Weight>=105.263416 Weight<111.004322 -> OLD_Obesity_Type_III\n",
      "   Train Covering size : 4\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.962\n",
      "\n",
      "Result found after 3 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 48 : \n",
      "\n",
      "Initial fidelity : 0.154839\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight>=112.993652 TUE<0.000665 -> OLD_Obesity_Type_II\n",
      "   Train Covering size : 8\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.871111\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 49 : \n",
      "\n",
      "Initial fidelity : 0.154839\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight>=112.993652 NCP<2.827633 -> OLD_Obesity_Type_II\n",
      "   Train Covering size : 4\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.832\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 50 : \n",
      "\n",
      "Initial fidelity : 0.141935\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "FCVC>=2.969344 Weight>=105.263416 Height<1.692476 -> OLD_Obesity_Type_III\n",
      "   Train Covering size : 7\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.96125\n",
      "\n",
      "Result found after 3 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 51 : \n",
      "\n",
      "Initial fidelity : 0.0774194\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "MTRANS_Walking>=0.5 TUE>=1.000703 -> OLD_Overweight_Level_I\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.573333\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "\n",
      "Time without data import = 0.376962 sec\n",
      "\n",
      "Full execution time = 0.409372 sec\n"
     ]
    }
   ],
   "source": [
    "args = f\"\"\"\n",
    "        --root_folder {rootDir} \n",
    "        --train_data_file {trainDataFile} \n",
    "        --train_pred_file {trainPredsFile} \n",
    "        --test_data_file {testDataFile}  \n",
    "        --test_pred_file {testPredsFile}\n",
    "        --rules_file {rulesFile} \n",
    "        --rules_outfile {localRuleOutFileName} \n",
    "        --nb_attributes {nattributes} \n",
    "        --attributes_file {attributesFile} \n",
    "        --nb_classes {nclasses}\n",
    "        \"\"\"\n",
    "\n",
    "status = fidex(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Fidex algorithm generated a rule file, let's observe what is inside:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No decision threshold is used.\n",
      "\n",
      "Rule for sample 0 :\n",
      "\n",
      "Height>=1.779662 Height<1.78706 Age>=24.133848 -> OLD_Obesity_Type_I\n",
      "   Train Covering size : 3\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.68\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "Rule for sample 1 :\n",
      "\n",
      "Weight>=130.606071 -> OLD_Obesity_Type_III\n",
      "   Train Covering size : 10\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.977273\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fidexRulesOutfile = \"fidex_rules.rls\"\n",
    "previewFile(rootDir+fidexRulesOutfile, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global ruleSet generation - FidexGlo\n",
    "We have seen how to compute a rule that explains the decision of the model for a specific sample with the Fidex algorithm. But how could we get a general set of rules that characterizes the whole train dataset ? Using the `fidexGloRules` (fidex global rules) algorithm, it is possible to archieve such thing.\n",
    "\n",
    "A global ruleset is a collection of rules that explains the model's decision for each sample present on the training portion of the dataset. Let's have a look on the fidexGloRules arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "Warning! The files are localised with respect to root folder dimlpfidex.\n",
      "The arguments can be specified in the command or in a json configuration file with --json_config_file your_config_file.json.\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Required parameters:\n",
      "\n",
      "--train_data_file <str>       Train data file\n",
      "--train_pred_file <str>       Train prediction file\n",
      "--train_class_file <str>      Train true class file, not mandatory if classes are specified in train data file\n",
      "--weights_file <str>          Weights file (not mandatory if a rules file is given with --rules_file)\n",
      "--rules_file <str>            Rules file to be converted to hyperlocus (not mandatory if a weights file is given with --weights_file)\n",
      "--global_rules_outfile <str>  Rules output file. If a .json filename is given, rules are saved in a special json format>\n",
      "--heuristic <int [1,3]>       Heuristic 1: optimal fidexGlo, 2: fast fidexGlo 3: very fast fidexGlo\n",
      "--nb_attributes <int [1,inf[> Number of attributes in dataset\n",
      "--nb_classes <int [2,inf[>    Number of classes in dataset\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Optional parameters: \n",
      "\n",
      "--json_config_file <str>      JSON file to configure all parameters. If used, this must be the sole argument and must specify the file's relative path\n",
      "--root_folder <str>           Folder based on main folder dimlpfidex(default folder) containg all used files and where generated files will be saved. If a file name is specified with another option, his path will be configured with respect to this root folder\n",
      "--attributes_file <str>       File of attributes\n",
      "--console_file <str>          File with console logs redirection\n",
      "--max_iterations <int [1,inf[>\n",
      "                              Max iteration number, also the max possible number of attributs in a rule, should be 25 if working with images (default: 10)\n",
      "--min_covering <int [1,inf[>  Minimum covering number (default: 2)\n",
      "--covering_strategy <bool>    Whether to use this strategy : if no rule is found with min_covering, find best rule with best covering using dichotomic search. Decreases min_fidelity if needed (default: True)\n",
      "--max_failed_attempts <int [0,inf[>\n",
      "                              Maximum number of failed attempts to find Fidex rule when covering is 1 and covering strategy is used (default: 30)\n",
      "--min_fidelity <float [0,1]>  Minimal rule fidelity accepted when generating a rule (default: 1.0)\n",
      "--lowest_min_fidelity <float [0,1]>\n",
      "                              Minimal min_fidelity to which we agree to go down during covering_strategy (default: 0.75)\n",
      "--dropout_dim <float [0,1]>   Dimension dropout parameter (default: 0.0)\n",
      "--dropout_hyp <float [0,1]>   Hyperplan dropout parameter (default: 0.0)\n",
      "--nb_quant_levels <int [3,inf[>\n",
      "                              Number of stairs in staircase activation function (default: 50)\n",
      "--decision_threshold <float [0,1]>\n",
      "                              Decision threshold for predictions, you need to specify the index of positive class if you want to use it\n",
      "--positive_class_index <int [0,nb_classes-1]>\n",
      "                              Index of positive class for the usage of decision threshold, index starts at 0\n",
      "--normalization_file <str>    File containing the mean and std of some attributes. Used to denormalize the rules if specified\n",
      "--mus <list<float ]inf,inf[>> Mean or median of each attribute index to denormalize in the rules\n",
      "--sigmas <list<float ]inf,inf[>>\n",
      "                              Standard deviation of each attribute index to denormalize in the rules\n",
      "--normalization_indices <list<int [0,nb_attributes-1]>>\n",
      "                              Attribute indices to denormalize in the rules, only used when no normalization_file is given, index starts at 0 (default: [0,...,nb_attributes-1])\n",
      "--nb_threads <int [1,nb_cores]>\n",
      "                              Number of threads used for computing the algorithm, 1=sequential execution (default: 1)\n",
      "--seed <int [0,inf[>          Seed, 0=random (default: 0)\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Execution example :\n",
      "\n",
      "fidex.fidexGloRules(\"--train_data_file datanormTrain.txt --train_pred_file predTrain.out --train_class_file dataclass2Train.txt --weights_file weights.wts --nb_attributes 16 --nb_classes 2 --heuristic 1 --global_rules_outfile globalRules.rls --root_folder dimlp/datafiles\")\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "status = fidexGloRules(\"--help\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meanwhile, there are `required parameters` very similar to the `Fidex` algorithm, there are a lot of optional arguments that you can use to customize the behavior of the algorithm. Let's have a look at some of them:\n",
    "\n",
    "- `--heuristic`: various ways to run the algorithm, these ways aim to increase execution speed. But also has a performance impact on results.\n",
    "- `--nb_threads`: number of processes used to compute the algorithm. Accelerate the process.\n",
    "- `--min_covering`: minimal number of samples a rule must cover\n",
    "- `--max_failed_attempts`: maximum failed attempts allowed when generating a rule\n",
    "- `--min_fidelity`: minimal fidelity allowed when generating a rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters list:\n",
      " - train_data_file                                                    data/OCDDataset/train_dataset.txt\n",
      " - train_pred_file                                                        data/OCDDataset/predTrain.out\n",
      " - rules_file                                                              data/OCDDataset/RF_rules.rls\n",
      " - global_rules_outfile                                         data/OCDDataset/fidexGloRules_rules.rls\n",
      " - root_folder                                                                         data/OCDDataset/\n",
      " - attributes_file                                                  data/OCDDataset/attributes_file.txt\n",
      " - nb_attributes                                                                                     20\n",
      " - nb_classes                                                                                         7\n",
      " - nb_quant_levels                                                                                   50\n",
      " - heuristic                                                                                          1\n",
      " - max_iterations                                                                                    10\n",
      " - min_covering                                                                                       2\n",
      " - max_failed_attempts                                                                               30\n",
      " - nb_threads                                                                                         8\n",
      " - positive_class_index                                                                              -1\n",
      " - seed                                                                                               0\n",
      " - decision_threshold                                                                         -1.000000\n",
      " - hi_knot                                                                                     5.000000\n",
      " - dropout_hyp                                                                                 0.000000\n",
      " - dropout_dim                                                                                 0.000000\n",
      " - min_fidelity                                                                                1.000000\n",
      " - lowest_min_fidelity                                                                         0.750000\n",
      " - covering_strategy                                                                                  1\n",
      "End of Parameters list.\n",
      "\n",
      "Importing files...\n",
      "Files imported\n",
      "\n",
      "Creation of hyperspace...\n",
      "Hyperspace created.\n",
      "\n",
      "Computing fidex rules...\n",
      "\n",
      "Thread #0 initialized, please wait for it to be done.\n",
      "Thread #3 initialized, please wait for it to be done.\n",
      "Thread #5 initialized, please wait for it to be done.\n",
      "Thread #1 initialized, please wait for it to be done.\n",
      "Thread #4 initialized, please wait for it to be done.\n",
      "Thread #7 initialized, please wait for it to be done.\n",
      "Thread #6 initialized, please wait for it to be done.\n",
      "Thread #2 initialized, please wait for it to be done.\n",
      "Thread #0 ended 20 iterations in 0.313301 seconds.\n",
      "Thread #1 ended 20 iterations in 0.313067 seconds.\n",
      "Thread #2 ended 20 iterations in 0.320514 seconds.\n",
      "Thread #3 ended 19 iterations in 0.313082 seconds.\n",
      "Thread #4 ended 19 iterations in 0.313036 seconds.\n",
      "Thread #5 ended 19 iterations in 0.313045 seconds.\n",
      "Thread #6 ended 19 iterations in 0.313012 seconds.\n",
      "Thread #7 ended 19 iterations in 0.313026 seconds.\n",
      "\n",
      "155 rules created.\n",
      "Number of sample with lower covering than 2 is 7\n",
      "Number of rules not found is 0\n",
      "Fidex rules computed\n",
      "Computing global ruleset...\n",
      "37 rules selected.\n",
      "Global ruleset Computed.\n",
      "\n",
      "heuristic #1 ended in 0.325867 sec\n",
      "\n",
      "Rules extraction...\n",
      "Mean covering size per rule : 5.48649\n",
      "Mean number of antecedents per rule : 2.59459\n",
      "\n",
      "Full execution time = 0.326398 sec\n"
     ]
    }
   ],
   "source": [
    "heuristic = 1\n",
    "nthreads = 8\n",
    "globalRulesOutfile = \"fidexGloRules_rules.rls\"\n",
    "\n",
    "args = f\"\"\"\n",
    "        --root_folder {rootDir} \n",
    "        --nb_threads {nthreads} \n",
    "        --train_data_file {trainDataFile} \n",
    "        --train_pred_file {trainPredsFile} \n",
    "        --rules_file {rulesFile} \n",
    "        --attributes_file {attributesFile} \n",
    "        --nb_attributes {nattributes} \n",
    "        --nb_classes {nclasses} \n",
    "        --heuristic {heuristic} \n",
    "        --global_rules_outfile {globalRulesOutfile}\n",
    "        \"\"\"\n",
    "\n",
    "status = fidexGloRules(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm generated a file that we're going to partially observe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rules : 37, mean sample covering number per rule : 5.486486, mean number of antecedents per rule : 2.594595\n",
      "No decision threshold is used.\n",
      "\n",
      "Rule 1: FCVC>=2.969344 Weight>=97.212196 Gender_Female>=0.5 -> OLD_Obesity_Type_III\n",
      "   Train Covering size : 22\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.971818\n",
      "\n",
      "Rule 2: Weight<50.5 Height>=1.505 -> OLD_Insufficient_Weight\n",
      "   Train Covering size : 20\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.9045\n",
      "\n",
      "Rule 3: Weight<61.834673 Height>=1.66 -> OLD_Insufficient_Weight\n",
      "   Train Covering size : 20\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.895\n",
      "\n",
      "Rule 4: Weight>=112.993652 Age>=24.133848 -> OLD_Obesity_Type_II\n",
      "   Train Covering size : 10\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.926\n",
      "\n",
      "Rule 5: Weight>=105.884819 TUE<0.000665 -> OLD_Obesity_Type_II\n",
      "   Train Covering size : 10\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.881\n",
      "\n",
      "Rule 6: Age<18.869944 Weight>=83.808815 FCVC<2.498308 -> OLD_Obesity_Type_I\n",
      "   Train Covering size : 9\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.904444\n",
      "\n",
      "Rule 7: TUE>=1.273543 Weight>=80.5 -> OLD_Obesity_Type_I\n",
      "   Train Covering size : 8\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.8725\n",
      "\n",
      "Rule 8: Age>=32.5 Age<37.315884 CALC<0.165 -> OLD_Overweight_Level_II\n",
      "   Train Covering size : 7\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.768571\n",
      "\n",
      "Rule 9: Weight>=112.993652 NCP<2.955784 -> OLD_Obesity_Type_II\n",
      "   Train Covering size : 7\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.874286\n",
      "\n",
      "Rule 10: Weight<75.205322 Weight>=61.834673 Height>=1.68 -> OLD_Normal_Weight\n",
      "   Train Covering size : 6\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.751667\n",
      "\n",
      "Rule 11: Height>=1.779662 NCP<2.509596 Weight<110.037472 -> OLD_Obesity_Type_I\n",
      "   Train Covering size : 6\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.865\n",
      "\n",
      "Rule 12: Weight>=100.566776 Age>=26.466783 TUE>=0.592749 -> OLD_Obesity_Type_II\n",
      "   Train Covering size : 6\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.888333\n",
      "\n",
      "Rule 13: CH2O>=2.86525 Weight>=90.885717 Height>=1.675 -> OLD_Obesity_Type_I\n",
      "   Train Covering size : 5\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.836\n",
      "\n",
      "Rule 14: NCP<1.007744 Weight<68.721386 Height>=1.521805 -> OLD_Normal_Weight\n",
      "   Train Covering size : 5\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.752\n",
      "\n",
      "Rule 15: NCP<2.669163 Weight>=75.205322 Height<1.62843 -> OLD_Obesity_Type_I\n",
      "   Train Covering size : 5\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.852\n",
      "\n",
      "Rule 16: Weight>=100.566776 CH2O<1.000347 -> OLD_Obesity_Type_II\n",
      "   Train Covering size : 4\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.8525\n",
      "\n",
      "Rule 17: CH2O<1.037396 Age>=23.99667 FAF<0.000136 -> OLD_Overweight_Level_I\n",
      "   Train Covering size : 4\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.7375\n",
      "\n",
      "Rule 18: Weight<70.221386 Weight>=59.841295 Gender_Female>=0.5 Age<20.168962 -> OLD_Normal_Weight\n",
      "   Train Covering size : 4\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.7875\n",
      "\n",
      "Rule 19: Age<19.045012 Weight>=81 Height<1.650075 -> OLD_Obesity_Type_I\n",
      "   Train Covering size : 4\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.8325\n",
      "\n",
      "Rule 20: Age>=38.324472 FAF<1.553201 -> OLD_Obesity_Type_I\n",
      "   Train Covering size : 4\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.7575\n",
      "\n",
      "Rule 21: CALC<0.165 Weight>=68.856747 FAVC<0.5 -> OLD_Overweight_Level_II\n",
      "   Train Covering size : 3\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.713333\n",
      "\n",
      "Rule 22: SCC>=0.5 FHWO>=0.5 -> OLD_Normal_Weight\n",
      "   Train Covering size : 3\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.796667\n",
      "\n",
      "Rule 23: CH2O<1.037396 Age>=23.99667 TUE>=0.07936 -> OLD_Overweight_Level_I\n",
      "   Train Covering size : 3\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.713333\n",
      "\n",
      "Rule 24: FCVC<2.001392 Weight>=89.919212 Weight<95.362549 -> OLD_Obesity_Type_I\n",
      "   Train Covering size : 3\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.783333\n",
      "\n",
      "Rule 25: NCP<2.94646 NCP>=2.569188 TUE>=0.721012 TUE<0.973545 -> OLD_Overweight_Level_II\n",
      "   Train Covering size : 3\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.75\n",
      "\n",
      "Rule 26: CAEC<0.165 -> OLD_Overweight_Level_I\n",
      "   Train Covering size : 3\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.88\n",
      "\n",
      "Rule 27: Age>=23.675585 Age<23.99667 -> OLD_Overweight_Level_II\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.75\n",
      "\n",
      "Rule 28: Age>=32.5 TUE>=0.607506 TUE<0.84668 -> OLD_Overweight_Level_II\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.705\n",
      "\n",
      "Rule 29: Age>=23.675585 Age<25.046897 Age>=24.200745 -> OLD_Overweight_Level_II\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.78\n",
      "\n",
      "Rule 30: TUE>=1.94127 CAEC>=0.495 -> OLD_Overweight_Level_I\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.665\n",
      "\n",
      "Rule 31: FCVC<2.001392 Height>=1.775625 FAF<0.754979 -> OLD_Obesity_Type_I\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.875\n",
      "\n",
      "Rule 32: CH2O<1.037396 Age>=23.99667 FCVC>=2.736264 -> OLD_Overweight_Level_I\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.85\n",
      "\n",
      "Rule 33: Weight>=100.566776 CH2O<1.481815 FAF<0.130637 -> OLD_Obesity_Type_II\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.815\n",
      "\n",
      "Rule 34: Age>=26.46775 CH2O>=2.36525 Age<33.625132 -> OLD_Overweight_Level_II\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.745\n",
      "\n",
      "Rule 35: Height<1.505 -> OLD_Normal_Weight\n",
      "   Train Covering size : 1\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.61\n",
      "\n",
      "Rule 36: FAF>=2.849437 MTRANS_Walking<0.5 -> OLD_Normal_Weight\n",
      "   Train Covering size : 1\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.72\n",
      "\n",
      "Rule 37: Weight<85.405804 Weight>=84.990974 -> OLD_Overweight_Level_I\n",
      "   Train Covering size : 1\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.66\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "previewFile(rootDir+globalRulesOutfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *The algorithm result is subject to randomness as it uses random processes to compute. Results may differ between executions.*\n",
    "\n",
    "You can observe the rules are ordered by their covering size. The first rule is the one that best describes the training portion of the dataset.\n",
    "\n",
    "Here's a given rule (can be unrelated to execution due to randomness) we are going to analyze:\n",
    "\n",
    "```md\n",
    "Rule 1: Weight>=101.258713 Gender_Female>=0.5 -> OLD_Obesity_Type_III\n",
    "   Train Covering size : 25\n",
    "   Train Fidelity : 1\n",
    "   Train Accuracy : 1\n",
    "   Train Confidence : 0.9852\n",
    "```\n",
    "\n",
    "This rule means the model is **98% sure** you are suffering from `Type 3 obesity` if your `weight` is above or equal to `~101.2 kg` and if you are, biologically speaking, a `female`. The rule is also **100% fidel** according to the model's predictions and is **100% accurate** concerning the training portion of the dataset.\n",
    "\n",
    "To get statistics on the test portion of the dataset, let's execute the `fidexGloStats`. Beginning with an overview of the arguments of the program: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "Warning! The files are localised with respect to root folder dimlpfidex.\n",
      "The arguments can be specified in the command or in a json configuration file with --json_config_file your_config_file.json.\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Required parameters:\n",
      "\n",
      "--test_data_file <str>        Test data file\n",
      "--test_pred_file <str>        Test prediction file\n",
      "--test_class_file <str>       Test true class file, not mandatory if classes are specified in test data file\n",
      "--global_rules_file <str>     Ruleset input file\n",
      "--nb_attributes <int [1,inf[> Number of attributes in dataset\n",
      "--nb_classes <int [2,inf[>    Number of classes in dataset\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Optional parameters: \n",
      "\n",
      "--json_config_file <str>      JSON file to configure all parameters. If used, this must be the sole argument and must specify the file's relative path\n",
      "--root_folder <str>           Folder based on main folder dimlpfidex(default folder) containg all used files and where generated files will be saved. If a file name is specified with another option, his path will be configured with respect to this root folder\n",
      "--attributes_file <str>       File of attributes> Mandatory if rules file contains attribute names, if not, do not add it\n",
      "--stats_file <str>            Output statistic file name\n",
      "--global_rules_outfile <str>  Global ruleset output file with stats on test set, if you want to compute statistics of global rules on tests set\n",
      "--console_file <str>          File with console logs redirection\n",
      "--positive_class_index <int [0,nb_classes-1]>\n",
      "                              Index of positive class to compute true/false positive/negative rates, index starts at 0. If it is specified in the rules file, it has to be the same value.\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Execution example :\n",
      "\n",
      "fidex.fidexGloStats(\"--test_data_file datanormTest.txt --test_pred_file predTest.out --test_class_file dataclass2Test.txt --global_rules_file globalRules.rls --nb_attributes 16 --nb_classes 2 --stats_file stats.txt --root_folder dimlp/datafiles\")\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "status = fidexGloStats(\"--help\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can observe, the required arguments are pretty much the same as previous executions. The only one that differs is `--global_rules_file` which simply asks to input the `global rule file` to compute statistics. Let's try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters list:\n",
      " - test_data_file                                                      data/OCDDataset/test_dataset.txt\n",
      " - test_pred_file                                                          data/OCDDataset/predTest.out\n",
      " - global_rules_file                                            data/OCDDataset/fidexGloRules_rules.rls\n",
      " - root_folder                                                                         data/OCDDataset/\n",
      " - attributes_file                                                  data/OCDDataset/attributes_file.txt\n",
      " - stats_file                                                              data/OCDDataset/RF_stats.txt\n",
      " - nb_attributes                                                                                     20\n",
      " - nb_classes                                                                                         7\n",
      " - positive_class_index                                                                              -1\n",
      "End of Parameters list.\n",
      "\n",
      "Importing files...\n",
      "\n",
      "Data imported.\n",
      "\n",
      "Compute statistics...\n",
      "\n",
      "Global statistics of the rule set : \n",
      "Number of rules : 37, mean sample covering number per rule : 5.486486, mean number of antecedents per rule : 2.594595\n",
      "\n",
      "Statistics with a test set of 52 samples :\n",
      "\n",
      "No decision threshold is used.\n",
      "No positive index class is used.\n",
      "The global rule fidelity rate is : 0.826923\n",
      "The global rule accuracy is : 0.692308\n",
      "The explainability rate (when we can find one or more rules, either correct ones or activated ones which all agree on the same class) is : 0.826923\n",
      "The default rule rate (when we can't find any rule activated for a sample) is : 0.134615\n",
      "The mean number of correct(fidel) activated rules per sample is : 0.884615\n",
      "The mean number of wrong(not fidel) activated rules per sample is : 0.596154\n",
      "The model test accuracy is : 0.788462\n",
      "The model test accuracy when rules and model agree is : 0.837209\n",
      "The model test accuracy when activated rules and model agree is : 0.888889\n",
      "\n",
      "Full execution time = 0.008841 sec\n"
     ]
    }
   ],
   "source": [
    "statsOutfileName = \"RF_stats.txt\"\n",
    "\n",
    "args = f\"\"\"\n",
    "        --root_folder {rootDir}\n",
    "        --test_data_file {testDataFile}\n",
    "        --test_pred_file {testPredsFile}\n",
    "        --global_rules_file {globalRulesOutfile}\n",
    "        --nb_attributes {nattributes}\n",
    "        --nb_classes {nclasses}\n",
    "        --attributes_file {attributesFile}\n",
    "        --stats_file {statsOutfileName}\n",
    "        \"\"\"\n",
    "\n",
    "status = fidexGloStats(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The execution of the algorithm generated a file that we named `RF_stats.txt` containing pretty much the same feedback as the program output. That being said, let's have a look inside the generated file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global statistics of the rule set : \n",
      "Number of rules : 37, mean sample covering number per rule : 5.486486, mean number of antecedents per rule : 2.594595\n",
      "\n",
      "Statistics with a test set of 52 samples :\n",
      "\n",
      "No decision threshold is used.\n",
      "No positive index class is used.\n",
      "The global rule fidelity rate is : 0.826923\n",
      "The global rule accuracy is : 0.692308\n",
      "The explainability rate (when we can find one or more rules, either correct ones or activated ones which all agree on the same class) is : 0.826923\n",
      "The default rule rate (when we can't find any rule activated for a sample) is : 0.134615\n",
      "The mean number of correct(fidel) activated rules per sample is : 0.884615\n",
      "The mean number of wrong(not fidel) activated rules per sample is : 0.596154\n",
      "The model test accuracy is : 0.788462\n",
      "The model test accuracy when rules and model agree is : 0.837209\n",
      "The model test accuracy when activated rules and model agree is : 0.888889\n",
      "\n"
     ]
    }
   ],
   "source": [
    "previewFile(rootDir+statsOutfileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the program shows various metrics, let's have a look at them individually:\n",
    "\n",
    "[//]: # (TODO: complete description for: positive class index, global rule accuracy and globabl rule fidelity rate)\n",
    "- `Global statistics`: Several values expressing general information about the ruleset.\n",
    "- `Decision threshold`: Value used to define a threshold where a class is considered as true. In this case, it's written that `no decision threshold is used`.\n",
    "- `Positive index class`: Value means which class is considered as the positive one. If no threshold is used, this cannot be used, like in this case.\n",
    "- `Global rule fidelity rate`: Expressing whether the ruleset\n",
    "- `Global rule accuracy`: expresses the proportions of false explanations.\n",
    "- `Explainability rate`: as described in the file itself, it shows the proportion of the samples that could be explained by one or more rules.\n",
    "- `Default rule rate`: describes the proportion of samples that could not be explained by a rule offered by the ruleset\n",
    "- `Mean number of correct activated rules`:\n",
    "- `Mean number of wrong activated rules`:\n",
    "- `Model test accuracy`\n",
    "- `Model test accuracy when rules agree`:\n",
    "- `Model test accuracy when activated rules agree`:\n",
    "\n",
    "With this program, you can have a general overview of the quality of the ruleset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen how to pre-process a dataset to comply with the expectations of the Random Forest, then we trained a pre-made Random Forest algorithm with our dataset. This gave us a set of rules that we then fed Fidex and FidexGloRules with. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
