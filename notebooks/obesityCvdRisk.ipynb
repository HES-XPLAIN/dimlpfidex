{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Random Forest and Fidex rule generation for obesity risk classification\n",
    "\n",
    "**Introduction:**\n",
    "\n",
    "Welcome to HES-Xplain, our interactive platform designed to facilitate explainable artificial intelligence (XAI) techniques. In this use case, we dive into obesity risk classification and showcase another application example of explainability techniques.\n",
    "\n",
    "This notebook is an alternative to the [`Exploring Dimlp and Fidex rule generation for breast cancer classification`](TODO). It aims to be similar but aims to use a different dataset and training model to show the versatility of our explainability tools.  In addition, we will cover how to pre-process a dataset that is not initially usable by a model and convert it to an exploitable dataset.\n",
    "\n",
    "**Objectives:**\n",
    "\n",
    "    1. Observe a different use case where XAI can be used\n",
    "    2. Understand how to pre-process data \n",
    "    3. Understand how to use Dimlp and Fidex.\n",
    "    4. Showcase the versatility of HES-Xplain using a different dataset and training model.\n",
    "    5. Provide practical insights into applying Random Forests and Fidex to breast cancer classifiers through an interactive notebook.\n",
    "    6. Foster a community of XAI enthusiasts and practitioners.\n",
    "\n",
    "**Outline:**\n",
    "\n",
    "    1. Dataset and Problem Statement.\n",
    "    2. Load and pre-process the dataset.\n",
    "    3. Train the Model.\n",
    "    4. Local rules generation - Fidex\n",
    "    5. Global ruleSet generation - FidexGlo\n",
    "    6. Conclusion.\n",
    "\n",
    "Through this use case, we aim to show the users the potential of Random Forests and Fidex as tools for transparent and interpretable classification. With HES-Xplain, we make XAI accessible, helping users build trust in their models and make informed decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and Problem Statement\n",
    "The dataset we'll be working with is called the [obesity or CVD risk](https://www.kaggle.com/datasets/aravindpcoder/obesity-or-cvd-risk-classifyregressorcluster/data) and is accessible on [Kaggle](https://www.kaggle.com). It comprises 2111 records of anonymized data concerning South American individuals and their dietary habits. In this notebook, our focus is on another medical challenge: classifying the risk of obesity based on various factors. These factors, drawn from the dataset, are outlined below with their original names:\n",
    "\n",
    "| **Full name**                             | **Used label** |                                                        **Values/Ranges**                                                       | **Description**                                                                     |\n",
    "|-------------------------------------------|:--------------:|:------------------------------------------------------------------------------------------------------------------------------:|-------------------------------------------------------------------------------------|\n",
    "| Gender                                    |     Gender     |                                                          Male, Female                                                          | Person's biological gender                                                          |\n",
    "| Age                                       |       Age      |                                                             [14:61]                                                            | Person's age in years                                                               |\n",
    "| Height                                    |     Height     |                                                           [1.45:1.98]                                                          | Person's height in meters                                                           |\n",
    "| Weight                                    |     Weight     |                                                            [39:173]                                                            | Person's weight in kilograms                                                        |\n",
    "| Family history with overweight            |      FHWO      |                                                             yes, no                                                            | Whether the person has at least one sibling that suffers or suffered of overweight  |\n",
    "| Frequent consumption of high-caloric food |      FAVC      |                                                             yes, no                                                            | Whether the person is frequently consuming high-caloric food                        |\n",
    "| Frequency of consumption of vegetables    |      FCVC      |                                                              [1:3]                                                             | Leveled frequency of consumption of vegetables                                      |\n",
    "| Number of main meals                      |       NCP      |                                                              [1:4]                                                             | Person's number of main meals during a day                                          |\n",
    "| Consumption of food between meals         |      CAEC      |                                                no, sometimes, frequently, always                                               | Person's consumption of food between main meals frequency per day                   |\n",
    "| Smoker or not                             |      SMOKE     |                                                             yes, no                                                            | Whether the person smokes                                                           |\n",
    "| Consumption of water daily                |      CH20      |                                                              [1:3]                                                             | Numeric representation of water consumption frequency per day                       |\n",
    "| Calories consumption monitoring           |       SCC      |                                                             yes, no                                                            | Whether the person is monitoring his daily calories intake                          |\n",
    "| Physical activity frequency               |       FAF      |                                                              [0:3]                                                             | Numeric representation of physical activity frequency per week                      |\n",
    "| Time using technology devices             |       TUE      |                                                              [0:2]                                                             | Numeric representation of electronic devices use frequency per day                  |\n",
    "| Consumption of alcohol                    |      CALC      |                                                no, sometimes, frequently, always                                               | Frequency of alcohol consumption                                                    |\n",
    "| Transportation used                       |     MTRANS     |                                   Public_Transportation, Automobile, Bike, Motorbike, Walking                                  | Medium usually used to transit                                                      |\n",
    "| Obesity level deducted                    |       OLD      | Insufficient_Weight, Normal_Weight, Overweight_Level_I, Overweight_Level_II, Obesity_Type_I, Obesity_Type_II, Obesity_Type_III | Obesity level observed according to the interpretation of the person's BMI          |\n",
    "\n",
    "Our goal is to train a random forest model to classify the obesity level based on the other features. To achieve this, we will need to modify the original dataset to convert several features into a format that is suitable for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and pre-process the dataset\n",
    "To kick things off, we'll begin by simplifying the names of the columns and taking a look at the CSV file containing the raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dimlpfidex.fidex import fidex, fidexGloRules, fidexGloStats\n",
    "from trainings.randForestsTrn import randForestsTrn as randomForest\n",
    "\n",
    "# silence warnings concerning replace() method being removed on pandas 3.0\n",
    "pd.set_option(\"future.no_silent_downcasting\", True)\n",
    "\n",
    "\n",
    "# utility function to preview a file entirely or only the first `nlines` lines\n",
    "def previewFile(filepath, nlines=-1):\n",
    "    lines = \"\"\n",
    "\n",
    "    with open(filepath, \"r\") as f:\n",
    "        if nlines == -1:\n",
    "            for line in f:\n",
    "                lines += line\n",
    "        else:\n",
    "            for _ in range(nlines):\n",
    "                try:\n",
    "                    lines += next(f)\n",
    "                except StopIteration:\n",
    "                    break\n",
    "    print(lines)\n",
    "\n",
    "\n",
    "\n",
    "dataset = pd.read_csv(\"data/OCDDataset/ObesityDataSet.csv\")\n",
    "\n",
    "# reducing labels names size\n",
    "dataset.rename(\n",
    "    columns={\n",
    "        \"family_history_with_overweight\": \"FHWO\",\n",
    "        \"NObeyesdad\": \"OLD\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# shuffle the entire dataset\n",
    "dataset = dataset.sample(frac=1)\n",
    "nrows = int(dataset.shape[0] * 0.1)\n",
    "dataset = dataset.iloc[:nrows, :]\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can observe a sample of the dataset. To make the dataset more compatible with machine learning, we'll start by converting features that have \"yes\" or \"no\" values into their boolean representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "strToBinDict = {\"yes\": 1, \"no\": 0}\n",
    "dataset[\"FHWO\"] = dataset[\"FHWO\"].replace(strToBinDict).astype(\"int8\")\n",
    "dataset[\"FAVC\"] = dataset[\"FAVC\"].replace(strToBinDict).astype(\"int8\")\n",
    "dataset[\"SMOKE\"] = dataset[\"SMOKE\"].replace(strToBinDict).astype(\"int8\")\n",
    "dataset[\"SCC\"] = dataset[\"SCC\"].replace(strToBinDict).astype(\"int8\")\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will convert the `CAEC` and `CALC` columns, which contain the values \"Always,\" \"Frequently,\" \"Sometimes,\" and \"no,\" into a numerical scale from 0.00 to 1.00 based on their frequency. Here's the conversion table:\n",
    "\n",
    "| **Adjective** | **Conversion Value** |\n",
    "|---------------|:--------------------:|\n",
    "| Always        |         1.00         |\n",
    "| Frequently    |         0.66         |\n",
    "| Sometimes     |         0.33         |\n",
    "| no            |         0.00         |\n",
    "\n",
    "We'll apply a similar procedure as before to achieve this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "adjToValDict = {\"Always\": 1.0, \"Frequently\": 0.66, \"Sometimes\": 0.33, \"no\": 0.0}\n",
    "dataset[\"CAEC\"] = dataset[\"CAEC\"].replace(adjToValDict).astype('float64')\n",
    "dataset[\"CALC\"] = dataset[\"CALC\"].replace(adjToValDict).astype('float64')\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll address three additional columns named `Gender`, `MTRANS`, and `OLD`, which currently contain non-numerical values. These values represent individual options and cannot be quantified using a scale like before. Instead, we'll encode them using a technique called \"one hot encoding.\" This technique will assign a binary value to each option, representing its presence or absence. Let's proceed with applying one hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "genderCols = pd.get_dummies(dataset[\"Gender\"], prefix=\"Gender\",prefix_sep='_', dtype='int8')\n",
    "mtransCols = pd.get_dummies(dataset[\"MTRANS\"], prefix=\"MTRANS\",prefix_sep='_', dtype='int8')\n",
    "oldCols = pd.get_dummies(dataset[\"OLD\"], prefix=\"OLD\",prefix_sep='_', dtype='int8')\n",
    "dataset = pd.concat([genderCols, dataset.iloc[:,:16], mtransCols,  dataset.iloc[:,16:], oldCols], axis=1)\n",
    "dataset.drop([\"Gender\", \"MTRANS\", \"OLD\"], axis=1, inplace=True)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our dataset is prepared to be used, let's ensure the data's integrity by verifying some information, starting with a general overview of our columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's verify that there are no missing values in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll ensure that there are no duplicated records in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "dataset = dataset.drop_duplicates()\n",
    "dataset.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we need to split our dataset into two distinct datasets, one for the training process and the other for the testing process. Then, write them in separate files to allow them to be used by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "nRecords = dataset.shape[0]\n",
    "trainSplit = int(0.75 * nRecords)\n",
    "\n",
    "trainds = dataset.iloc[:trainSplit, :]\n",
    "testds = dataset.iloc[trainSplit:, :]\n",
    "\n",
    "# We are writing TXT format to comply with our random forest algorithm\n",
    "rootDir = \"data/OCDDataset/\"\n",
    "trainDataFile = \"train_dataset.txt\"\n",
    "testDataFile = \"test_dataset.txt\"\n",
    "\n",
    "trainds.to_csv(rootDir + trainDataFile, header=False, index=False)\n",
    "testds.to_csv(rootDir + testDataFile, header=False, index=False)\n",
    "\n",
    "print(\n",
    "f\"\"\"\n",
    "Total number of records:\\t{nRecords}\n",
    "Number of records for training:\\t{trainds.shape[0]}\n",
    "Number of records for testing:\\t{testds.shape[0]}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data is ready and checked for any missing or duplicate values, we're all set to move on to the next step. In the upcoming chapter, we'll use our prepared dataset to train our Random Forest model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "Let's dig into the main part of our task: training the model. To do so, we're going to use a type of model called random forests. Random forests are a type of machine learning model that works by creating a multitude of decision trees during training. Each tree independently makes predictions, and the final prediction is determined by averaging the predictions of all the trees (for regression tasks) or taking a majority vote (for classification tasks). \n",
    "\n",
    "In this case, we are going to use our Python program called [randForestsTrn](https://github.com/HES-XPLAIN/dimlpfidex/blob/main/trainings/randForestsTrn.py). Let's begin with importing the script and printing its help message to observe every option available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "status = randomForest(\"--help\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output reveals various options. Among these, we'll focus on the required parameters (and the `--root_folder` for convenience). Since we've already generated the train and test data files in the previous chapter, our next step is to determine the number of attributes and classes. As the original class is denoted by `OLD`, post one-hot encoding, we need to count the number of labels prefixed with `OLD_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "labels = list(dataset.columns)\n",
    "\n",
    "nclasses = sum(1 for label in labels if label.startswith(\"OLD_\"))\n",
    "nattributes = len(labels) - nclasses\n",
    "attributesFile = \"attributes_file.txt\" \n",
    "\n",
    "\n",
    "with open(rootDir+attributesFile, 'w') as af:\n",
    "    for label in dataset.columns:\n",
    "        af.write(label+'\\n')\n",
    "\n",
    "print(f\"# attributes:\\t{nattributes}\\n# classes:\\t{nclasses}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now, let's gather the elements we have to run the model:\n",
    "\n",
    "| **Parameter name** | **Input**           |\n",
    "|--------------------|:-------------------:|\n",
    "| --root_folder      | data/OCDDataset/    |\n",
    "| --train_data_file  | train_dataset.txt   |\n",
    "| --test_data_file   | test_dataset.txt    |\n",
    "| --nb_attributes    | 21\\*                |\n",
    "| --nb_classes       | 7\\*                 |\n",
    "\n",
    "<br>\n",
    "\n",
    "> *\\*these values depend on the portion of the dataset used and therefore can vary.*\n",
    "\n",
    "With these parameters in place, we can proceed to run our random forest model, allowing the remaining options to be determined by their default settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = f\"\"\"\n",
    "        --root_folder {rootDir} \n",
    "        --train_data_file {trainDataFile} \n",
    "        --test_data_file {testDataFile} \n",
    "        --nb_attributes {nattributes} \n",
    "        --nb_classes {nclasses}\n",
    "        \"\"\"\n",
    "\n",
    "randomForest(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm ended and generated a `rule_outfile` file. It contains all rules generated by each tree from the random forest. Lets visualize some of the first tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rulesFile = \"RF_rules.rls\" # if you used the --rules_outfile option when running randomForest(), please don't forget to adapt this according to your input\n",
    "previewFile(rootDir+rulesFile, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output displays a segment of the newly generated file, showcasing rules generated by each tree of the random forest algorithm. Remarkably, the rules generated appear to be quite similar within a single tree. This is entirely normal, as each tree operates independently and may converge on similar decision boundaries.\n",
    "\n",
    "With our set of rules generated and ready to go, let's move on the next chapter and explore the Fidex algorithm to find local rules for given samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local rules generation - Fidex\n",
    "\n",
    "Now we can generate `local rules` to explain the model's results. We can start with launching Fidex on one test sample. This will generate a rule explaining the sample locally. It is `local` because the algorithm searches a rule only for one sample.\n",
    "\n",
    "First of all, let's take a look at Fidex's arguments :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = fidex(\"--help\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a closer look at the Fidex help output. We can observe that there are `required parameters`. Let's have a look on them:\n",
    "\n",
    "- `--train_data_file`: a file containing features from the training portion of the dataset\n",
    "- `--train_pred_file`: a file containing predictions from the training portion of the dataset\n",
    "- `--train_class_file`: a file containing classes from the training portion of the dataset\n",
    "- `--test_data_file`: a file containing samples to be used when generating a local rule\n",
    "- `--weights_file`: a file containing weights from a model training (in our case, we don't need it because we already have a `rules file` from the RF training)\n",
    "- `--rules_file`: a file containing the rules generated by a model training \n",
    "- `--rules_outfile`: a file name that will contain the output of the Fidex algorithm\n",
    "- `--nb_attributes`: the number of attributes present in the dataset\n",
    "- `--nb_classes`: the number of classes present in the dataset\n",
    "\n",
    "There are also optional arguments that we are going to use:\n",
    "- `--root_folder`: path defining the root directory where every other path specified in other arguments begins\n",
    "- `--attributes_file`: a file containing all attributes and class names\n",
    "\n",
    "All steps done until now will allow us to run the Fidex program. To see what happens, we launch it with just one sample, and we save beforehand the test data sample in a file with its classes and predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localRuleOutFileName = \"fidex_rules.rls\"\n",
    "trainClassesFile = \"train_classes.txt\"\n",
    "trainPredsFile = \"predTrain.out\" # generated by the RF\n",
    "testPredsFile = \"predTest.out\" # generated by the RF\n",
    "testSampleFile = \"test_sample.txt\"\n",
    "\n",
    "sampleSelected = 0\n",
    "assert(sampleSelected < nrows)\n",
    "\n",
    "\n",
    "# extract a sample to generate local rule\n",
    "testPreds = pd.read_csv(rootDir+testPredsFile, sep=\" \", header=None, index_col=None).iloc[:, :nclasses]\n",
    "sampleData = testds.iloc[sampleSelected, :nattributes].to_list()\n",
    "samplePred = testPreds.iloc[sampleSelected, :].to_list()\n",
    "sampleClasses = testds.iloc[sampleSelected, nattributes:].to_list()\n",
    "\n",
    "# write the sample, classes and predictions in the testSampleFile file (file writing format must be respected)\n",
    "with open(rootDir+testSampleFile, 'w') as f:\n",
    "    f.write(\" \".join(str(x) for x in sampleData) + '\\n')\n",
    "    f.write(\" \".join(str(x) for x in samplePred) + '\\n')\n",
    "    f.write(\" \".join(str(x) for x in sampleClasses) + '\\n')\n",
    "\n",
    "args = f\"\"\"\n",
    "        --root_folder {rootDir} \n",
    "        --train_data_file {trainDataFile} \n",
    "        --train_pred_file {trainPredsFile} \n",
    "        --test_data_file {testSampleFile}  \n",
    "        --rules_file {rulesFile} \n",
    "        --rules_outfile {localRuleOutFileName} \n",
    "        --nb_attributes {nattributes} \n",
    "        --attributes_file {attributesFile} \n",
    "        --nb_classes {nclasses}\n",
    "        \"\"\"\n",
    "\n",
    "status = fidex(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the algorithm shows us, in the terminal, a walkthrough of the process. At the end of it, you can observe the generated rule. Let's have a closer look to it by extracting the freshly written rule file: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previewFile(rootDir+localRuleOutFileName, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output displays a preview of a rule generated by Fidex. Each rule includes various properties:\n",
    "- The index of the sample from which the rule has been generated\n",
    "- The rule itself, composed of a single or list of antecedents and the prediction\n",
    "- The number of samples, in the training dataset, covered by the rule\n",
    "- The fidelity of the rule according to the model's predictions\n",
    "- The accuracy of the rule\n",
    "- The confidence of the rule with its choices, concerning the prediction values\n",
    "\n",
    "These rules provide insights into the model's predictions for each sample, helping to explain its decision-making process.\n",
    "\n",
    "Next, we'll rerun Fidex with all test samples to generate a comprehensive set of rules for further analysis. Please note that this process may take some time depending on the dataset size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = f\"\"\"\n",
    "        --root_folder {rootDir} \n",
    "        --train_data_file {trainDataFile} \n",
    "        --train_pred_file {trainPredsFile} \n",
    "        --test_data_file {testDataFile}  \n",
    "        --test_pred_file {testPredsFile}\n",
    "        --rules_file {rulesFile} \n",
    "        --rules_outfile {localRuleOutFileName} \n",
    "        --nb_attributes {nattributes} \n",
    "        --attributes_file {attributesFile} \n",
    "        --nb_classes {nclasses}\n",
    "        \"\"\"\n",
    "\n",
    "status = fidex(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Fidex algorithm generated a rule file, let's observe what is inside:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fidexRulesOutfile = \"fidex_rules.rls\"\n",
    "previewFile(rootDir+fidexRulesOutfile, 20) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the output is very similar to the single sample test, the only difference is the amount of rules generated, which is proportional to the number of samples.\n",
    "\n",
    "Running Fidex with all samples provides a comprehensive set of rules adapted to every sample given. These rules are useful for understanding how different factors influence the model's predictions for various samples.\n",
    "\n",
    "In the next chapter, we will move on to global ruleSet generation using FidexGloRules. This will help us understand the overall behavior of the model by generating a set of global rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global ruleSet generation - FidexGlo\n",
    "We have seen how to compute a rule that explains the decision of the model for a specific sample with the Fidex algorithm. But how could we get a general set of rules that characterizes the whole train dataset ? Using the `fidexGloRules` (fidex global rules) algorithm, it is possible to archieve this.\n",
    "\n",
    "A global ruleset is a collection of rules that explains the model's decision for each sample present on the training portion of the dataset. Let's have a look on the fidexGloRules arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = fidexGloRules(\"--help\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meanwhile, there are `required parameters` very similar to the `Fidex` algorithm, there many optional arguments that you can use to customize the behavior of the algorithm. Let's have a look at some of them:\n",
    "\n",
    "- `--heuristic`: various ways to run the algorithm, these ways aim to increase execution speed. But also has a performance impact on results.\n",
    "- `--nb_threads`: number of processes used to compute the algorithm. Accelerate the process.\n",
    "- `--min_covering`: minimal number of samples a rule must cover\n",
    "- `--max_failed_attempts`: maximum failed attempts allowed when generating a rule\n",
    "- `--min_fidelity`: minimal fidelity allowed when generating a rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heuristic = 1\n",
    "nthreads = 8\n",
    "globalRulesOutfile = \"fidexGloRules_rules.rls\"\n",
    "\n",
    "args = f\"\"\"\n",
    "        --root_folder {rootDir} \n",
    "        --nb_threads {nthreads} \n",
    "        --train_data_file {trainDataFile} \n",
    "        --train_pred_file {trainPredsFile} \n",
    "        --rules_file {rulesFile} \n",
    "        --attributes_file {attributesFile} \n",
    "        --nb_attributes {nattributes} \n",
    "        --nb_classes {nclasses} \n",
    "        --heuristic {heuristic} \n",
    "        --global_rules_outfile {globalRulesOutfile}\n",
    "        \"\"\"\n",
    "\n",
    "status = fidexGloRules(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm generated a file that we're going to partially observe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previewFile(rootDir+globalRulesOutfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *The algorithm result is subject to randomness as it uses random processes to compute. Results may differ between executions.*\n",
    "\n",
    "You can observe the rules are ordered by their covering size. The first rule is the one that best describes the training portion of the dataset.\n",
    "\n",
    "Here's a given rule (can be unrelated to execution due to randomness) we are going to analyze:\n",
    "\n",
    "```md\n",
    "Rule 1: Weight>=101.258713 Gender_Female>=0.5 -> OLD_Obesity_Type_III\n",
    "   Train Covering size : 25\n",
    "   Train Fidelity : 1\n",
    "   Train Accuracy : 1\n",
    "   Train Confidence : 0.9852\n",
    "```\n",
    "\n",
    "This rule means the model is **98% sure** you are suffering from `Type 3 obesity` if your `weight` is above or equal to `~101.2 kg` and if you are, biologically speaking, a `female`. The rule is also **100% fidel** according to the model's predictions and is **100% accurate** concerning the training portion of the dataset.\n",
    "\n",
    "To get statistics on the test portion of the dataset, let's execute the `fidexGloStats`. Beginning with an overview of the arguments of the program: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = fidexGloStats(\"--help\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can observe, the required arguments are pretty much the same as previous executions. The only one that differs is `--global_rules_file` which simply asks to input the `global rule file` to compute statistics. Let's try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statsOutfileName = \"RF_stats.txt\"\n",
    "\n",
    "args = f\"\"\"\n",
    "        --root_folder {rootDir}\n",
    "        --test_data_file {testDataFile}\n",
    "        --test_pred_file {testPredsFile}\n",
    "        --global_rules_file {globalRulesOutfile}\n",
    "        --nb_attributes {nattributes}\n",
    "        --nb_classes {nclasses}\n",
    "        --attributes_file {attributesFile}\n",
    "        --stats_file {statsOutfileName}\n",
    "        \"\"\"\n",
    "\n",
    "status = fidexGloStats(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The execution of the algorithm generated a file that we named `RF_stats.txt` containing pretty much the same feedback as the program output. That being said, let's have a look inside the generated file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previewFile(rootDir+statsOutfileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the program shows various metrics, let's have a look at them individually:\n",
    "\n",
    "[//]: # (TODO: complete description for: positive class index, global rule accuracy and globabl rule fidelity rate)\n",
    "- `Global statistics`: Several values expressing general information about the ruleset.\n",
    "- `Decision threshold`: Value used to define a threshold where a class is considered as true. In this case, it's written that `no decision threshold is used`.\n",
    "- `Positive index class`: Value means which class is considered as the positive one. If no threshold is used, this cannot be used, like in this case.\n",
    "- `Global rule fidelity rate`: Expressing whether the ruleset accurately reflects the model's predictions.\n",
    "- `Global rule accuracy`: Proportion of correct predictions made by the ruleset.\n",
    "- `Explainability rate`: Proportion of the samples that could be explained by one or more rules.\n",
    "- `Default rule rate`: Proportion of samples that could not be explained by a rule offered by the ruleset.\n",
    "- `Mean number of correct activated rules`: Average number of correct rules activated per sample.\n",
    "- `Mean number of wrong activated rules`: Average number of incorrect rules activated per sample.\n",
    "- `Model test accuracy`: Accuracy of the model on the test dataset\n",
    "- `Model test accuracy when rules agree`: Accuracy of the model on test samples where the ruleset and model predictions agree.\n",
    "- `Model test accuracy when activated rules agree`: Accuracy when at least one activated rule agrees with the model's prediction.\n",
    "\n",
    "With this program, you can have a general overview of the quality of the ruleset.\n",
    "\n",
    "With the generation of local and global rules using the Fidex algorithms, we have a clearer view of how our model makes predictions. These rules help us understand the model's decisions, making it more transparent. Now, let's wrap up our findings and discuss the importance of explainable AI in the final chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we explored explainable AI using Random Forests and the Fidex family of algorithms. We prepared our dataset, trained a Random Forest model, and examined the generated rules. We used Fidex to create local rules for individual sample explanations and FidexGlo to generate a global ruleset for the entire training dataset. Finally, we evaluated the ruleset with FidexGloStats, providing insights into the model's accuracy, fidelity, and explainability.\n",
    "\n",
    "This process demonstrated how explainable AI techniques can clarify complex models, making them more transparent and trustworthy. By understanding our model's decision-making process, we can ensure better, more reliable outcomes in various applications. Using Random Forests with Fidex offers a balanced approach to building interpretable and effective AI models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
