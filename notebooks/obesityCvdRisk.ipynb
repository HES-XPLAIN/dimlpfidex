{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Random Forest and Fidex rule generation for obesity risk classification\n",
    "\n",
    "**Introduction:**\n",
    "\n",
    "Welcome to HES-Xplain, our interactive platform designed to facilitate explainable artificial intelligence (XAI) techniques. In this use case, we dive into obesity risk classification and showcase another application example of explainability techniques.\n",
    "\n",
    "This notebook is an alternative to the [`Exploring Dimlp and Fidex rule generation for breast cancer classification`](TODO). It aims to be similar but aims to use a different dataset and training model to show the versatility of our explainability tools.  In addition, we will cover how to pre-process a dataset that is not initially usable by a model and convert it to an exploitable dataset.\n",
    "\n",
    "**Objectives:**\n",
    "    1. Observe a different use case where XAI can be used\n",
    "    2. Understand how to pre-process data \n",
    "    3. Understand how to use Dimlp and Fidex.\n",
    "    4. Showcase the versatility of HES-Xplain using a different dataset and training model.\n",
    "    5. Provide practical insights into applying Random Forests and Fidex to breast cancer classifiers through an interactive notebook.\n",
    "    6. Foster a community of XAI enthusiasts and practitioners.\n",
    "\n",
    "**Outline:**\n",
    "\n",
    "    1. Dataset and Problem Statement.\n",
    "    2. Load and pre-process the dataset.\n",
    "    3. Train the Model.\n",
    "    4. Local rules generation - Fidex // ???\n",
    "    5. Global ruleSet generation - FidexGlo // ???\n",
    "    6. Conclusion.\n",
    "\n",
    "Through this use case, we aim to empower users to grasp the potential of Random Forests and Fidex as tools for transparent and interpretable classification. With HES-Xplain, we make XAI accessible, helping users build trust in their models and make informed decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and Problem Statement\n",
    "The dataset we'll be working with is called the [obesity or CVD risk](https://www.kaggle.com/datasets/aravindpcoder/obesity-or-cvd-risk-classifyregressorcluster/data) and is accessible on [Kaggle](https://www.kaggle.com). It comprises 2111 records of anonymized data pertaining to South American individuals and their dietary habits. In this notebook, our focus is on tackling another prevalent medical challenge: classifying the risk of obesity based on various factors. These factors, drawn from the dataset, are outlined below with their original names:\n",
    "\n",
    "| **Full name**                             | **Used label** |                                                        **Values/Ranges**                                                       | **Description**                                                                     |\n",
    "|-------------------------------------------|:--------------:|:------------------------------------------------------------------------------------------------------------------------------:|-------------------------------------------------------------------------------------|\n",
    "| Gender                                    |     Gender     |                                                          Male, Female                                                          | Person's biological gender                                                          |\n",
    "| Age                                       |       Age      |                                                             [14:61]                                                            | Person's age in years                                                               |\n",
    "| Height                                    |     Height     |                                                           [1.45:1.98]                                                          | Person's height in meters                                                           |\n",
    "| Weight                                    |     Weight     |                                                            [39:173]                                                            | Person's weight in kilograms                                                        |\n",
    "| Family history with overweight            |      FHWO      |                                                             yes, no                                                            | Whether the person has at least one sibling that suffers or suffered of overweight  |\n",
    "| Frequent consumption of high-caloric food |      FAVC      |                                                             yes, no                                                            | Whether the person is frequently consuming high-caloric food                        |\n",
    "| Frequency of consumption of vegetables    |      FCVC      |                                                              [1:3]                                                             | Leveled frequency of consumption of vegetables                                      |\n",
    "| Number of main meals                      |       NCP      |                                                              [1:4]                                                             | Person's number of main meals during a day                                          |\n",
    "| Consumption of food between meals         |      CAEC      |                                                no, sometimes, frequently, always                                               | Person's consumption of food between main meals frequency per day                   |\n",
    "| Smoker or not                             |      SMOKE     |                                                             yes, no                                                            | Whether the person smokes                                                           |\n",
    "| Consumption of water daily                |      CH20      |                                                              [1:3]                                                             | Numeric representation of water consumption frequency per day                       |\n",
    "| Calories consumption monitoring           |       SCC      |                                                             yes, no                                                            | Whether the person is monitoring his daily calories intake                          |\n",
    "| Physical activity frequency               |       FAF      |                                                              [0:3]                                                             | Numeric representation of physical activity frequency per week                      |\n",
    "| Time using technology devices             |       TUE      |                                                              [0:2]                                                             | Numeric representation of electronic devices use frequency per day                  |\n",
    "| Consumption of alcohol                    |      CALC      |                                                no, sometimes, frequently, always                                               | Frequency of alcohol consumption                                                    |\n",
    "| Transportation used                       |     MTRANS     |                                   Public_Transportation, Automobile, Bike, Motorbike, Walking                                  | Medium usually used to transit                                                      |\n",
    "| Obesity level deducted                    |       OLD      | Insufficient_Weight, Normal_Weight, Overweight_Level_I, Overweight_Level_II, Obesity_Type_I, Obesity_Type_II, Obesity_Type_III | Obesity level observed according to the interpretation of the person's BMI          |\n",
    "\n",
    "In our case, we look forward to training a random forest model to classify the obesity level deducted from all the other features. To do so, we need to slightly modify the original dataset to convert several features to be digestible by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and pre-process the dataset\n",
    "To kick things off, we'll begin by simplifying the names of the columns and taking a look at the CSV file containing the raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>FHWO</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>OLD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>64.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.52</td>\n",
       "      <td>56.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>77.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>87.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Walking</td>\n",
       "      <td>Overweight_Level_I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>89.8</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender   Age  Height  Weight FHWO FAVC  FCVC  NCP       CAEC SMOKE  CH2O  \\\n",
       "0  Female  21.0    1.62    64.0  yes   no   2.0  3.0  Sometimes    no   2.0   \n",
       "1  Female  21.0    1.52    56.0  yes   no   3.0  3.0  Sometimes   yes   3.0   \n",
       "2    Male  23.0    1.80    77.0  yes   no   2.0  3.0  Sometimes    no   2.0   \n",
       "3    Male  27.0    1.80    87.0   no   no   3.0  3.0  Sometimes    no   2.0   \n",
       "4    Male  22.0    1.78    89.8   no   no   2.0  1.0  Sometimes    no   2.0   \n",
       "\n",
       "   SCC  FAF  TUE        CALC                 MTRANS                  OLD  \n",
       "0   no  0.0  1.0          no  Public_Transportation        Normal_Weight  \n",
       "1  yes  3.0  0.0   Sometimes  Public_Transportation        Normal_Weight  \n",
       "2   no  2.0  1.0  Frequently  Public_Transportation        Normal_Weight  \n",
       "3   no  2.0  0.0  Frequently                Walking   Overweight_Level_I  \n",
       "4   no  0.0  0.0   Sometimes  Public_Transportation  Overweight_Level_II  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# silence warnings concerning replace() method being removed on pandas 3.0\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "dataset = pd.read_csv(\"data/OCDDataset/ObesityDataSet.csv\")\n",
    "\n",
    "# reducing labels names size\n",
    "dataset.rename(\n",
    "    columns={\n",
    "        \"family_history_with_overweight\": \"FHWO\",\n",
    "        \"NObeyesdad\": \"OLD\",\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can observe a sample of the dataset. To make the dataset more compatible with machine learning, we'll start by converting features that have \"yes\" or \"no\" values into their boolean representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>FHWO</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>OLD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.52</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Walking</td>\n",
       "      <td>Overweight_Level_I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>89.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender   Age  Height  Weight  FHWO  FAVC  FCVC  NCP       CAEC  SMOKE  \\\n",
       "0  Female  21.0    1.62    64.0     1     0   2.0  3.0  Sometimes      0   \n",
       "1  Female  21.0    1.52    56.0     1     0   3.0  3.0  Sometimes      1   \n",
       "2    Male  23.0    1.80    77.0     1     0   2.0  3.0  Sometimes      0   \n",
       "3    Male  27.0    1.80    87.0     0     0   3.0  3.0  Sometimes      0   \n",
       "4    Male  22.0    1.78    89.8     0     0   2.0  1.0  Sometimes      0   \n",
       "\n",
       "   CH2O  SCC  FAF  TUE        CALC                 MTRANS                  OLD  \n",
       "0   2.0    0  0.0  1.0          no  Public_Transportation        Normal_Weight  \n",
       "1   3.0    1  3.0  0.0   Sometimes  Public_Transportation        Normal_Weight  \n",
       "2   2.0    0  2.0  1.0  Frequently  Public_Transportation        Normal_Weight  \n",
       "3   2.0    0  2.0  0.0  Frequently                Walking   Overweight_Level_I  \n",
       "4   2.0    0  0.0  0.0   Sometimes  Public_Transportation  Overweight_Level_II  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: convert values\n",
    "strToBinDict = {\"yes\": 1, \"no\": 0}\n",
    "dataset[\"FHWO\"] = dataset[\"FHWO\"].replace(strToBinDict).astype(\"int8\")\n",
    "dataset[\"FAVC\"] = dataset[\"FAVC\"].replace(strToBinDict).astype(\"int8\")\n",
    "dataset[\"SMOKE\"] = dataset[\"SMOKE\"].replace(strToBinDict).astype(\"int8\")\n",
    "dataset[\"SCC\"] = dataset[\"SCC\"].replace(strToBinDict).astype(\"int8\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will convert the `CAEC` and `CALC` columns, which contain the values \"Always,\" \"Frequently,\" \"Sometimes,\" and \"no,\" into a numerical scale from 0.00 to 1.00 based on their frequency. Here's the conversion table:\n",
    "\n",
    "| **Adjective** | **Conversion Value** |\n",
    "|---------------|:--------------------:|\n",
    "| Always        |         1.0          |\n",
    "| Frequently    |         0.66         |\n",
    "| Sometimes     |         0.33         |\n",
    "| no            |         0.0          |\n",
    "\n",
    "We'll apply a similar procedure as before to achieve this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>FHWO</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>OLD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.52</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>Walking</td>\n",
       "      <td>Overweight_Level_I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>89.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender   Age  Height  Weight  FHWO  FAVC  FCVC  NCP  CAEC  SMOKE  CH2O  \\\n",
       "0  Female  21.0    1.62    64.0     1     0   2.0  3.0  0.33      0   2.0   \n",
       "1  Female  21.0    1.52    56.0     1     0   3.0  3.0  0.33      1   3.0   \n",
       "2    Male  23.0    1.80    77.0     1     0   2.0  3.0  0.33      0   2.0   \n",
       "3    Male  27.0    1.80    87.0     0     0   3.0  3.0  0.33      0   2.0   \n",
       "4    Male  22.0    1.78    89.8     0     0   2.0  1.0  0.33      0   2.0   \n",
       "\n",
       "   SCC  FAF  TUE  CALC                 MTRANS                  OLD  \n",
       "0    0  0.0  1.0  0.00  Public_Transportation        Normal_Weight  \n",
       "1    1  3.0  0.0  0.33  Public_Transportation        Normal_Weight  \n",
       "2    0  2.0  1.0  0.66  Public_Transportation        Normal_Weight  \n",
       "3    0  2.0  0.0  0.66                Walking   Overweight_Level_I  \n",
       "4    0  0.0  0.0  0.33  Public_Transportation  Overweight_Level_II  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjToValDict = {\"Always\": 1.0, \"Frequently\": 0.66, \"Sometimes\": 0.33, \"no\": 0.0}\n",
    "dataset[\"CAEC\"] = dataset[\"CAEC\"].replace(adjToValDict).astype('float64')\n",
    "dataset[\"CALC\"] = dataset[\"CALC\"].replace(adjToValDict).astype('float64')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll address three additional columns named Gender, MTRANS, and OLD, which currently contain non-numerical values. These values represent individual options and cannot be quantified using a scale like before. Instead, we'll encode them using a technique called \"one hot encoding.\" This technique will assign a binary value to each option, representing its presence or absence. Let's proceed with applying one hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>FHWO</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>...</th>\n",
       "      <th>MTRANS_Motorbike</th>\n",
       "      <th>MTRANS_Public_Transportation</th>\n",
       "      <th>MTRANS_Walking</th>\n",
       "      <th>OLD_Insufficient_Weight</th>\n",
       "      <th>OLD_Normal_Weight</th>\n",
       "      <th>OLD_Obesity_Type_I</th>\n",
       "      <th>OLD_Obesity_Type_II</th>\n",
       "      <th>OLD_Obesity_Type_III</th>\n",
       "      <th>OLD_Overweight_Level_I</th>\n",
       "      <th>OLD_Overweight_Level_II</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.52</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>89.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender_Female  Gender_Male   Age  Height  Weight  FHWO  FAVC  FCVC  NCP  \\\n",
       "0              1            0  21.0    1.62    64.0     1     0   2.0  3.0   \n",
       "1              1            0  21.0    1.52    56.0     1     0   3.0  3.0   \n",
       "2              0            1  23.0    1.80    77.0     1     0   2.0  3.0   \n",
       "3              0            1  27.0    1.80    87.0     0     0   3.0  3.0   \n",
       "4              0            1  22.0    1.78    89.8     0     0   2.0  1.0   \n",
       "\n",
       "   CAEC  ...  MTRANS_Motorbike  MTRANS_Public_Transportation  MTRANS_Walking  \\\n",
       "0  0.33  ...                 0                             1               0   \n",
       "1  0.33  ...                 0                             1               0   \n",
       "2  0.33  ...                 0                             1               0   \n",
       "3  0.33  ...                 0                             0               1   \n",
       "4  0.33  ...                 0                             1               0   \n",
       "\n",
       "   OLD_Insufficient_Weight  OLD_Normal_Weight  OLD_Obesity_Type_I  \\\n",
       "0                        0                  1                   0   \n",
       "1                        0                  1                   0   \n",
       "2                        0                  1                   0   \n",
       "3                        0                  0                   0   \n",
       "4                        0                  0                   0   \n",
       "\n",
       "   OLD_Obesity_Type_II  OLD_Obesity_Type_III  OLD_Overweight_Level_I  \\\n",
       "0                    0                     0                       0   \n",
       "1                    0                     0                       0   \n",
       "2                    0                     0                       0   \n",
       "3                    0                     0                       1   \n",
       "4                    0                     0                       0   \n",
       "\n",
       "   OLD_Overweight_Level_II  \n",
       "0                        0  \n",
       "1                        0  \n",
       "2                        0  \n",
       "3                        0  \n",
       "4                        1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genderCols = pd.get_dummies(dataset[\"Gender\"], prefix=\"Gender\",prefix_sep='_', dtype='int8')\n",
    "mtransCols = pd.get_dummies(dataset[\"MTRANS\"], prefix=\"MTRANS\",prefix_sep='_', dtype='int8')\n",
    "oldCols = pd.get_dummies(dataset[\"OLD\"], prefix=\"OLD\",prefix_sep='_', dtype='int8')\n",
    "dataset = pd.concat([genderCols, dataset.iloc[:,:16], mtransCols,  dataset.iloc[:,16:], oldCols], axis=1)\n",
    "dataset.drop([\"Gender\", \"MTRANS\", \"OLD\"], axis=1, inplace=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our dataset is prepared to be used, let's ensure the data's integrity by verifying some information, starting with a general overview of our columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2111 entries, 0 to 2110\n",
      "Data columns (total 28 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Gender_Female                 2111 non-null   int8   \n",
      " 1   Gender_Male                   2111 non-null   int8   \n",
      " 2   Age                           2111 non-null   float64\n",
      " 3   Height                        2111 non-null   float64\n",
      " 4   Weight                        2111 non-null   float64\n",
      " 5   FHWO                          2111 non-null   int8   \n",
      " 6   FAVC                          2111 non-null   int8   \n",
      " 7   FCVC                          2111 non-null   float64\n",
      " 8   NCP                           2111 non-null   float64\n",
      " 9   CAEC                          2111 non-null   float64\n",
      " 10  SMOKE                         2111 non-null   int8   \n",
      " 11  CH2O                          2111 non-null   float64\n",
      " 12  SCC                           2111 non-null   int8   \n",
      " 13  FAF                           2111 non-null   float64\n",
      " 14  TUE                           2111 non-null   float64\n",
      " 15  CALC                          2111 non-null   float64\n",
      " 16  MTRANS_Automobile             2111 non-null   int8   \n",
      " 17  MTRANS_Bike                   2111 non-null   int8   \n",
      " 18  MTRANS_Motorbike              2111 non-null   int8   \n",
      " 19  MTRANS_Public_Transportation  2111 non-null   int8   \n",
      " 20  MTRANS_Walking                2111 non-null   int8   \n",
      " 21  OLD_Insufficient_Weight       2111 non-null   int8   \n",
      " 22  OLD_Normal_Weight             2111 non-null   int8   \n",
      " 23  OLD_Obesity_Type_I            2111 non-null   int8   \n",
      " 24  OLD_Obesity_Type_II           2111 non-null   int8   \n",
      " 25  OLD_Obesity_Type_III          2111 non-null   int8   \n",
      " 26  OLD_Overweight_Level_I        2111 non-null   int8   \n",
      " 27  OLD_Overweight_Level_II       2111 non-null   int8   \n",
      "dtypes: float64(10), int8(18)\n",
      "memory usage: 202.2 KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's verify that there are no missing values in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender_Female                   0\n",
       "Gender_Male                     0\n",
       "Age                             0\n",
       "Height                          0\n",
       "Weight                          0\n",
       "FHWO                            0\n",
       "FAVC                            0\n",
       "FCVC                            0\n",
       "NCP                             0\n",
       "CAEC                            0\n",
       "SMOKE                           0\n",
       "CH2O                            0\n",
       "SCC                             0\n",
       "FAF                             0\n",
       "TUE                             0\n",
       "CALC                            0\n",
       "MTRANS_Automobile               0\n",
       "MTRANS_Bike                     0\n",
       "MTRANS_Motorbike                0\n",
       "MTRANS_Public_Transportation    0\n",
       "MTRANS_Walking                  0\n",
       "OLD_Insufficient_Weight         0\n",
       "OLD_Normal_Weight               0\n",
       "OLD_Obesity_Type_I              0\n",
       "OLD_Obesity_Type_II             0\n",
       "OLD_Obesity_Type_III            0\n",
       "OLD_Overweight_Level_I          0\n",
       "OLD_Overweight_Level_II         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll ensure that there are no duplicated records in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.drop_duplicates()\n",
    "dataset.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we need to split our dataset into two distinct datasets, one for the training process and the other for the tests process. Then write them in separate files to allow them to be used by the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of records:\t2087\n",
      "Number of records for training:\t1565\n",
      "Number of records for testing:\t522\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nRecords = dataset.shape[0]\n",
    "trainSplit = int(0.75 * nRecords)\n",
    "\n",
    "trainds = dataset.iloc[:trainSplit, :]\n",
    "testds = dataset.iloc[trainSplit:, :]\n",
    "\n",
    "print(\n",
    "f\"\"\"\n",
    "Total number of records:\\t{nRecords}\n",
    "Number of records for training:\\t{trainds.shape[0]}\n",
    "Number of records for testing:\\t{testds.shape[0]}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# We are writing .txt files to comply with our random forest algorithm\n",
    "path = \"data/OCDDataset/\"\n",
    "trainfile = \"train_dataset.txt\"\n",
    "testfile = \"test_dataset.txt\"\n",
    "\n",
    "trainds.to_csv(path + trainfile, header=False, index=False)\n",
    "testds.to_csv(path + testfile, header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data is ready and checked for any missing or duplicate values, we're all set to move on to the next step. In the upcoming chapter, we'll use our prepared dataset to train our Random Forest model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's dig into the main part of our task: training our model. To do so, we're going to use a type of model called random forests. Random forests are a type of machine learning model that works by creating a multitude of decision trees during training. Each tree independently makes predictions, and the final prediction is determined by averaging the predictions of all the trees (for regression tasks) or taking a majority vote (for classification tasks). \n",
    "\n",
    "In this case, we are going to use a Python program called [randForestsTrn](https://github.com/HES-XPLAIN/dimlpfidex/blob/main/trainings/randForestsTrn.py). Let's begin with importing the script and printing its help message to observe every option available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: \n",
      "--train_data_file <str> --test_data_file <str> --nb_attributes <int [1,inf[> --nb_classes <int [1,inf[> [-h, --help] [--json_config_file <str>] [--root_folder <str>] [--train_class_file <str>] [--train_pred_outfile <str>] [--test_class_file <str>] [--test_pred_outfile <str>] [--console_file <str>] [--stats_file <str>] [--rules_outfile <str>] [--n_estimators <int [1,inf[>] [--criterion <{gini, entropy, log_loss}>] [--max_depth <int [1,inf[>] [--min_samples_split <int [2,inf[ U float]0,1.0]>] [--min_samples_leaf <int [1,inf[ U float]0,1[>] [--min_weight_fraction_leaf <float [0,0.5]>] [--max_features <{sqrt, log2, all, float ]0,1[, int [1,inf[}>] [--max_leaf_nodes <int [2,inf[>] [--min_impurity_decrease <float [0,inf[>] [--bootstrap <bool>] [--oob_score <bool>] [--n_jobs <int>] [--seed <{int [0,inf[}>] [--verbose <int [0,inf[>] [--warm_start <bool>] [--class_weight <{balanced, dict}>] [--ccp_alpha <float [0,inf[>] [--max_samples <int [1,inf[ U float]0,1.0]>]\n",
      "\n",
      "This is a parser for randForestsTrn\n",
      "\n",
      "\n",
      "Parameters:\n",
      "\n",
      "  ---------------------------------------------------------------------\n",
      "\n",
      "  Warning! The files are localised with respect to root folder dimlpfidex.\n",
      "\n",
      "  The arguments can be specified in the command or in a json configuration file with --json_config_file your_config_file.json.\n",
      "\n",
      "  ----------------------------\n",
      "\n",
      "  Required parameters:\n",
      "\n",
      "  --train_data_file <str>                                   Train data file\n",
      "  --test_data_file <str>                                    Test data file\n",
      "  --nb_attributes <int [1,inf[>                             Number of attributes in dataset\n",
      "  --nb_classes <int [1,inf[>                                Number of classes in dataset\n",
      "\n",
      "  ----------------------------\n",
      "\n",
      "  Optional parameters:\n",
      "\n",
      "  -h --help                                                 show this help message and exit\n",
      "  --json_config_file <str>                                  JSON file to configure all parameters. If used, this must be the sole argument and must\n",
      "                                                            specify the file's relative path\n",
      "  --root_folder <str>                                       Folder based on main folder dimlpfidex(default folder) containg all used files and where\n",
      "                                                            generated files will be saved. If a file name is specified with another option, his path\n",
      "                                                            will be configured with respect to this root folder> (default: \"\")\n",
      "  --train_class_file <str>                                  Train class file, mandatory if classes are not specified in train_data_file\n",
      "  --train_pred_outfile <str>                                Output train prediction file name (default: predTrain.out)\n",
      "  --test_class_file <str>                                   Test class file, mandatory if classes are not specified in test_data_file\n",
      "  --test_pred_outfile <str>                                 Output test prediction file name (default: predTest.out)\n",
      "  --console_file <str>                                      File with console logs redirection\n",
      "  --stats_file <str>                                        Output statistic file name with train and test accuracy (default: stats.txt)\n",
      "  --rules_outfile <str>                                     Output random forests rules file (default: RF_rules.rls)\n",
      "\n",
      "  ----------------------------\n",
      "\n",
      "  RF parameters (optional):\n",
      "\n",
      "  --n_estimators <int [1,inf[>                              Number of generated trees in the forest (default: 100)\n",
      "  --criterion <{gini, entropy, log_loss}>                   Function to measure split quality (default: gini)\n",
      "  --max_depth <int [1,inf[>                                 Maximum depth of the tree\n",
      "  --min_samples_split <int [2,inf[ U float]0,1.0]>          Minimum number of samples required to split an internal node, if float, it is a fraction\n",
      "                                                            of the number of samples. (default: 2)\n",
      "  --min_samples_leaf <int [1,inf[ U float]0,1[>             Minimum number of samples required to be at a leaf node, if float, it is a fraction of the\n",
      "                                                            number of samples (default: 1)\n",
      "  --min_weight_fraction_leaf <float [0,0.5]>                Minimum weighted fraction of the sum total of input samples weights required to be at a\n",
      "                                                            leaf node (default: 0.0)\n",
      "  --max_features <{sqrt, log2, all, float ]0,1[, int [1,inf[}>\n",
      "                                                            Number of features to consider when looking for the best splitif float, it is a fraction\n",
      "                                                            of the number of features. 1 stands for 1 feature, for all features put 'all', not 1.0\n",
      "                                                            (default: sqrt)\n",
      "  --max_leaf_nodes <int [2,inf[>                            Grow trees with max_leaf_nodes in best-first fashion\n",
      "  --min_impurity_decrease <float [0,inf[>                   A node will be split if this split induces a decrease of the impurity greater than or\n",
      "                                                            equal to this value (default: 0.0)\n",
      "  --bootstrap <bool>                                        Whether bootstrap samples are used when building trees (default: True)\n",
      "  --oob_score <bool>                                        Whether to use out-of-bag samples to estimate the generalization score (default: False)\n",
      "  --n_jobs <int>                                            Number of jobs to run in parallel, -1 = using all processors (default: 1)\n",
      "  --seed <{int [0,inf[}>                                    Random seed\n",
      "  --verbose <int [0,inf[>                                   Controls the verbosity when fitting and predicting (default: 0)\n",
      "  --warm_start <bool>                                       Whether to reuse the solution of the previous call to fit and add more estimators to the\n",
      "                                                            ensemble (default: False)\n",
      "  --class_weight <{balanced, dict}>                         Class balance, for exemple with a dictionnary and 2 classes : {0:1.2, 1:3.5}\n",
      "  --ccp_alpha <float [0,inf[>                               Complexity parameter used for Minimal Cost-Complexity Pruning (default: 0.0)\n",
      "  --max_samples <int [1,inf[ U float]0,1.0]>                Number of samples to draw to train each base estimator for bootstrap, if float, it is a\n",
      "                                                            fraction of the number of samples\n",
      "\n",
      "  ----------------------------\n",
      "\n",
      "Execution example :\n",
      "\n",
      "randForestsTrn('--train_data_file datanormTrain.txt --train_class_file dataclass2Train.txt --test_data_file datanormTest.txt --test_class_file dataclass2Test.txt --stats_file rf/stats.txt --train_pred_outfile rf/predTrain.out --test_pred_outfile rf/predTest.out --rules_outfile rf/RF_rules.rls --nb_attributes 16 --nb_classes 2 --root_folder dimlp/datafiles')\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trainings.randForestsTrn import randForestsTrn as randomForest\n",
    "\n",
    "randomForest(\"--help\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output shows several options available. From all those, we're going to focus on the required parameters (and the `--root_folder` for convenience purposes) only for now. We already have the train and test data files (generated in the last chapter). Now we just have to get the number of attributes and number of classes. As we know, the original class is `OLD`, as it has been one hotted. We need to count the number of labels with the `OLD` prefix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# attributes:\t21\n",
      "# classes:\t7\n"
     ]
    }
   ],
   "source": [
    "labels = list(dataset.columns)\n",
    "\n",
    "nclasses = sum(1 for label in labels if label.startswith(\"OLD_\"))\n",
    "nattributes = len(labels) - nclasses\n",
    "\n",
    "print(f\"# attributes:\\t{nattributes}\\n# classes:\\t{nclasses}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now, lets gather the elements we have to run the model:\n",
    "\n",
    "| **Parameter name** | **Input**           |\n",
    "|--------------------|:-------------------:|\n",
    "| --root_folder      | data/OCDDataset/    |\n",
    "| --train_data_file  | train_dataset.txt   |\n",
    "| --test_data_file   | test_dataset.txt    |\n",
    "| --nb_attributes    | 21                  |\n",
    "| --nb_classes       | 7                   |\n",
    "\n",
    "We can now try to run our random forest model with it and let the rest of the options be decided be the defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters list:\n",
      " - root_folder                                                   data/OCDDataset/\n",
      " - train_data_file                                               data/OCDDataset/train_dataset.txt\n",
      " - train_pred_outfile                                            data/OCDDataset/predTrain.out\n",
      " - test_data_file                                                data/OCDDataset/test_dataset.txt\n",
      " - test_pred_outfile                                             data/OCDDataset/predTest.out\n",
      " - stats_file                                                    data/OCDDataset/stats.txt\n",
      " - nb_attributes                                                 21\n",
      " - nb_classes                                                    7\n",
      " - rules_outfile                                                 data/OCDDataset/RF_rules.rls\n",
      " - n_estimators                                                  100\n",
      " - criterion                                                     gini\n",
      " - min_samples_split                                             2\n",
      " - min_samples_leaf                                              1\n",
      " - min_weight_fraction_leaf                                      0.0\n",
      " - max_features                                                  sqrt\n",
      " - min_impurity_decrease                                         0.0\n",
      " - bootstrap                                                     True\n",
      " - oob_score                                                     False\n",
      " - n_jobs                                                        1\n",
      " - verbose                                                       0\n",
      " - warm_start                                                    False\n",
      " - ccp_alpha                                                     0.0\n",
      "End of Parameters list. \n",
      "\n",
      "Training accuracy : 100%.\n",
      "Testing accuracy : 99.425287%.\n",
      "\n",
      "Full execution time = 0.794832 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = f\"--root_folder {path} --train_data_file {trainfile} --test_data_file {testfile} --nb_attributes {nattributes} --nb_classes {nclasses}\"\n",
    "randomForest(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm ended and generated a `rule_outfile` file. It contains all rules generated by each tree from the random forest. Lets visualize some of the first tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "Tree 1\n",
      "-------------------\n",
      "Rule 1: X13<=2.9698665142059326 X8<=3.087331533432007 X5<=0.5 X1<=0.5 X14<=1.9864630103111267 X9<=0.4950000196695328 X7<=1.9308720231056213 -> class 0 Covering: [1, 0, 0, 0, 0, 0, 0]\n",
      "Rule 2: X13<=2.9698665142059326 X8<=3.087331533432007 X5<=0.5 X1<=0.5 X14<=1.9864630103111267 X9<=0.4950000196695328 X7>1.9308720231056213 X14<=1.0007025003433228 X3<=1.5588060021400452 X13<=1.632308006286621 X14<=0.3588874936103821 X4<=49.17173194885254 -> class 0 Covering: [1, 0, 0, 0, 0, 0, 0]\n",
      "Rule 3: X13<=2.9698665142059326 X8<=3.087331533432007 X5<=0.5 X1<=0.5 X14<=1.9864630103111267 X9<=0.4950000196695328 X7>1.9308720231056213 X14<=1.0007025003433228 X3<=1.5588060021400452 X13<=1.632308006286621 X14<=0.3588874936103821 X4>49.17173194885254 X2<=25.41852855682373 X4<=59.31416130065918 X2<=19.5 -> class 5 Covering: [0, 0, 0, 0, 0, 1, 0]\n",
      "Rule 4: X13<=2.9698665142059326 X8<=3.087331533432007 X5<=0.5 X1<=0.5 X14<=1.9864630103111267 X9<=0.4950000196695328 X7>1.9308720231056213 X14<=1.0007025003433228 X3<=1.5588060021400452 X13<=1.632308006286621 X14<=0.3588874936103821 X4>49.17173194885254 X2<=25.41852855682373 X4<=59.31416130065918 X2>19.5 -> class 1 Covering: [0, 1, 0, 0, 0, 0, 0]\n",
      "Rule 5: X13<=2.9698665142059326 X8<=3.087331533432007 X5<=0.5 X1<=0.5 X14<=1.9864630103111267 X9<=0.4950000196695328 X7>1.9308720231056213 X14<=1.0007025003433228 X3<=1.5588060021400452 X13<=1.632308006286621 X14<=0.3588874936103821 X4>49.17173194885254 X2<=25.41852855682373 X4>59.31416130065918 -> class 5 Covering: [0, 0, 0, 0, 0, 1, 0]\n",
      "Rule 6: X13<=2.9698665142059326 X8<=3.087331533432007 X5<=0.5 X1<=0.5 X14<=1.9864630103111267 X9<=0.4950000196695328 X7>1.9308720231056213 X14<=1.0007025003433228 X3<=1.5588060021400452 X13<=1.632308006286621 X14<=0.3588874936103821 X4>49.17173194885254 X2>25.41852855682373 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 7: X13<=2.9698665142059326 X8<=3.087331533432007 X5<=0.5 X1<=0.5 X14<=1.9864630103111267 X9<=0.4950000196695328 X7>1.9308720231056213 X14<=1.0007025003433228 X3<=1.5588060021400452 X13<=1.632308006286621 X14>0.3588874936103821 -> class 5 Covering: [0, 0, 0, 0, 0, 1, 0]\n",
      "Rule 8: X13<=2.9698665142059326 X8<=3.087331533432007 X5<=0.5 X1<=0.5 X14<=1.9864630103111267 X9<=0.4950000196695328 X7>1.9308720231056213 X14<=1.0007025003433228 X3<=1.5588060021400452 X13>1.632308006286621 -> class 0 Covering: [1, 0, 0, 0, 0, 0, 0]\n",
      "Rule 9: X13<=2.9698665142059326 X8<=3.087331533432007 X5<=0.5 X1<=0.5 X14<=1.9864630103111267 X9<=0.4950000196695328 X7>1.9308720231056213 X14<=1.0007025003433228 X3>1.5588060021400452 X2<=29.5 X4<=50.5 X3<=1.6366044878959656 X11<=2.120803475379944 -> class 1 Covering: [0, 1, 0, 0, 0, 0, 0]\n",
      "Rule 10: X13<=2.9698665142059326 X8<=3.087331533432007 X5<=0.5 X1<=0.5 X14<=1.9864630103111267 X9<=0.4950000196695328 X7>1.9308720231056213 X14<=1.0007025003433228 X3>1.5588060021400452 X2<=29.5 X4<=50.5 X3<=1.6366044878959656 X11>2.120803475379944 -> class 0 Covering: [1, 0, 0, 0, 0, 0, 0]\n",
      "Rule 11: X13<=2.9698665142059326 X8<=3.087331533432007 X5<=0.5 X1<=0.5 X14<=1.9864630103111267 X9<=0.4950000196695328 X7>1.9308720231056213 X14<=1.0007025003433228 X3>1.5588060021400452 X2<=29.5 X4<=50.5 X3>1.6366044878959656 -> class 0 Covering: [1, 0, 0, 0, 0, 0, 0]\n",
      "Rule 12: X13<=2.9698665142059326 X8<=3.087331533432007 X5<=0.5 X1<=0.5 X14<=1.9864630103111267 X9<=0.4950000196695328 X7>1.9308720231056213 X14<=1.0007025003433228 X3>1.5588060021400452 X2<=29.5 X4>50.5 X4<=61.308000564575195 -> class 1 Covering: [0, 1, 0, 0, 0, 0, 0]\n",
      "Rule 13: X13<=2.9698665142059326 X8<=3.087331533432007 X5<=0.5 X1<=0.5 X14<=1.9864630103111267 X9<=0.4950000196695328 X7>1.9308720231056213 X14<=1.0007025003433228 X3>1.5588060021400452 X2<=29.5 X4>50.5 X4>61.308000564575195 X3<=1.6150000095367432 -> class 5 Covering: [0, 0, 0, 0, 0, 1, 0]\n",
      "Rule 14: X13<=2.9698665142059326 X8<=3.087331533432007 X5<=0.5 X1<=0.5 X14<=1.9864630103111267 X9<=0.4950000196695328 X7>1.9308720231056213 X14<=1.0007025003433228 X3>1.5588060021400452 X2<=29.5 X4>50.5 X4>61.308000564575195 X3>1.6150000095367432 -> class 1 Covering: [0, 1, 0, 0, 0, 0, 0]\n",
      "Rule 15: X13<=2.9698665142059326 X8<=3.087331533432007 X5<=0.5 X1<=0.5 X14<=1.9864630103111267 X9<=0.4950000196695328 X7>1.9308720231056213 X14<=1.0007025003433228 X3>1.5588060021400452 X2>29.5 X11<=2.0650395154953003 -> class 5 Covering: [0, 0, 0, 0, 0, 1, 0]\n",
      "Rule 16: X13<=2.9698665142059326 X8<=3.087331533432007 X5<=0.5 X1<=0.5 X14<=1.9864630103111267 X9<=0.4950000196695328 X7>1.9308720231056213 X14<=1.0007025003433228 X3>1.5588060021400452 X2>29.5 X11>2.0650395154953003 -> class 6 Covering: [0, 0, 0, 0, 0, 0, 1]\n",
      "Rule 17: X13<=2.9698665142059326 X8<=3.087331533432007 X5<=0.5 X1<=0.5 X14<=1.9864630103111267 X9<=0.4950000196695328 X7>1.9308720231056213 X14>1.0007025003433228 X13<=0.3751315027475357 X2<=17.728906631469727 -> class 5 Covering: [0, 0, 0, 0, 0, 1, 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nlinesToVisualize = 20\n",
    "rulesFilePath = path + \"RF_rules.rls\" # if you used the --rules_outfile option when running randomForest(), please don't forget to adapt this according to your input\n",
    "lines = \"\"\n",
    "\n",
    "with open(rulesFilePath) as f:\n",
    "    for _ in range(nlinesToVisualize):\n",
    "        lines += next(f) \n",
    "\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: explain what we see here\n",
    "\n",
    "Now we trained and generated our set of rules, lets use Fidex to sort them (TODO complete this)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local rules generation - Fidex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global ruleSet generation - FidexGlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
