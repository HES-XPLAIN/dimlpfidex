{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6032ef9f-92e2-44dc-a11b-b224342bee29",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Exploring Dimlp and Fidex rule generation for breast cancer classification\n",
    "\n",
    "**Introduction:**\n",
    "\n",
    "Welcome to HES-Xplain, our interactive platform designed to facilitate explainable artificial intelligence (XAI) techniques. In this use case, we dive into breast cancer classification and showcase the power of Dimlp and Fidex as interpretability tools.\n",
    "\n",
    "In the medical field, there are many machine-learning models that can obtain results. These models are like black boxes that return results without fully understanding the reasoning leading to them. Depending on the nature of the problem it's important to understand the model's decision. It's difficult for a doctor or a patient to make a decision based on a model that we don't understand. Likewise, insurance companies will not necessarily agree to pay for a medication that a model has advised people to take. This is why explainability in this field is important.\n",
    "\n",
    "Fidex is an algorithm used in classification problems that allows us to obtain a rule explaining the decision class of the model for a given test sample. It enables us to grasp the model's decision-making process and to better understand the importance of each parameter in discerning the nature of the tumor, distinguishing between benign and malignant cases.\n",
    "\n",
    "The global version of Fidex, FidexGlo, allows us to get a set of rules that englobes all the decision-making process for the entire training set. We can then check if a new sample verifies all the properties of one rule of the ruleset, in which case this rule explains the model's decision.\n",
    "\n",
    "Our goal is to demonstrate how HES-Xplain empowers users to explore and interpret breast cancer classification effectively. By the end of this use case, you'll have a solid understanding of how to use Dimlp to train the model and the Fidex algorithms into your own classification datasets.\n",
    "\n",
    "**Objectives:**\n",
    "\n",
    "    1. Understand the importance of interpretability in medical problems.\n",
    "    2. Introduce Dimlp and Fidex as powerful XAI techniques.\n",
    "    3. Understand how to use Dimlp and Fidex.\n",
    "    4. Showcase the capabilities of HES-Xplain in implementing Dimlp and Fidex algorithms.\n",
    "    5. Provide practical insights into applying Dimlp and Fidex to breast cancer classifiers through an interactive notebook.\n",
    "    6. Foster a community of XAI enthusiasts and practitioners.\n",
    "\n",
    "**Outline:**\n",
    "\n",
    "    1. Dataset and Problem Statement.\n",
    "    2. Load the dataset.\n",
    "    3. Training of the Model.\n",
    "    4. Local rules generation - Fidex\n",
    "    5. Global ruleSet generation - FidexGlo\n",
    "    6. Conclusion.\n",
    "    7. References.\n",
    "\n",
    "Through this use case, we aim to empower users to grasp the potential of Dimlp and Fidex as tools for transparent and interpretable classification. With HES-Xplain, we make XAI accessible, helping users build trust in their models and make informed decisions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f882f8-9ee5-44a3-9091-bc5cd14c896e",
   "metadata": {},
   "source": [
    "# Dataset and Problem Statement\n",
    "\n",
    "The Breast Cancer Dataset used in this use case consists of 569 data samples representing patients who have tumors. Each patient has 30 attributes, computed out of an image, used to determine if the tumor is malignant (first class) or benign (second class). This dataset is available on [Kaggle](https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data) and can be imported with sklearn. It is composed of 455 training samples and 114 testing samples. \n",
    "\n",
    "The 30 attributes are composed of 10 real-valued features computed for each cell nucleus :\n",
    "\n",
    "- **Radius**: Mean of distances from the center to points on the perimeter.\n",
    "- **Texture**: Standard deviation of gray-scale values.\n",
    "- **Perimeter**\n",
    "- **Area**\n",
    "- **Smoothness**: Local variation in radius lengths.\n",
    "- **Compactness**: $\\frac{\\text{perimeter}^2}{\\text{area}} - 1.0$\n",
    "- **Concavity**: Severity of concave portions of the contour.\n",
    "- **Concave Points**: Number of concave portions of the contour.\n",
    "- **Symmetry**\n",
    "- **Fractal Dimension**: \"Coastline approximation\" - 1.\n",
    "\n",
    "For each tumor image, the mean, standard error, and worst errors were computed and appear as different attributes.\n",
    "\n",
    "**Problem Statement:** Our objective is to build a robust classifier capable of accurately classifying breast cancer samples among the 2 classes. By leveraging deep learning techniques and Fidex algorithms, we aim to not only achieve high classification performance but also gain insights into the attributes that contribute to the classification decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfedb29-a2b0-4a64-9958-da3f1463a78d",
   "metadata": {},
   "source": [
    "# Load the dataset\n",
    "First of all, we unbuffer Python output so that it prints the result as soon as possible (you won't need to do this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c2697a5-c92e-40a6-86ce-018b897baea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unbuffered(object):\n",
    "   def __init__(self, stream):\n",
    "       self.stream = stream\n",
    "   def write(self, data):\n",
    "       self.stream.write(data)\n",
    "       self.stream.flush()\n",
    "   def writelines(self, datas):\n",
    "       self.stream.writelines(datas)\n",
    "       self.stream.flush()\n",
    "   def __getattr__(self, attr):\n",
    "       return getattr(self.stream, attr)\n",
    "\n",
    "import sys\n",
    "sys.stdout = Unbuffered(sys.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dade571b-4876-45b5-9d09-a76791165a75",
   "metadata": {},
   "source": [
    "We start by loading the dataset. First, we need to download the data with sklearn and shuffle it randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd7b7b29-d07d-4750-820f-2270937d8ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "datas, classes = shuffle(datasets.load_breast_cancer().data, datasets.load_breast_cancer().target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f5257d-2146-4d30-915e-e34289e843ce",
   "metadata": {},
   "source": [
    "We normalize the data so that the model learns better. We save the mean and std in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fcc0424-b1a1-4c63-a44c-68c55e99f49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.41272917e+01 1.92896485e+01 9.19690334e+01 6.54889104e+02\n",
      " 9.63602812e-02 1.04340984e-01 8.87993158e-02 4.89191459e-02\n",
      " 1.81161863e-01 6.27976098e-02 4.05172056e-01 1.21685343e+00\n",
      " 2.86605923e+00 4.03370791e+01 7.04097891e-03 2.54781388e-02\n",
      " 3.18937163e-02 1.17961371e-02 2.05422988e-02 3.79490387e-03\n",
      " 1.62691898e+01 2.56772232e+01 1.07261213e+02 8.80583128e+02\n",
      " 1.32368594e-01 2.54265044e-01 2.72188483e-01 1.14606223e-01\n",
      " 2.90075571e-01 8.39458172e-02]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "means = np.mean(datas, axis=0)\n",
    "print(means)\n",
    "stds = np.std(datas, axis=0)\n",
    "normalized_datas = (datas - means) / stds\n",
    "\n",
    "with open(\"data/BCWDataset/normalisation.txt\", 'w') as myfile:\n",
    "    for i in range(len(means)):\n",
    "        myfile.write(\"Attribut \" + str(i) + \": mean: \" + str(means[i]) + \", std: \" + str(stds[i]) + '\\n')\n",
    "    myfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d87dd5-2233-43e2-9f95-777a1f7bda99",
   "metadata": {},
   "source": [
    "Then we define test and training sets by distributing the data so that there is one-fifth of the data for the test and four-fifths for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a0ed78b-b077-4136-84a6-9f176f33c223",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_samples = len(classes)\n",
    "cutoff = int((4/5)*nb_samples)\n",
    "train_classes = classes[:cutoff]\n",
    "train_datas = normalized_datas[:cutoff]\n",
    "test_classes = classes[cutoff:]\n",
    "test_datas = normalized_datas[cutoff:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d123e58b-b85d-4b43-9e1d-fcc11b65eaa3",
   "metadata": {},
   "source": [
    "We can display the number of training and testing data and check that there is the same number of data as classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ce94b0e-e7ab-4d8f-9082-cb57da8b17cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 455 train datas and 455 train classes\n",
      "There are 114 test datas and 114 test classes\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {len(train_datas)} train datas and {len(train_classes)} train classes\")\n",
    "print(f\"There are {len(test_datas)} test datas and {len(test_classes)} test classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7724b51a-a76f-4e3e-9e27-b1b0a40a148d",
   "metadata": {},
   "source": [
    "Finally, we save the data in text files in a specific format. We create a folder BCWDataset inside a data folder if it doesn't already exist and we save the files here.\n",
    "For the classes, we encode in one hot format, with 1 on the position of the right class and 0 elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a104b59-41da-4963-b799-70cb8544f8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def create_folder(folder_path):\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "        print(f\"Folder '{folder_path}' created successfully.\")\n",
    "\n",
    "def save_data(datafile, datas):\n",
    "    f = open(datafile, \"w\")\n",
    "    for data in datas:\n",
    "        for val in data:\n",
    "            f.write(str(val)+\" \")\n",
    "        f.write(\"\\n\")\n",
    "    f.close()\n",
    "\n",
    "def save_class(classfile, classes, nb_classes):\n",
    "    f = open(classfile, \"w\")\n",
    "    for classe in classes:\n",
    "        for i in range(nb_classes):\n",
    "            if classe == i:\n",
    "                f.write(\"1 \")\n",
    "            else:\n",
    "                f.write(\"0 \")\n",
    "        f.write(\"\\n\")\n",
    "    f.close()\n",
    "\n",
    "create_folder(\"data/BCWDataset\")\n",
    "\n",
    "nb_classes = len(datasets.load_breast_cancer().target_names)\n",
    "save_data(\"data/BCWDataset/datas.txt\", datas)\n",
    "save_data(\"data/BCWDataset/trainData.txt\", train_datas)\n",
    "save_data(\"data/BCWDataset/testData.txt\", test_datas)\n",
    "save_class(\"data/BCWDataset/trainClass.txt\", train_classes, nb_classes)\n",
    "save_class(\"data/BCWDataset/testClass.txt\", test_classes, nb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b34fc4-1e80-4eab-84ec-a0a4a28626fb",
   "metadata": {},
   "source": [
    "In order to generate beautiful and understandable rules, we still have to create an attribute file with attribute and class names.<br>\n",
    "For the attributes we have :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6634d478-316f-464d-9199-a8ea39883b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "attributes = datasets.load_breast_cancer().feature_names\n",
    "print(attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2ed3d0-cb53-4371-9ec8-76500422c93d",
   "metadata": {},
   "source": [
    "And for the classes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d5ee674-09b8-47a2-a927-d2b3de0c3c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "classes = datasets.load_breast_cancer().target_names\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb8d44f-be2c-485a-99dc-5e90ea7e74a1",
   "metadata": {},
   "source": [
    "We store the attributes and classes in a file attributes.txt and fill the spaces with _ and apply upper case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba892ed9-0ae5-4711-a998-07bc668764f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"data/BCWDataset/attributes.txt\", \"w\")\n",
    "for attribute in attributes:\n",
    "    f.write(attribute.upper().replace(\" \", \"_\")+\"\\n\")\n",
    "for classe in classes:\n",
    "    f.write(classe.upper().replace(\" \", \"_\")+\"\\n\")\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1c6815-e0b7-4231-bbcb-ea1b072b4ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65c01997-d95c-4c99-8ea4-3dfa31d7ba2f",
   "metadata": {},
   "source": [
    "# Training of the model\n",
    "\n",
    "We train the dimlp model. First, let's import it and display the parameters that are needed and optional for training. Dimlp is able to train the model as well as generate rules with his own algorithm. The Fidex algorithms are an improvement that we'll see later on. We choose the training with DimlpBT, which is the same as Dimlp but with bagging.\n",
    "The main package name is dimlpfidex, and we need the dimlp module where DimlpBT is located. To display the parameters, we can just call dimlpBT with no parameters, or with -h or --help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25fb49df-c5d9-402a-b48d-23b34c1108d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dimlpfidex'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdimlpfidex\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dimlp\n\u001b[1;32m      2\u001b[0m res \u001b[38;5;241m=\u001b[39m dimlp\u001b[38;5;241m.\u001b[39mdimlpBT(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdimlpBT\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dimlpfidex'"
     ]
    }
   ],
   "source": [
    "from dimlpfidex import dimlp\n",
    "res = dimlp.dimlpBT(\"--help\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cf5278-16aa-4455-8114-bd3c9b2a5359",
   "metadata": {},
   "source": [
    "Now we can run dimlpBT with the right parameters.<br>\n",
    "\n",
    "As we see in the parameter list, we need to give the train data file(--train_data_file), the number of input neurons of the model(--nb_attributes), which is the number of attributes, and the number of output neurons(--nb_classes) which is the number of classes.<br>\n",
    "For this dataset, we recommend adding a hidden layer (--hidden_layers) of size 5 or 10 in the model architecture. Here we choose 5.\n",
    "\n",
    "In the training file, we can also have the classes, but here we've chosen to save them in a different file, so we add it too with --train_class_file.<br>\n",
    "To get test predictions and statistics, we specify a test data file and test class file with --test_data_file and --test_class_file.<br>\n",
    "We choose the names for the files of statistics(--stats_file), train(--train_pred_outfile) and test predictions(--test_pred_outfile), and weights(--weights_outfile).<br>\n",
    "We specify with --root_folder the folder where we have all the data files and where we want to save the results. <br>\n",
    "\n",
    "This is enough to train our model, but we can add the computation of explaining rules with the Dimlp algorithm. You will be able to compare the rules obtained with the Dimlp algorithm and with the Fidex one. We just add --with_rule_extraction to ask for the computation of the rules, --global_rules_outfile to specify the name of the rules file, and --attributes_file, to give the attribute and class names that will appear in the rules.<br>\n",
    "\n",
    "As there are a lot of things to be written on output, we save the program output with --console_file. If you remove it you may have some neverending execution problem in the notebook. <br>\n",
    "\n",
    "To execute dimlpBT, we can either write the whole command (see the commented line below) or call a JSON configuration file (--json_config_file) containing each parameter as we want. All configuration files are located in the data folder. You can create new ones or modify them as you like by adding, removing, or modifying some parameters. To create a new file, we recommend you use our graphical user interface (GUI). <br>\n",
    "\n",
    "Additionally, we have a notebook that explains how to use this GUI, providing detailed instructions and practical examples. We encourage you to read this notebook to get the most out of our tools. You can access the notebook by following this link: **Link to the notebook**. <br>\n",
    "\n",
    "Here is how we execute dimlpBT :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e804d87b-b2dc-4946-9e99-caf1fa3fa066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of Weights folder if it doesn't exist\n",
    "create_folder(\"data/BCWDataset/Weights\")\n",
    "#result = dimlp.dimlpBT(\"dimlpBT -L trainData.txt -1 trainClass.txt -T testData.txt -2 testClass.txt -A attributes.txt -w Weights/weights -I 30 -O 2 -p predTrain.out -t predTest.out -R -F dimlpBTRules.rls -o stats.txt -r resultDimlpBT.txt -S data/BCWDataset\") \n",
    "result = dimlp.dimlpBT(\"--train_data_file trainData.txt --train_class_file trainClass.txt --test_data_file testData.txt --test_class_file testClass.txt --attributes_file attributes.txt --nb_attributes 30 --hidden_layers 5 --nb_classes 2 --weights_outfile Weights/weights.wts --with_rule_extraction true --global_rules_outfile dimlpBTRules.rls --train_pred_outfile predTrain.out --test_pred_outfile predTest.out --stats_file stats.txt --console_file resultDimlpBT.txt --root_folder data/BCWDataset\")\n",
    "result = dimlp.dimlpBT(\"--json_config_file data/config_dimlpBT.json\")\n",
    "if (result == 0):\n",
    "    print(\"Training done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c12044-2b09-4b7c-82b4-e6285ef55dfc",
   "metadata": {},
   "source": [
    "If you go to the folder data/BCWDataset and open the file result.txt, you can see that the training went through, and some rules were computed. You can now open the file stats.txt in the same folder to see the train and test accuracy as well as the sum squared errors. In the folder, you can also see the train and test predictions, the weights obtained for Fidex, and the dimlpRules.<br>\n",
    "\n",
    "In the file dimlpRules.txt, you can see the rule set, some statistics on the rules, and some statistics on the ruleset. Each rule is composed of antecedents and target class as well as the number of covering of the rule, which is the number of examples that verify(or \"activate\") the rule (even if the class is not correct).<br>\n",
    "\n",
    "For each rule, we have from left to right:<br>\n",
    "The number of covered samples, the number of correct covered samples, the number of false covered samples, and the accuracy of the rule.<br>\n",
    "\n",
    "The statistics of the ruleset are: <br>\n",
    "- The number of rules in the set\n",
    "- The mean total and the mean number of antecedents per rule\n",
    "- The covering of the rule\n",
    "- The rules' accuracy\n",
    "- The fidelity to the model, which is the percentage of covered samples that are correct with respect to the model's decision.\n",
    "- The model accuracy if we keep only the samples for which the model and the rules decision agree\n",
    "- The default rule activation rate, which is the percentage of samples for which no rule is activated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0865c6d-1648-4a61-8962-e81690b8d491",
   "metadata": {},
   "source": [
    "# Local rules generation - Fidex\n",
    "Now we can generate some local rules to explain the models' results. We can start with launching Fidex on one test sample. This will generate a rule explaining the sample locally. It is local because the algorithm searches a rule only for one sample.\n",
    "Fidex is located in the fidex module. Let's take a look at the parameters :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9478d54a-b460-40d0-8e0f-162d3d46bdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dimlpfidex import fidex\n",
    "res = fidex.fidex(\"--help\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4603d85-d0eb-4fb1-bd50-e66cac47b936",
   "metadata": {},
   "source": [
    "We see that we need the number of attributes and classes, the train and test data and class files, as well as train and test predictions, weights file name, and rule output file name where the rules will be saved.<br>\n",
    "We specify as well the saved folder and the attributes.<br>\n",
    "\n",
    "To see what happens, we launch it with just one sample, we save beforehand the test data sample in a file with its class and predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add3ff77-f54f-4288-b7fa-3c780a617653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from file\n",
    "def get_data(file_name):\n",
    "    with open(file_name, \"r\") as my_file:\n",
    "        data = []\n",
    "        line = my_file.readline()\n",
    "        while line:\n",
    "            line = line.strip()  # Remove the line break at the end of the line\n",
    "            di = [float(elt) for elt in line.split(\" \")]\n",
    "            data.append(di)\n",
    "            line = my_file.readline()\n",
    "        my_file.close()\n",
    "    return data\n",
    "\n",
    "test_preds = get_data(\"data/BCWDataset/predTest.out\")\n",
    "\n",
    "# Save the data, prediction, and class of the first sample in a new file\n",
    "f = open(\"data/BCWDataset/testDataSample.txt\", \"w\")\n",
    "for val in test_datas[0]:\n",
    "    f.write(str(val)+\" \")    \n",
    "f.write(\"\\n\")\n",
    "for val in test_preds[0]:\n",
    "    f.write(str(val)+\" \")    \n",
    "f.write(\"\\n\")\n",
    "val = test_classes[0]\n",
    "for i in range(nb_classes):\n",
    "    if val == i:\n",
    "        f.write(\"1 \")\n",
    "    else:\n",
    "        f.write(\"0 \")  \n",
    "f.write(\"\\n\")\n",
    "f.close()\n",
    "\n",
    "#res = fidex.fidex(\"fidex -T trainData.txt -P predTrain.out -C trainClass.txt -S testDataSample.txt -W Weights/weights -N 25 -A attributes.txt -O rule.txt -R data/BCWDataset\")\n",
    "#res = fidex.fidex(\"--train_data_file trainData.txt --train_pred_file predTrain.out --train_class_file trainClass.txt --test_data_file testDataSample.txt --weights_file Weights/weights.wts --attributes_file attributes.txt --rules_outfile rule.rls --nb_attributes 30 --nb_classes 2 --root_folder data/BCWDataset\")\n",
    "result = fidex.fidex(\"--json_config_file data/config_fidexOne.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dcf258-9284-4a41-817b-9158f321a2df",
   "metadata": {},
   "source": [
    "You can see the walkthrough of the algorithm and the rule extracted. The rule is also saved in the rule.rls file. With the rule, we see also the covering size of the rule on the training set, the fidelity, the accuracy, and the confidence of the rule. The confidence shows how much the rule is confident with his choices, with respect to the prediction values.<br>\n",
    "\n",
    "Now, we execute Fidex with all test samples. We send the console output in the fidexResult.txt file and save the global statistics in fidexStats.txt. **It should take about a minute**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2475dc1f-0815-476b-a695-9869598dcd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#res = fidex.fidex(\"fidex -T trainData.txt -P predTrain.out -C trainClass.txt -S testData.txt -p predTest.out -c testClass.txt -W Weights/weights -N 25 -A attributes.txt -O fidexRules.rls -s fidexStats.txt -r fidexResult.txt -R data/BCWDataset\")\n",
    "#res = fidex.fidex(\"--train_data_file trainData.txt --train_pred_file predTrain.out --train_class_file trainClass.txt --test_data_file testData.txt --test_class_file testClass.txt --test_pred_file predTest.out --weights_file Weights/weights.wts --attributes_file attributes.txt --rules_outfile fidexRules.rls --stats_file fidexStats.txt --console_file fidexResult.txt --nb_attributes 30 --nb_classes 2 --root_folder data/BCWDataset\")\n",
    "res = fidex.fidex(\"--json_config_file data/config_fidex.json\")\n",
    "\n",
    "if (res == 0):\n",
    "    print(\"Fidex done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c4f8fe-ec3d-4231-866a-e4361dd323be",
   "metadata": {},
   "source": [
    "You can see the rules of each sample in the file fidexRules.rls. The global statistics on the test set appear in statsFidex.txt. There is the mean covering size per rule, the mean number of antecedents per rule, and the mean rule fidelity, accuracy, and confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2c1cad-7802-47e5-bc09-aa28967913cc",
   "metadata": {},
   "source": [
    "# Global ruleSet generation - FidexGlo\n",
    "We've seen how to compute a rule that explains the decision of the model for a specific sample. Now, we will generalize a ruleset that characterizes the whole train dataset. That means that for each training sample, there is a rule in the set of rules that explains the model's decision for this sample. We will use this global ruleset to explain the results obtained on new test samples. If there is a rule of the ruleset corresponding to the sample, we take this one and get a global explanation for the sample. If there is none, we call Fidex and only have a local explanation.<br>\n",
    "\n",
    "To get the ruleSet we execute fidexGloRules which is located in the fidex module. Here are the possible parameters :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8286ec5a-306b-4048-84cb-7358c2647863",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = fidex.fidexGloRules(\"--help\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665be28c-c788-41c2-ae00-b7a7b3118c2b",
   "metadata": {},
   "source": [
    "We use nearly the same parameters as for Fidex but we only need train data. We need to choose a heuristic for fidexGloRules, we choose the optimal to get better results.<br>\n",
    "**It should take about 5 minutes**. If you want to accelerate the process, you can use some dropout, the algorithm will randomly skip some dimensions or some hyperplans. For example, you can put: -d 0.5 -h 0.5, to skip half dimensions and half hyperplans, which should be about 4 times faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e0d897-ab14-4e8d-a0f9-da7fe35bfb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#res = fidexGlo.fidexGloRules(\"fidexGloRules -T trainData.txt -P predTrain.out -C trainClass.txt -W Weights/weights -N 25 -A attributes.txt -O globalRules.rls -M 1 -r fidexGloRulesResult.txt -S data/BCWDataset\")\n",
    "#res = fidex.fidexGloRules(\"--train_data_file trainData.txt --train_pred_file predTrain.out --train_class_file trainClass.txt --weights_file Weights/weights.wts --nb_attributes 30 --nb_classes 2 --heuristic 1 --global_rules_outfile globalRules.rls --console_file fidexGloRulesResult.txt --root_folder data/BCWDataset\")\n",
    "res = fidex.fidexGloRules(\"--json_config_file data/config_fidexGloRules.json\")\n",
    "if (res == 0):\n",
    "    print(\"FidexGloRules done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e7b780-5fc6-4d0a-a82e-1b86ed6853d4",
   "metadata": {},
   "source": [
    "You can see the console result in the file fidexGloRulesResult.txt and the ruleset in the file globalRules.rls.\n",
    "The algorithm is random, so each execution may generate different rules and a different number of them. It should generate about 20 rules. You can see at the top of the globalRules file the number of rules, the mean covering number per rule, and the mean number of antecedents. Here is an example of a rule that you may obtain:<br>\n",
    "\n",
    "Rule 1: MEAN_CONCAVE_POINTS<0.041282 WORST_CONCAVE_POINTS<0.150829 -> BENIGN <br>\n",
    "Train Covering size : 249 <br>\n",
    "Train Fidelity : 1 <br>\n",
    "Train Accuracy : 0.959839 <br>\n",
    "Train Confidence : 0.965581 <br>\n",
    "\n",
    "This rule is the first rule, which means that it's the rule with the maximum covering. Here, 249 train samples verify this rule. She is 100% fidel with the model and has about 96% train accuracy.\n",
    "This rule says that if you have mean concave points lower than 0.41282 and worst concave points lower than 0.15089, then your breast cancer is benign. And this rule is accurate, on train test, at 96%.<br>\n",
    "\n",
    "Now, we can see some global statistics on the test set, and also some statistics directly on each rule. So we will see the test accuracy on this rule.<br>\n",
    "We execute fidexGloStats which is located in the fidex module. First, let's check the parameters :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6aaa70-4ffa-4205-99f8-840d67b260cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = fidex.fidexGloStats(\"--help\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b7ebed-01b9-4016-addb-d99839f7be74",
   "metadata": {},
   "source": [
    "We need the test files(data, prediction, class), the rules file, and the number of attributes and classes. We need to specify the attribute file as well. We choose to save the results in the file fidexGloStats.txt. With --global_rules_outfile we can generate the statistics on rules which will modify the rules file. If you want to keep the first ruleSet unchanged, you should give another name. Finally, with --positive_class_index we can specify the positive class in order to get a ROC curve and some other statistics on false and true positives/negatives. We will design the malignant class as positive. So here is the command :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375ef5c0-aca8-4e1a-a842-ed229d23e8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#res = fidexGlo.fidexGloStats(\"fidexGloStats -T testData.txt -P predTest.out -C testClass.txt -R globalRules.rls -F globalRules.rls -A attributes.txt -O fidexGloStats.txt -x 0 -S data/BCWDataset\")\n",
    "res = fidex.fidexGloStats(\"--test_data_file testData.txt --test_pred_file predTest.out --test_class_file testClass.txt --attributes_file attributes.txt --global_rules_file globalRules.rls --global_rules_outfile globalRules.rls --nb_attributes 30 --nb_classes 2 --stats_file fidexGloStats.txt --positive_class_index 0 --root_folder data/BCWDataset\")\n",
    "res = fidex.fidexGloStats(\"--json_config_file data/config_fidexGloStats.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c523c382-b2ed-413e-84e7-c0d39c6d1bf5",
   "metadata": {},
   "source": [
    "Here you can see the global statistics on the test set. As the previous calculations have randomness, each execution is a bit different. So here we will discuss the same case as before, so you may have slightly different results. In our case, we had about 95% fidelity, which is good, and a rule accuracy about 1% lower than the model accuracy. So the rules seem to classify a bit worse. The explainability rate is the percentage of samples for which we can find a rule in the rules set. For the others, we need to execute Fidex (this is the default rule rate). In our case, we had more than a 97% explainability rate, so only in 3% of cases do we need to compute Fidex. Each rule can activate many rules. Here on average, a sample activates 3 correct rules and 0.1 wrong rules. A wrong rule is a rule with which the model doesn't agree. For example, if the rule says malign and the model says benign. Something interesting is the model test accuracy when rules and model agree. You can see that, generally, the accuracy increases if we consider samples where rules and model agree, and increases even more if we take only the activated rules (when there are no activated rules, we choose the model prediction). That means that the rules confirm well the model decision, but when no rule is found, the model decision may as well be wrong. <br>\n",
    "\n",
    "Finally, we have the statistics on the positive/negative decisions of the model and of the rules. For the model's decisions, we had 1% false positives and 7% false negatives. That means that when the model says that it's malign, it has a 99% chance of being malign. But when it says that it's benign, there is a 7% risk that it is malign in reality. So the precision is 97% and the recall is 93%.\n",
    "\n",
    "In the case of the rules decisions, the rules decision is the same as the model if we find a correct rule. If there is no rule, we can launch Fidex, so it's also the same decision as the model because it will create a fidel rule. The only scenario when the decision changes from the model's is when some rules are activated, all rules decide the same class which is not the class chosen by the model. The results are really close with 95% of precision and 93% of recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5400680-5058-4f75-97f1-552b1cead6d8",
   "metadata": {},
   "source": [
    "In globalRules file, you can now see the statistics of rules on the test set. Here is the same rule as before that I have now:<br>\n",
    "\n",
    "Rule 1: MEAN_CONCAVE_POINTS<0.041282 WORST_CONCAVE_POINTS<0.150829 -> BENIGN <br>\n",
    "Train Covering size : 249 --- Test Covering size : 65 <br>\n",
    "Train Fidelity : 1 --- Test Fidelity : 0.969231 <br>\n",
    "Train Accuracy : 0.959839 --- Test Accuracy : 0.984615 <br>\n",
    "Train Confidence : 0.965581 --- Test Confidence : 0.963119 <br>\n",
    "\n",
    "You can see that the rule no longer always agrees with the model, only in 0.969% of cases. However, the rule accuracy has increased with the test. That means that the rule is very good in reality, with 98.4% of correct classification."
   ]
  },
  {
   "cell_type": "raw",
   "id": "c457745a-6030-486e-95d4-33040fe430ea",
   "metadata": {},
   "source": [
    "We can get a ROC curve obtained with the test set. Here are the parameters of computeRocCurve which is located in the trainings package :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338b8a62-832e-45f7-8540-9ec4a7928447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.path)\n",
    "from trainings.computeRocCurve import computeRocCurve\n",
    "res = computeRocCurve(\"--help\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ec3ff5-a6db-4478-9d36-87f2ddbc3247",
   "metadata": {},
   "source": [
    "We execute computeRocCurve :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c817149-bae3-4ce2-8bc8-074a27747705",
   "metadata": {},
   "outputs": [],
   "source": [
    "#res = computeRocCurve(test_class = \"testClass.txt\", test_pred = \"predTest.out\", positive_index = 0, output_roc=\"outRoc.png\", stats_file=\"stats.txt\", save_folder = \"data/BCWDataset\")\n",
    "#res = computeRocCurve('--test_class_file testClass.txt --test_pred_file predTest.out --positive_class_index 0 --output_roc outRoc.png --stats_file rocStats.txt --root_folder data/BCWDataset --nb_classes 2')\n",
    "res = computeRocCurve(\"--json_config_file data/config_roc.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a27b096-fbfd-4c67-a303-58a5b404169b",
   "metadata": {},
   "source": [
    "The AUC score is added to the stats file and the ROC curve is saved in the outRoc.png file. We get an AUC of about 99%. <br>\n",
    "We can visualize the AUC curve :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd579681-492d-4900-84ae-69aeef690a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(filename=\"data/BCWDataset/outRoc.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6709efc3-5ac9-41d8-927e-1c5fedddef82",
   "metadata": {},
   "source": [
    "Finally, it's possible to launch fidexGlo on a test set. It will, for each test sample, search in the global ruleset for all the rules that verify the sample's properties and match the decision of the model. If no rule verifies the properties, it calls Fidex on the test sample. In the other case, it gives all the correct and wrong activated rules.<br>\n",
    "\n",
    "FidexGlo is located in the fidex module. Here are the possible parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ccff77-b9a8-4c97-b3f7-2f8756935bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = fidex.fidexGlo(\"--help\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c845e1fe-9226-4aa7-874d-eb582695afda",
   "metadata": {},
   "source": [
    "As we want to use Fidex on test sample not covered by the global ruleset, we need to specify the Fidex parameters. We launch it with :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec3cd7f-502b-49c4-b1ce-28f219b8d5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#res = fidexGlo.fidexGlo(\"fidexGlo -S testData.txt -p predTest.out -R globalRules.rls -A attributes.txt -O explanations.txt -r fidexGloResults.txt -F data/BCWDataset\")\n",
    "#res = fidex.fidexGlo(\"--test_data_file testData.txt --test_pred_file predTest.out --global_rules_file globalRules.rls --nb_attributes 30 --nb_classes 2 --attributes_file attributes.txt --explanation_file explanations.txt --console_file fidexGloResults.txt --root_folder data/BCWDataset --with_fidex true --train_data_file trainData.txt --train_pred_file predTrain.out --train_class_file trainClass.txt --test_class_file testClass.txt --weights_file Weights/weights.wts\")\n",
    "res = fidex.fidexGlo(\"--json_config_file data/config_fidexGlo.json\")\n",
    "\n",
    "if res == 0:\n",
    "    print(\"Explanations generated\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccf58f4-b70b-4586-ad3c-345d9a5d0823",
   "metadata": {},
   "source": [
    "The explanations for each test sample can then be found in the file explanations.txt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7f3208-c538-40eb-8c76-31e75d687198",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Throughout this notebook, we've learned how to use DimlpBT to train a dataset and get some explaining rules, and we got into the different Fidex algorithms to get some local and global explanations, and some statistics on the model's decisions. We used the example of the breast cancer dataset from Wisconsin and we saw that the algorithms perform very well. It gives some good explanations of the model's decision and does it very fast, especially if a fidexGlo ruleset has been computed beforehand. You can try with any tabular dataset you want, you just have to remember to transform the data in a good format. <be>\n",
    "\n",
    "We didn't speak about every single parameter, you can try to change every hyperparameter you want to see how it goes. An interesting parameter that we didn't consider is the parameter for decision threshold (--decision_threshold) in Fidex algorithms. It allows us to change prediction with respect to a specific threshold on the positive class. If the model gives a score prediction, for the positive class, greater than this threshold, the model prediction is considered to be the positive class, even if another class obtains a higher score. If the recall is not good enough, it's possible to improve it this way. Another parameter is the seed. It allows you to remove the randomness of the algorithms and get the same result in each execution for the same parameters and data.<br>\n",
    "\n",
    "We considered only a simple tabular dataset. It's also possible to use it for an image classification problem. To see how we can train a dataset with convolutions, we recommend exploring the Mnist notebook for a hands-on experience **Insérer lien notebook Mnist**. There are also other training methods, like an MLP or decision trees. The Keel Australian notebook goes through these and shows what to do when we have categorical attributes **Insérer Keel Australian notebook**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605dcb45-4862-4268-bef2-068cf96de3d9",
   "metadata": {},
   "source": [
    "# Références\n",
    "\n",
    "Article DimlpBT de Guido\n",
    "Article Fidex de Guido (à venir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1981df31-b3c1-4c80-adc9-30e3bd72dd94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
