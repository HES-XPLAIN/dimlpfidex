{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6032ef9f-92e2-44dc-a11b-b224342bee29",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Exploring Dimlp and Fidex rule generation for breast cancer classification\n",
    "\n",
    "**Introduction:**\n",
    "\n",
    "Welcome to HES-Xplain, our interactive platform designed to facilitate explainable artificial intelligence (XAI) techniques. In this use case, we dive into breast cancer classification and showcase the power of Dimlp and Fidex as interpretability tools.\n",
    "\n",
    "In the medical field, there are many machine-learning models that can obtain results. These models are like black boxes that return results without fully understanding the reasoning leading to them. Depending on the nature of the problem it's important to understand the model's decision. It's difficult for a doctor or a patient to make a decision based on a model that we don't understand. Likewise, insurance companies will not necessarily agree to pay for a medication that a model has advised people to take. This is why explainability in this field is important.\n",
    "\n",
    "Fidex is an algorithm used in classification problems that allows us to obtain a rule explaining the decision class of the model for a given test sample. It enables us to grasp the model's decision-making process and to better understand the importance of each parameter in discerning the nature of the tumor, distinguishing between benign and malignant cases.\n",
    "\n",
    "The global version of Fidex, FidexGlo, allows us to get a set of rules that englobes all the decision-making process for the entire training set. We can then check if a new sample verifies all the properties of one rule of the ruleset, in which case this rule explains the model's decision.\n",
    "\n",
    "Our goal is to demonstrate how HES-Xplain empowers users to explore and interpret breast cancer classification effectively. By the end of this use case, you'll have a solid understanding of how to use Dimlp to train the model and the Fidex algorithms into your own classification datasets.\n",
    "\n",
    "**Objectives:**\n",
    "\n",
    "    1. Understand the importance of interpretability in medical problems.\n",
    "    2. Introduce Dimlp and Fidex as powerful XAI techniques.\n",
    "    3. Understand how to use Dimlp and Fidex.\n",
    "    4. Showcase the capabilities of HES-Xplain in implementing Dimlp and Fidex algorithms.\n",
    "    5. Provide practical insights into applying Dimlp and Fidex to breast cancer classifiers through an interactive notebook.\n",
    "    6. Foster a community of XAI enthusiasts and practitioners.\n",
    "\n",
    "**Outline:**\n",
    "\n",
    "    1. Dataset and Problem Statement.\n",
    "    2. Load the dataset.\n",
    "    3. Training of the Model.\n",
    "    4. Local rules generation - Fidex\n",
    "    5. Global ruleSet generation - FidexGlo\n",
    "    6. Conclusion.\n",
    "    7. References.\n",
    "\n",
    "Through this use case, we aim to empower users to grasp the potential of Dimlp and Fidex as tools for transparent and interpretable classification. With HES-Xplain, we make XAI accessible, helping users build trust in their models and make informed decisions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f882f8-9ee5-44a3-9091-bc5cd14c896e",
   "metadata": {},
   "source": [
    "# Dataset and Problem Statement\n",
    "\n",
    "The Breast Cancer Dataset used in this use case consists of 569 data samples representing patients who have tumors. Each patient has 30 attributes, computed out of an image, used to determine if the tumor is malignant (first class) or benign (second class). This dataset is available on [Kaggle](https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data) and can be imported with sklearn. It is composed of 455 training samples and 114 testing samples. \n",
    "\n",
    "The 30 attributes are composed of 10 real-valued features computed for each cell nucleus :\n",
    "\n",
    "- **Radius**: Mean of distances from the center to points on the perimeter.\n",
    "- **Texture**: Standard deviation of gray-scale values.\n",
    "- **Perimeter**\n",
    "- **Area**\n",
    "- **Smoothness**: Local variation in radius lengths.\n",
    "- **Compactness**: $\\frac{\\text{perimeter}^2}{\\text{area}} - 1.0$\n",
    "- **Concavity**: Severity of concave portions of the contour.\n",
    "- **Concave Points**: Number of concave portions of the contour.\n",
    "- **Symmetry**\n",
    "- **Fractal Dimension**: \"Coastline approximation\" - 1.\n",
    "\n",
    "For each tumor image, the mean, standard error, and worst errors were computed and appear as different attributes.\n",
    "\n",
    "**Problem Statement:** Our objective is to build a robust classifier capable of accurately classifying breast cancer samples among the 2 classes. By leveraging deep learning techniques and Fidex algorithms, we aim to not only achieve high classification performance but also gain insights into the attributes that contribute to the classification decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfedb29-a2b0-4a64-9958-da3f1463a78d",
   "metadata": {},
   "source": [
    "# Load the dataset\n",
    "First of all, we unbuffer Python output so that it prints the result as soon as possible (you won't need to do this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c2697a5-c92e-40a6-86ce-018b897baea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unbuffered(object):\n",
    "   def __init__(self, stream):\n",
    "       self.stream = stream\n",
    "   def write(self, data):\n",
    "       self.stream.write(data)\n",
    "       self.stream.flush()\n",
    "   def writelines(self, datas):\n",
    "       self.stream.writelines(datas)\n",
    "       self.stream.flush()\n",
    "   def __getattr__(self, attr):\n",
    "       return getattr(self.stream, attr)\n",
    "\n",
    "import sys\n",
    "sys.stdout = Unbuffered(sys.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dade571b-4876-45b5-9d09-a76791165a75",
   "metadata": {},
   "source": [
    "We start by loading the dataset. First, we need to download the data with sklearn and shuffle it randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd7b7b29-d07d-4750-820f-2270937d8ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "datas, classes = shuffle(datasets.load_breast_cancer().data, datasets.load_breast_cancer().target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d87dd5-2233-43e2-9f95-777a1f7bda99",
   "metadata": {},
   "source": [
    "Then we define test and training sets by distributing the data so that there is one-fifth of the data for the test and four-fifths for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a0ed78b-b077-4136-84a6-9f176f33c223",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_samples = len(classes)\n",
    "cutoff = int((4/5)*nb_samples)\n",
    "train_classes = classes[:cutoff]\n",
    "train_datas = datas[:cutoff]\n",
    "test_classes = classes[cutoff:]\n",
    "test_datas = datas[cutoff:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d123e58b-b85d-4b43-9e1d-fcc11b65eaa3",
   "metadata": {},
   "source": [
    "We can display the number of training and testing data and check that there is the same number of data as classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ce94b0e-e7ab-4d8f-9082-cb57da8b17cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 455 train datas and 455 train classes\n",
      "There are 114 test datas and 114 test classes\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {len(train_datas)} train datas and {len(train_classes)} train classes\")\n",
    "print(f\"There are {len(test_datas)} test datas and {len(test_classes)} test classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7724b51a-a76f-4e3e-9e27-b1b0a40a148d",
   "metadata": {},
   "source": [
    "Now, we save the data in text files in a specific format. We create a folder BCWDataset inside a data folder if it doesn't already exist and we save the files here.\n",
    "For the classes, we encode in one hot format, with 1 on the position of the right class and 0 elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a104b59-41da-4963-b799-70cb8544f8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def create_folder(folder_path):\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "        print(f\"Folder '{folder_path}' created successfully.\")\n",
    "\n",
    "def save_data(datafile, datas):\n",
    "    f = open(datafile, \"w\")\n",
    "    for data in datas:\n",
    "        for val in data:\n",
    "            f.write(str(val)+\" \")\n",
    "        f.write(\"\\n\")\n",
    "    f.close()\n",
    "\n",
    "def save_class(classfile, classes, nb_classes):\n",
    "    f = open(classfile, \"w\")\n",
    "    for classe in classes:\n",
    "        for i in range(nb_classes):\n",
    "            if classe == i:\n",
    "                f.write(\"1 \")\n",
    "            else:\n",
    "                f.write(\"0 \")\n",
    "        f.write(\"\\n\")\n",
    "    f.close()\n",
    "\n",
    "create_folder(\"data/BCWDataset\")\n",
    "\n",
    "nb_classes = len(datasets.load_breast_cancer().target_names)\n",
    "save_data(\"data/BCWDataset/datas.txt\", datas)\n",
    "save_data(\"data/BCWDataset/trainData.txt\", train_datas)\n",
    "save_data(\"data/BCWDataset/testData.txt\", test_datas)\n",
    "save_class(\"data/BCWDataset/trainClass.txt\", train_classes, nb_classes)\n",
    "save_class(\"data/BCWDataset/testClass.txt\", test_classes, nb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a05c5c-ad03-4e58-96d7-6bbe04f79a0c",
   "metadata": {},
   "source": [
    "Finally, we normalize the data so that the model learns better. We save the mean and std of each attribute in the file normalization_stats.txt. We use the normalization file located in the trainings module. To display the parameters, you can just call normalization with no parameters, or with -h or --help. Without further details, we normalize with this command :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "350d6c19-c2af-4a8e-893f-4b86fa9460e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters list:\n",
      " - root_folder                                                   data/BCWDataset\n",
      " - nb_attributes                                                 30\n",
      " - missing_values                                                NaN\n",
      " - normalization_indices                                         [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
      " - data_files                                                    ['data/BCWDataset/trainData.txt', 'data/BCWDataset/testData.txt']\n",
      " - output_normalization_file                                     data/BCWDataset/normalization_stats.txt\n",
      " - output_data_files                                             ['data/BCWDataset/trainData_normalized.txt', 'data/BCWDataset/testData_normalized.txt']\n",
      " - with_median                                                   False\n",
      " - fill_missing_values                                           True\n",
      "End of Parameters list. \n",
      "\n",
      "\n",
      "Full execution time = 0.30381 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trainings.normalization import normalization\n",
    "#normalization(\"--help\")\n",
    "normalization('--data_files [trainData.txt,testData.txt] --nb_attributes 30 --missing_values NaN --root_folder data/BCWDataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b34fc4-1e80-4eab-84ec-a0a4a28626fb",
   "metadata": {},
   "source": [
    "In order to generate beautiful and understandable rules, we still have to create an attribute file with attribute and class names.<br>\n",
    "For the attributes we have :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6634d478-316f-464d-9199-a8ea39883b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "attributes = datasets.load_breast_cancer().feature_names\n",
    "print(attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2ed3d0-cb53-4371-9ec8-76500422c93d",
   "metadata": {},
   "source": [
    "And for the classes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d5ee674-09b8-47a2-a927-d2b3de0c3c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "classes = datasets.load_breast_cancer().target_names\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb8d44f-be2c-485a-99dc-5e90ea7e74a1",
   "metadata": {},
   "source": [
    "We store the attributes and classes in a file attributes.txt and fill the spaces with _ and apply upper case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba892ed9-0ae5-4711-a998-07bc668764f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"data/BCWDataset/attributes.txt\", \"w\")\n",
    "for attribute in attributes:\n",
    "    f.write(attribute.upper().replace(\" \", \"_\")+\"\\n\")\n",
    "for classe in classes:\n",
    "    f.write(classe.upper().replace(\" \", \"_\")+\"\\n\")\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c01997-d95c-4c99-8ea4-3dfa31d7ba2f",
   "metadata": {},
   "source": [
    "# Training of the model\n",
    "\n",
    "We train the dimlp model. First, let's import it and display the parameters that are needed and optional for training. Dimlp is able to train the model as well as generate rules with his own algorithm. The Fidex algorithms are an improvement that we'll see later on. We choose the training with DimlpBT, which is the same as Dimlp but with bagging.\n",
    "The main package name is dimlpfidex, and we need the dimlp module where DimlpBT is located. To display the parameters, we can just call dimlpBT with no parameters, or with -h or --help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25fb49df-c5d9-402a-b48d-23b34c1108d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "Warning! The files are localised with respect to root folder dimlpfidex.\n",
      "The arguments can be specified in the command or in a json configuration file with --json_config_file your_config_file.json.\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Required parameters:\n",
      "\n",
      "--train_data_file <str>       Train data file\n",
      "--nb_attributes <int [1,inf[> Number of input neurons\n",
      "--nb_classes <int [2,inf[>    Number of output neurons\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Optional parameters: \n",
      "\n",
      "--json_config_file <str>      JSON file to configure all parameters. If used, this must be the sole argument and must specify the file's relative path\n",
      "--root_folder <str>           Folder based on main folder dimlpfidex(default folder) containg all used files and where generated files will be saved. If a file name is specified with another option, his path will be configured with respect to this root folder\n",
      "--nb_dimlp_nets <int [1,inf[> Number of networks (default: 25)\n",
      "--attributes_file <str>       File of attributes\n",
      "--test_data_file <str>        Test data file\n",
      "--train_class_file <str>      Train true class file\n",
      "--test_class_file <str>       Test true class file\n",
      "--console_file <str>          File with console logs redirection\n",
      "--weights_outfile <str>       Output weights file name file (default: dimlpBT.wts)\n",
      "--train_pred_outfile <str>    Output train prediction file name (default: dimlpBTTrain.out)\n",
      "--test_pred_outfile <str>     Output test prediction file name (default: dimlpBTTest.out)\n",
      "--stats_file <str>            Output file name with train, test and validation accuracy and with the global train and test accuracy\n",
      "--first_hidden_layer <int k*nb_attributes, k in [1,inf[>\n",
      "                              Number of neurons in the first hidden layer (default: nb_attributes)\n",
      "--hidden_layers <list<int [1,inf[>>\n",
      "                              Number of neurons in each hidden layer, from the second layer through to the last\n",
      "--hidden_layers_outfile <str> Output hidden layers file name (default: hidden_layers.out)\n",
      "--with_rule_extraction <bool> Whether to extract rules with dimlpBT algorithm\n",
      "--global_rules_outfile <str>  Rules output file\n",
      "--momentum <float [0,inf[>    Back-propagation momentum parameter (default: 0.6)\n",
      "--flat <float [0,inf[>        Back-propagation flat spot elimination parameter (default: 0.01)\n",
      "--nb_quant_levels <int [3,inf[>\n",
      "                              Number of stairs in staircase activation function (default: 50)\n",
      "--error_thresh <float [0,inf[>\n",
      "                              Error threshold to stop training\n",
      "--acc_thresh <float ]0,1]>    Accuracy threshold to stop training\n",
      "--abs_error_thresh <float [0,inf[>\n",
      "                              Absolute difference error threshold, 0 if not using this stopping criteria (default: 0)\n",
      "--nb_epochs <int [1,inf[>     Number of epochs (default: 1500)\n",
      "--nb_epochs_error <int [1,inf[>\n",
      "                              Number of epochs to show error (default: 10)\n",
      "--nb_ex_per_net <int [1,inf[> Number of examples for one single network, 0 for all examples, it is not recommended to change this value (default: 0)\n",
      "--normalization_file <str>    File containing the mean and std of some attributes. Used to denormalize the rules if specified\n",
      "--mus <list<float ]inf,inf[>> Mean or median of each attribute index to denormalize in the rules\n",
      "--sigmas <list<float ]inf,inf[>>\n",
      "                              Standard deviation of each attribute index to denormalize in the rules\n",
      "--normalization_indices <list<int [0,nb_attributes-1]>>\n",
      "                              Attribute indices to denormalize in the rules, only used when no normalization_file is given, index starts at 0 (default: [0,...,nb_attributes-1])\n",
      "--seed <int [0,inf[>          Seed, 0=random (default: 0)\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Execution example :\n",
      "\n",
      "dimlp.dimlpBT(\"--train_data_file datanormTrain.txt --train_class_file dataclass2Train.txt --test_data_file datanormTest.txt --test_class_file dataclass2Test.txt --nb_attributes 16 --hidden_layers 5 --nb_classes 2 --nb_dimlp_nets 2 --weights_outfile dimlpDatanormBT.wts --with_rule_extraction true --global_rules_outfile globalRules.rls --train_pred_outfile predTrain.out --test_pred_outfile predTest.out --stats_file stats.txt --root_folder dimlp/datafiles\")\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dimlpfidex import dimlp\n",
    "res = dimlp.dimlpBT(\"--help\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cf5278-16aa-4455-8114-bd3c9b2a5359",
   "metadata": {},
   "source": [
    "Now we can run dimlpBT with the right parameters.<br>\n",
    "\n",
    "As we see in the parameter list, we need to give the train data file(--train_data_file), the number of input neurons of the model(--nb_attributes), which is the number of attributes, and the number of output neurons(--nb_classes) which is the number of classes.<br>\n",
    "For this dataset, we recommend adding a hidden layer (--hidden_layers) of size 5 or 10 in the model architecture. Here we choose 5.\n",
    "\n",
    "In the training file, we can also have the classes, but here we've chosen to save them in a different file, so we add it too with --train_class_file.<br>\n",
    "To get test predictions and statistics, we specify a test data file and test class file with --test_data_file and --test_class_file.<br>\n",
    "We choose the names for the files of statistics(--stats_file), train(--train_pred_outfile) and test predictions(--test_pred_outfile), and weights(--weights_outfile).<br>\n",
    "We specify with --root_folder the folder where we have all the data files and where we want to save the results. <br>\n",
    "\n",
    "This is enough to train our model, but we can add the computation of explaining rules with the Dimlp algorithm. You will be able to compare the rules obtained with the Dimlp algorithm and with the Fidex one. We just add --with_rule_extraction to ask for the computation of the rules, --global_rules_outfile to specify the name of the rules file, and --attributes_file, to give the attribute and class names that will appear in the rules.<br>\n",
    "\n",
    "As there are a lot of things to be written on output, we save the program output with --console_file. If you remove it you may have some neverending execution problem in the notebook. <br>\n",
    "\n",
    "To execute dimlpBT, we can either write the whole command (see the commented line below) or call a JSON configuration file (--json_config_file) containing each parameter as we want. All configuration files are located in the data folder. You can create new ones or modify them as you like by adding, removing, or modifying some parameters. To create a new file, we recommend you use our graphical user interface (GUI). <br>\n",
    "\n",
    "Additionally, we have a notebook that explains how to use this GUI, providing detailed instructions and practical examples. We encourage you to read this notebook to get the most out of our tools. You can access the notebook by following this link: **Link to the notebook**. <br>\n",
    "\n",
    "Here is how we execute dimlpBT :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e804d87b-b2dc-4946-9e99-caf1fa3fa066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done\n"
     ]
    }
   ],
   "source": [
    "# Creation of Weights folder if it doesn't exist\n",
    "create_folder(\"data/BCWDataset/Weights\")\n",
    "#result = dimlp.dimlpBT(\"--train_data_file trainData_normalized.txt --train_class_file trainClass.txt --test_data_file testData_normalized.txt --test_class_file testClass.txt --attributes_file attributes.txt --nb_attributes 30 --hidden_layers 5 --nb_classes 2 --weights_outfile Weights/weights.wts --with_rule_extraction true --global_rules_outfile dimlpBTRules.rls --train_pred_outfile predTrain.out --test_pred_outfile predTest.out --stats_file stats.txt --console_file resultDimlpBT.txt --root_folder data/BCWDataset\")\n",
    "result = dimlp.dimlpBT(\"--json_config_file data/BCWTemplates/config_dimlpBT.json\")\n",
    "if (result == 0):\n",
    "    print(\"Training done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c12044-2b09-4b7c-82b4-e6285ef55dfc",
   "metadata": {},
   "source": [
    "If you go to the folder data/BCWDataset and open the file result.txt, you can see that the training went through, and some rules were computed. You can now open the file stats.txt in the same folder to see the train and test accuracy as well as the sum squared errors. In the folder, you can also see the train and test predictions, the weights obtained for Fidex, and the dimlpRules.<br>\n",
    "\n",
    "In the file dimlpRules.txt, you can see the rule set, some statistics on the rules, and some statistics on the ruleset. Each rule is composed of antecedents and target class as well as the number of covering of the rule, which is the number of examples that verify(or \"activate\") the rule (even if the class is not correct).<br>\n",
    "\n",
    "For each rule, we have from left to right:<br>\n",
    "The number of covered samples, the number of correct covered samples, the number of false covered samples, and the accuracy of the rule.<br>\n",
    "\n",
    "The statistics of the ruleset are: <br>\n",
    "- The number of rules in the set\n",
    "- The mean total and the mean number of antecedents per rule\n",
    "- The covering of the rule\n",
    "- The rules' accuracy\n",
    "- The fidelity to the model, which is the percentage of covered samples that are correct with respect to the model's decision.\n",
    "- The model accuracy if we keep only the samples for which the model and the rules decision agree\n",
    "- The default rule activation rate, which is the percentage of samples for which no rule is activated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0865c6d-1648-4a61-8962-e81690b8d491",
   "metadata": {},
   "source": [
    "# Local rules generation - Fidex\n",
    "Now we can generate some local rules to explain the models' results. We can start with launching Fidex on one test sample. This will generate a rule explaining the sample locally. It is local because the algorithm searches a rule only for one sample.\n",
    "Fidex is located in the fidex module. Let's take a look at the parameters :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "368222c7-c0f8-4af0-a6a7-7adf290b7192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "Warning! The files are localised with respect to root folder dimlpfidex.\n",
      "The arguments can be specified in the command or in a json configuration file with --json_config_file your_config_file.json.\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Required parameters:\n",
      "\n",
      "--train_data_file <str>       Train data file\n",
      "--train_pred_file <str>       Train prediction file\n",
      "--train_class_file <str>      Train true class file, not mandatory if classes are specified in train data file\n",
      "--test_data_file <str>        Test sample(s) data file with data, prediction(if no --test_pred_file) and true class(if no --test_class_file)\n",
      "--weights_file <str>          Weights file (not mandatory if a rules file is given with --rules_file)\n",
      "--rules_file <str>            Rules file to be converted to hyperlocus (not mandatory if a weights file is given with --weights_file)\n",
      "--rules_outfile <str>         Rule(s) output file. If a .json filename is given, rules are saved in a special json format\n",
      "--nb_attributes <int [1,inf[> Number of attributes in dataset\n",
      "--nb_classes <int [2,inf[>    Number of classes in dataset\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Optional parameters: \n",
      "\n",
      "--json_config_file <str>      JSON file to configure all parameters. If used, this must be the sole argument and must specify the file's relative path\n",
      "--root_folder <str>           Folder based on main folder dimlpfidex(default folder) containg all used files and where generated files will be saved. If a file name is specified with another option, his path will be configured with respect to this root folder\n",
      "--test_pred_file <str>        Test prediction file\n",
      "--test_class_file <str>       Test true class file. If at least --test_pred_file is specified, --test_data_file needs to have only test datas and eventually classes on same line (don't add --test_class_file in this case)\n",
      "--attributes_file <str>       File of attributes\n",
      "--stats_file <str>            Output statistic file name\n",
      "--console_file <str>          File with console logs redirection\n",
      "--max_iterations <int [1,inf[>\n",
      "                              Max iteration number, also the max possible number of attributs in a rule, should be 25 if working with images (default: 10)\n",
      "--min_covering <int [1,inf[>  Minimum covering number (default: 2)\n",
      "--covering_strategy <bool>    Whether to use this strategy : if no rule is found with min_covering, find best rule with best covering using dichotomic search. Decreases min_fidelity if needed (default: True)\n",
      "--max_failed_attempts <int [0,inf[>\n",
      "                              Maximum number of failed attempts to find Fidex rule when covering is 1 and covering strategy is used (default: 30)\n",
      "--min_fidelity <float [0,1]>  Minimal rule fidelity accepted when generating a rule (default: 1.0)\n",
      "--lowest_min_fidelity <float [0,1]>\n",
      "                              Minimal min_fidelity to which we agree to go down during covering_strategy (default: 0.75)\n",
      "--dropout_dim <float [0,1]>   Dimension dropout parameter (default: 0.0)\n",
      "--dropout_hyp <float [0,1]>   Hyperplan dropout parameter (default: 0.0)\n",
      "--nb_quant_levels <int [3,inf[>\n",
      "                              Number of stairs in staircase activation function (default: 50)\n",
      "--decision_threshold <float [0,1]>\n",
      "                              Decision threshold for predictions, you need to specify the index of positive class if you want to use it\n",
      "--positive_class_index <int [0,nb_classes-1]>\n",
      "                              Index of positive class for the usage of decision threshold, index starts at 0\n",
      "--normalization_file <str>    File containing the mean and std of some attributes. Used to denormalize the rules if specified\n",
      "--mus <list<float ]inf,inf[>> Mean or median of each attribute index to denormalize in the rules\n",
      "--sigmas <list<float ]inf,inf[>>\n",
      "                              Standard deviation of each attribute index to denormalize in the rules\n",
      "--normalization_indices <list<int [0,nb_attributes-1]>>\n",
      "                              Attribute indices to denormalize in the rules, only used when no normalization_file is given, index starts at 0 (default: [0,...,nb_attributes-1])\n",
      "--seed <int [0,inf[>          Seed, 0=random (default: 0)\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Execution example :\n",
      "\n",
      "fidex.fidex(\"--train_data_file datanormTrain.txt --train_pred_file predTrain.out --train_class_file dataclass2Train.txt --test_data_file testSampleDataCombine.txt --nb_attributes 16 --nb_classes 2 --weights_file weights.wts --rules_outfile rules.rls --stats_file stats.txt --root_folder dimlp/datafiles\")\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dimlpfidex import fidex\n",
    "res = fidex.fidex(\"--help\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4603d85-d0eb-4fb1-bd50-e66cac47b936",
   "metadata": {},
   "source": [
    "We see that we need the number of attributes and classes, the train and test data and class files, as well as train and test predictions, weights file name, and rule output file name where the rules will be saved.<br>\n",
    "We specify as well the saved folder and the attributes.<br>\n",
    "We also need to specify the normalization file obtained from training, to denormalize the values in the generated rule, otherwise the values will be normalized and impossible to interpret.<br>\n",
    "\n",
    "To see what happens, we launch it with just one sample, and we save beforehand the test data sample in a file with its class and predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "add3ff77-f54f-4288-b7fa-3c780a617653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters list:\n",
      " - train_data_file                                             data/BCWDataset/trainData_normalized.txt\n",
      " - train_pred_file                                                        data/BCWDataset/predTrain.out\n",
      " - train_class_file                                                      data/BCWDataset/trainClass.txt\n",
      " - test_data_file                                                    data/BCWDataset/testDataSample.txt\n",
      " - rules_outfile                                                               data/BCWDataset/rule.rls\n",
      " - root_folder                                                                          data/BCWDataset\n",
      " - attributes_file                                                       data/BCWDataset/attributes.txt\n",
      " - weights_file                                                     data/BCWDataset/Weights/weights.wts\n",
      " - normalization_file                                           data/BCWDataset/normalization_stats.txt\n",
      " - nb_attributes                                                                                     30\n",
      " - nb_classes                                                                                         2\n",
      " - nb_quant_levels                                                                                   50\n",
      " - max_iterations                                                                                    10\n",
      " - min_covering                                                                                       2\n",
      " - max_failed_attempts                                                                               30\n",
      " - positive_class_index                                                                              -1\n",
      " - seed                                                                                               0\n",
      " - decision_threshold                                                                         -1.000000\n",
      " - hi_knot                                                                                     5.000000\n",
      " - dropout_hyp                                                                                 0.000000\n",
      " - dropout_dim                                                                                 0.000000\n",
      " - min_fidelity                                                                                1.000000\n",
      " - lowest_min_fidelity                                                                         0.750000\n",
      " - covering_strategy                                                                                  1\n",
      "End of Parameters list.\n",
      "\n",
      "Import files...\n",
      "\n",
      "Import time = 0.095747 sec\n",
      "Files imported\n",
      "\n",
      "----------------------------------------------\n",
      "\n",
      "Creation of hyperspace...\n",
      "\n",
      "Parameters of hyperLocus :\n",
      "\n",
      "- Number of stairs 50\n",
      "- Interval : [-5,5]\n",
      "\n",
      "Import weight file...\n",
      "HyperLocus computed\n",
      "\n",
      "Hyperspace created\n",
      "\n",
      "Searching for discriminating hyperplans...\n",
      "Initial fidelity : 0.369231\n",
      "Final fidelity : 1\n",
      "Discriminating hyperplans generated.\n",
      "\n",
      "\n",
      "Extracted rule :\n",
      "MEAN_PERIMETER>=114.837974 -> MALIGNANT\n",
      "   Train Covering size : 84\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 0.988235\n",
      "   Train Confidence : 0.987915\n",
      "\n",
      "Result found after 1 iterations.\n",
      "-------------------------------------------------\n",
      "\n",
      "Time without data import = 0.00665 sec\n",
      "\n",
      "Full execution time = 0.103354 sec\n"
     ]
    }
   ],
   "source": [
    "# Get data from file\n",
    "def get_data(file_name):\n",
    "    with open(file_name, \"r\") as my_file:\n",
    "        data = []\n",
    "        line = my_file.readline()\n",
    "        while line:\n",
    "            line = line.strip()  # Remove the line break at the end of the line\n",
    "            di = [float(elt) for elt in line.split(\" \")]\n",
    "            data.append(di)\n",
    "            line = my_file.readline()\n",
    "        my_file.close()\n",
    "    return data\n",
    "\n",
    "test_preds = get_data(\"data/BCWDataset/predTest.out\")\n",
    "test_datas_normalized = get_data(\"data/BCWDataset/testData.txt\")\n",
    "# Save the data, prediction, and class of the first sample in a new file\n",
    "f = open(\"data/BCWDataset/testDataSample.txt\", \"w\")\n",
    "for val in test_datas_normalized[0]:\n",
    "    f.write(str(val)+\" \")    \n",
    "f.write(\"\\n\")\n",
    "for val in test_preds[0]:\n",
    "    f.write(str(val)+\" \")    \n",
    "f.write(\"\\n\")\n",
    "val = test_classes[0]\n",
    "for i in range(nb_classes):\n",
    "    if val == i:\n",
    "        f.write(\"1 \")\n",
    "    else:\n",
    "        f.write(\"0 \")  \n",
    "f.write(\"\\n\")\n",
    "f.close()\n",
    "\n",
    "#res = fidex.fidex(\"--train_data_file trainData_normalized.txt --train_pred_file predTrain.out --train_class_file trainClass.txt --test_data_file testDataSample.txt --weights_file Weights/weights.wts --attributes_file attributes.txt --rules_outfile rule.rls --nb_attributes 30 --nb_classes 2 --normalization_file normalization_stats.txt --root_folder data/BCWDataset\")\n",
    "res = fidex.fidex(\"--json_config_file data/BCWTemplates/config_fidexOne.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dcf258-9284-4a41-817b-9158f321a2df",
   "metadata": {},
   "source": [
    "You can see the walkthrough of the algorithm and the rule extracted. The rule is also saved in the rule.rls file. With the rule, we see also the covering size of the rule on the training set, the fidelity, the accuracy, and the confidence of the rule. The confidence shows how much the rule is confident with his choices, with respect to the prediction values.<br>\n",
    "\n",
    "Now, we execute Fidex with all test samples. We send the console output in the fidexResult.txt file and save the global statistics in fidexStats.txt. **It should take about a minute**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2475dc1f-0815-476b-a695-9869598dcd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidex done\n"
     ]
    }
   ],
   "source": [
    "#res = fidex.fidex(\"--train_data_file trainData_normalized.txt --train_pred_file predTrain.out --train_class_file trainClass.txt --test_data_file testData_normalized.txt --test_class_file testClass.txt --test_pred_file predTest.out --weights_file Weights/weights.wts --attributes_file attributes.txt --rules_outfile fidexRules.rls --stats_file fidexStats.txt --console_file fidexResult.txt --nb_attributes 30 --nb_classes 2 --normalization_file normalization_stats.txt --root_folder data/BCWDataset\")\n",
    "res = fidex.fidex(\"--json_config_file data/BCWTemplates/config_fidex.json\")\n",
    "\n",
    "if (res == 0):\n",
    "    print(\"Fidex done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c4f8fe-ec3d-4231-866a-e4361dd323be",
   "metadata": {},
   "source": [
    "You can see the rules generated for each sample in the file fidexRules.rls. The global statistics on the test set appear in statsFidex.txt. There is the mean covering size per rule, the mean number of antecedents per rule, and the mean rule fidelity, accuracy, and confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2c1cad-7802-47e5-bc09-aa28967913cc",
   "metadata": {},
   "source": [
    "# Global ruleSet generation - FidexGlo\n",
    "We've seen how to compute a rule that explains the decision of the model for a specific sample. Now, we will generalize a ruleset that characterizes the whole train dataset. That means that for each training sample, there is a rule in the set of rules that explains the model's decision for this sample. We will use this global ruleset to explain the results obtained on new test samples. If there is a rule of the ruleset corresponding to the sample, we take this one and get a global explanation for the sample. If there is none, we call Fidex and only have a local explanation.<br>\n",
    "\n",
    "To get the ruleSet we execute fidexGloRules which is located in the fidex module. Here are the possible parameters :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8286ec5a-306b-4048-84cb-7358c2647863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "Warning! The files are localised with respect to root folder dimlpfidex.\n",
      "The arguments can be specified in the command or in a json configuration file with --json_config_file your_config_file.json.\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Required parameters:\n",
      "\n",
      "--train_data_file <str>       Train data file\n",
      "--train_pred_file <str>       Train prediction file\n",
      "--train_class_file <str>      Train true class file, not mandatory if classes are specified in train data file\n",
      "--weights_file <str>          Weights file (not mandatory if a rules file is given with --rules_file)\n",
      "--rules_file <str>            Rules file to be converted to hyperlocus (not mandatory if a weights file is given with --weights_file)\n",
      "--global_rules_outfile <str>  Rules output file. If a .json filename is given, rules are saved in a special json format>\n",
      "--heuristic <int [1,3]>       Heuristic 1: optimal fidexGlo, 2: fast fidexGlo 3: very fast fidexGlo\n",
      "--nb_attributes <int [1,inf[> Number of attributes in dataset\n",
      "--nb_classes <int [2,inf[>    Number of classes in dataset\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Optional parameters: \n",
      "\n",
      "--json_config_file <str>      JSON file to configure all parameters. If used, this must be the sole argument and must specify the file's relative path\n",
      "--root_folder <str>           Folder based on main folder dimlpfidex(default folder) containg all used files and where generated files will be saved. If a file name is specified with another option, his path will be configured with respect to this root folder\n",
      "--attributes_file <str>       File of attributes\n",
      "--console_file <str>          File with console logs redirection\n",
      "--max_iterations <int [1,inf[>\n",
      "                              Max iteration number, also the max possible number of attributs in a rule, should be 25 if working with images (default: 10)\n",
      "--min_covering <int [1,inf[>  Minimum covering number (default: 2)\n",
      "--covering_strategy <bool>    Whether to use this strategy : if no rule is found with min_covering, find best rule with best covering using dichotomic search. Decreases min_fidelity if needed (default: True)\n",
      "--max_failed_attempts <int [0,inf[>\n",
      "                              Maximum number of failed attempts to find Fidex rule when covering is 1 and covering strategy is used (default: 30)\n",
      "--min_fidelity <float [0,1]>  Minimal rule fidelity accepted when generating a rule (default: 1.0)\n",
      "--lowest_min_fidelity <float [0,1]>\n",
      "                              Minimal min_fidelity to which we agree to go down during covering_strategy (default: 0.75)\n",
      "--dropout_dim <float [0,1]>   Dimension dropout parameter (default: 0.0)\n",
      "--dropout_hyp <float [0,1]>   Hyperplan dropout parameter (default: 0.0)\n",
      "--nb_quant_levels <int [3,inf[>\n",
      "                              Number of stairs in staircase activation function (default: 50)\n",
      "--decision_threshold <float [0,1]>\n",
      "                              Decision threshold for predictions, you need to specify the index of positive class if you want to use it\n",
      "--positive_class_index <int [0,nb_classes-1]>\n",
      "                              Index of positive class for the usage of decision threshold, index starts at 0\n",
      "--normalization_file <str>    File containing the mean and std of some attributes. Used to denormalize the rules if specified\n",
      "--mus <list<float ]inf,inf[>> Mean or median of each attribute index to denormalize in the rules\n",
      "--sigmas <list<float ]inf,inf[>>\n",
      "                              Standard deviation of each attribute index to denormalize in the rules\n",
      "--normalization_indices <list<int [0,nb_attributes-1]>>\n",
      "                              Attribute indices to denormalize in the rules, only used when no normalization_file is given, index starts at 0 (default: [0,...,nb_attributes-1])\n",
      "--nb_threads <int [1,nb_cores]>\n",
      "                              Number of threads used for computing the algorithm, 1=sequential execution (default: 1)\n",
      "--seed <int [0,inf[>          Seed, 0=random (default: 0)\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Execution example :\n",
      "\n",
      "fidex.fidexGloRules(\"--train_data_file datanormTrain.txt --train_pred_file predTrain.out --train_class_file dataclass2Train.txt --weights_file weights.wts --nb_attributes 16 --nb_classes 2 --heuristic 1 --global_rules_outfile globalRules.rls --root_folder dimlp/datafiles\")\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = fidex.fidexGloRules(\"--help\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665be28c-c788-41c2-ae00-b7a7b3118c2b",
   "metadata": {},
   "source": [
    "We use nearly the same parameters as for Fidex but we only need train data. We need to choose a heuristic for fidexGloRules, we choose the optimal to get better results. We don't forget to add the normalization file.<br>\n",
    "**It should take about 3 minutes**. If you have several processors available, you should add the parameter nb_threads with the number of processors that you want to use, it can speed up the process a lot. If you want to accelerate the process even more, you can use some dropout, the algorithm will randomly skip some dimensions or some hyperplans. For example, you can put: -d 0.5 -h 0.5, to skip half dimensions and half hyperplans, which should be about 4 times faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26e0d897-ab14-4e8d-a0f9-da7fe35bfb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FidexGloRules done\n"
     ]
    }
   ],
   "source": [
    "#res = fidex.fidexGloRules(\"--train_data_file trainData_normalized.txt --train_pred_file predTrain.out --train_class_file trainClass.txt --weights_file Weights/weights.wts --attributes_file attributes.txt --nb_attributes 30 --nb_classes 2 --heuristic 1 --global_rules_outfile globalRules.rls --console_file fidexGloRulesResult.txt --normalization_file normalization_stats.txt --root_folder data/BCWDataset\")\n",
    "res = fidex.fidexGloRules(\"--json_config_file data/BCWTemplates/config_fidexGloRules.json\")\n",
    "if (res == 0):\n",
    "    print(\"FidexGloRules done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e7b780-5fc6-4d0a-a82e-1b86ed6853d4",
   "metadata": {},
   "source": [
    "You can see the console result in the file fidexGloRulesResult.txt and the ruleset in the file globalRules.rls.\n",
    "The algorithm is random, so each execution may generate different rules and a different number of them. It should generate about 25 rules. You can see at the top of the globalRules file the number of rules, the mean covering number per rule, and the mean number of antecedents. Here is an example of a rule that you may obtain:<br>\n",
    "\n",
    "Rule 1: WORST_CONCAVE_POINTS<0.111377 AREA_ERROR<37.691316 -> BENIGN <br>\n",
    "   Train Covering size : 217 <br>\n",
    "   Train Fidelity : 1 <br>\n",
    "   Train Accuracy : 0.990783 <br>\n",
    "   Train Confidence : 0.984811 <br>\n",
    "\n",
    "This rule is the first rule, which means that it's the rule with the maximum covering. Here, 217 train samples verify this rule. She is 100% fidel with the model and has about 99% train accuracy.\n",
    "This rule says that if you have worst concave points lower than 0.111377 and an area error lower than 37.691316, then your breast cancer is benign. And this rule is accurate, on train test, at 99% and has 98% of confidence.<br>\n",
    "\n",
    "Now, we can see some global statistics on the test set, and also some statistics directly on each rule. So we will see the test accuracy on this rule.<br>\n",
    "We execute fidexGloStats which is located in the fidex module. First, let's check the parameters :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d6aaa70-4ffa-4205-99f8-840d67b260cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "Warning! The files are localised with respect to root folder dimlpfidex.\n",
      "The arguments can be specified in the command or in a json configuration file with --json_config_file your_config_file.json.\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Required parameters:\n",
      "\n",
      "--test_data_file <str>        Test data file\n",
      "--test_pred_file <str>        Test prediction file\n",
      "--test_class_file <str>       Test true class file, not mandatory if classes are specified in test data file\n",
      "--global_rules_file <str>     Ruleset input file\n",
      "--nb_attributes <int [1,inf[> Number of attributes in dataset\n",
      "--nb_classes <int [2,inf[>    Number of classes in dataset\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Optional parameters: \n",
      "\n",
      "--json_config_file <str>      JSON file to configure all parameters. If used, this must be the sole argument and must specify the file's relative path\n",
      "--root_folder <str>           Folder based on main folder dimlpfidex(default folder) containg all used files and where generated files will be saved. If a file name is specified with another option, his path will be configured with respect to this root folder\n",
      "--attributes_file <str>       File of attributes> Mandatory if rules file contains attribute names, if not, do not add it\n",
      "--stats_file <str>            Output statistic file name\n",
      "--global_rules_outfile <str>  Global ruleset output file with stats on test set, if you want to compute statistics of global rules on tests set\n",
      "--console_file <str>          File with console logs redirection\n",
      "--positive_class_index <int [0,nb_classes-1]>\n",
      "                              Index of positive class to compute true/false positive/negative rates, index starts at 0. If it is specified in the rules file, it has to be the same value.\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Execution example :\n",
      "\n",
      "fidex.fidexGloStats(\"--test_data_file datanormTest.txt --test_pred_file predTest.out --test_class_file dataclass2Test.txt --global_rules_file globalRules.rls --nb_attributes 16 --nb_classes 2 --stats_file stats.txt --root_folder dimlp/datafiles\")\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = fidex.fidexGloStats(\"--help\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b7ebed-01b9-4016-addb-d99839f7be74",
   "metadata": {},
   "source": [
    "We need the test files(data, prediction, class), the rules file, and the number of attributes and classes. We need to specify the attribute file as well. We choose to save the results in the file fidexGloStats.txt. With --global_rules_outfile we can generate the statistics on rules which will modify the rules file. If you want to keep the first ruleSet unchanged, you should give another name. Finally, with --positive_class_index we can specify the positive class in order to get a ROC curve and some other statistics on false and true positives/negatives. We will design the malignant class as positive. So here is the command :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "375ef5c0-aca8-4e1a-a842-ed229d23e8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters list:\n",
      " - test_data_file                                                          data/BCWDataset/testData.txt\n",
      " - test_pred_file                                                          data/BCWDataset/predTest.out\n",
      " - test_class_file                                                        data/BCWDataset/testClass.txt\n",
      " - global_rules_outfile                                                 data/BCWDataset/globalRules.rls\n",
      " - global_rules_file                                                    data/BCWDataset/globalRules.rls\n",
      " - root_folder                                                                          data/BCWDataset\n",
      " - attributes_file                                                       data/BCWDataset/attributes.txt\n",
      " - stats_file                                                         data/BCWDataset/fidexGloStats.txt\n",
      " - nb_attributes                                                                                     30\n",
      " - nb_classes                                                                                         2\n",
      " - positive_class_index                                                                               0\n",
      "End of Parameters list.\n",
      "\n",
      "Importing files...\n",
      "\n",
      "Data imported.\n",
      "\n",
      "Compute statistics...\n",
      "\n",
      "Global statistics of the rule set : \n",
      "Number of rules : 25, mean sample covering number per rule : 86.28, mean number of antecedents per rule : 1.88\n",
      "\n",
      "Statistics with a test set of 114 samples :\n",
      "\n",
      "No decision threshold is used.\n",
      "Positive index class used : 0\n",
      "The global rule fidelity rate is : 0.956140\n",
      "The global rule accuracy is : 0.973684\n",
      "The explainability rate (when we can find one or more rules, either correct ones or activated ones which all agree on the same class) is : 0.991228\n",
      "The default rule rate (when we can't find any rule activated for a sample) is : 0.008772\n",
      "The mean number of correct(fidel) activated rules per sample is : 4.850877\n",
      "The mean number of wrong(not fidel) activated rules per sample is : 0.096491\n",
      "The model test accuracy is : 0.964912\n",
      "The model test accuracy when rules and model agree is : 0.990826\n",
      "The model test accuracy when activated rules and model agree is : 0.990741\n",
      "\n",
      "With positive class MALIGNANT :\n",
      "\n",
      "Computation with model decision :\n",
      "The number of true positive test samples is : 38\n",
      "The number of false positive test samples is : 3\n",
      "The number of true negative test samples is : 72\n",
      "The number of false negative test samples is : 1\n",
      "The false positive rate is : 0.040000\n",
      "The false negative rate is : 0.025641\n",
      "The precision is : 0.926829\n",
      "The recall is : 0.974359\n",
      "\n",
      "Computation with rules decision :\n",
      "The number of true positive test samples is : 36\n",
      "The number of false positive test samples is : 0\n",
      "The number of true negative test samples is : 75\n",
      "The number of false negative test samples is : 3\n",
      "The false positive rate is : 0.000000\n",
      "The false negative rate is : 0.076923\n",
      "The precision is : 1.000000\n",
      "The recall is : 0.923077\n",
      "\n",
      "Full execution time = 0.03516 sec\n"
     ]
    }
   ],
   "source": [
    "#res = fidex.fidexGloStats(\"--test_data_file testData.txt --test_pred_file predTest.out --test_class_file testClass.txt --attributes_file attributes.txt --global_rules_file globalRules.rls --global_rules_outfile globalRules.rls --nb_attributes 30 --nb_classes 2 --stats_file fidexGloStats.txt --positive_class_index 0 --root_folder data/BCWDataset\")\n",
    "res = fidex.fidexGloStats(\"--json_config_file data/BCWTemplates/config_fidexGloStats.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c523c382-b2ed-413e-84e7-c0d39c6d1bf5",
   "metadata": {},
   "source": [
    "Here you can see the global statistics on the test set. As the previous calculations have randomness, each execution is a bit different. So here we will discuss the same case as before, so you may have slightly different results. In our case, we had about 98% fidelity, which is good, and a rule accuracy(96.5%) about 1.5% lower than the model accuracy(98%). So the rules seem to classify a bit worse. The explainability rate is the percentage of samples for which we can find a rule in the rules set. For the others, we need to execute Fidex (this is the default rule rate). In our case, we had more than a 97% explainability rate, so only in 3% of cases do we need to compute Fidex. Each rule can activate many rules. Here on average, a sample activates 5 correct rules and 0.05 wrong rules. A wrong rule is a rule with which the model doesn't agree. For example, if the rule says malign and the model says benign. Something interesting is the model test accuracy when rules and model agree. You can see that, generally, the accuracy increases if we consider samples where rules and model agree, and increases even more if we take only the activated rules (when there are no activated rules, we choose the model prediction). That means that the rules confirm well the model decision, but when no rule is found, the model decision may as well be wrong. <br>\n",
    "\n",
    "Finally, we have the statistics on the positive/negative decisions of the model and of the rules. For the model's decisions, we had 1% false positives and 7% false negatives. That means that when the model says that it's malign, it has a 99% chance of being malign. But when it says that it's benign, there is a 7% risk that it is malign in reality. So the precision is 97% and the recall is 93%.\n",
    "\n",
    "In the case of the rules decisions, the rules decision is the same as the model if we find a correct rule. If there is no rule, we can launch Fidex, so it's also the same decision as the model because it will create a fidel rule. The only scenario when the decision changes from the model's is when some rules are activated, all rules decide the same class which is not the class chosen by the model. The results are really close with 95% of precision and 93% of recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5400680-5058-4f75-97f1-552b1cead6d8",
   "metadata": {},
   "source": [
    "In globalRules file, you can now see the statistics of rules on the test set. Here is the same rule as before that I have now:<br>\n",
    "\n",
    "Rule 1: MEAN_CONCAVE_POINTS<0.041282 WORST_CONCAVE_POINTS<0.150829 -> BENIGN <br>\n",
    "   Train Covering size : 217 --- Test Covering size : 54 <br>\n",
    "   Train Fidelity : 1 --- Test Fidelity : 0.981481 <br>\n",
    "   Train Accuracy : 0.990783 --- Test Accuracy : 1 <br>\n",
    "   Train Confidence : 0.984811 --- Test Confidence : 0.979816 <br>\n",
    "\n",
    "You can see that the rule no longer always agrees with the model, only in 98.15% of cases. However, the rule accuracy has increased with the test. That means that the rule is very good in reality, with 100% of correct classification."
   ]
  },
  {
   "cell_type": "raw",
   "id": "c457745a-6030-486e-95d4-33040fe430ea",
   "metadata": {},
   "source": [
    "We can get a ROC curve obtained with the test set. Here are the parameters of computeRocCurve which is located in the trainings package :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "338b8a62-832e-45f7-8540-9ec4a7928447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: \n",
      "--test_class_file <str> --test_pred_file <str> --nb_classes <int [1,inf[> --positive_class_index <int [0,nb_classes-1]> [-h, --help] [--json_config_file <str>] [--root_folder <str>] [--stats_file <str>] [--show_params <bool>] [--estimator <str>] [--output_roc <str>]\n",
      "\n",
      "This is a parser for computeRocCurve\n",
      "\n",
      "\n",
      "Parameters:\n",
      "\n",
      "  ---------------------------------------------------------------------\n",
      "\n",
      "  Warning! The files are localised with respect to root folder dimlpfidex.\n",
      "\n",
      "  The arguments can be specified in the command or in a json configuration file with --json_config_file your_config_file.json.\n",
      "\n",
      "  ----------------------------\n",
      "\n",
      "  Required parameters:\n",
      "\n",
      "  --test_class_file <str>                        Test class file\n",
      "  --test_pred_file <str>                         Test prediction file\n",
      "  --nb_classes <int [1,inf[>                     Number of classes in dataset\n",
      "  --positive_class_index <int [0,nb_classes-1]>  Index of positive class, index starts at 0\n",
      "\n",
      "  ----------------------------\n",
      "\n",
      "  Optional parameters:\n",
      "\n",
      "  -h --help                                      show this help message and exit\n",
      "  --json_config_file <str>                       JSON file to configure all parameters. If used, this must be the sole argument and must specify the\n",
      "                                                 file's relative path\n",
      "  --root_folder <str>                            Folder based on main folder dimlpfidex(default folder) containg all used files and where generated\n",
      "                                                 files will be saved. If a file name is specified with another option, his path will be configured\n",
      "                                                 with respect to this root folder> (default: \"\")\n",
      "  --stats_file <str>                             Output statistic file name with AUC score, can be the training stats file\n",
      "  --show_params <bool>                           Whether to show parameters (default: True)\n",
      "\n",
      "  ----------------------------\n",
      "\n",
      "  ROC parameters (optional):\n",
      "\n",
      "  --estimator <str>                              Name of estimator\n",
      "  --output_roc <str>                             Output ROC curve file name (default: roc_curve.png)\n",
      "\n",
      "  ----------------------------\n",
      "\n",
      "Execution example :\n",
      "\n",
      "computeRocCurve('--test_class_file dataclass2Test.txt --test_pred_file predTest.out --positive_class_index 1 --output_roc roc_curve.png --stats_file stats.txt --root_folder dimlp/datafiles --nb_classes 2')\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from trainings.computeRocCurve import computeRocCurve\n",
    "res = computeRocCurve(\"--help\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ec3ff5-a6db-4478-9d36-87f2ddbc3247",
   "metadata": {},
   "source": [
    "We execute computeRocCurve :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c817149-bae3-4ce2-8bc8-074a27747705",
   "metadata": {},
   "outputs": [],
   "source": [
    "#res = computeRocCurve('--test_class_file testClass.txt --test_pred_file predTest.out --positive_class_index 0 --output_roc outRoc.png --stats_file stats.txt --root_folder data/BCWDataset --nb_classes 2 --show_params false')\n",
    "res = computeRocCurve(\"--json_config_file data/BCWTemplates/config_roc.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a27b096-fbfd-4c67-a303-58a5b404169b",
   "metadata": {},
   "source": [
    "The AUC score is added to the stats file and the ROC curve is saved in the outRoc.png file. We get an AUC of about 99%. <br>\n",
    "We can visualize the AUC curve :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd579681-492d-4900-84ae-69aeef690a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(filename=\"data/BCWDataset/outRoc.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6709efc3-5ac9-41d8-927e-1c5fedddef82",
   "metadata": {},
   "source": [
    "Finally, it's possible to launch fidexGlo on a test set. It will, for each test sample, search in the global ruleset for all the rules that verify the sample's properties and match the decision of the model. If no rule verifies the properties, it calls Fidex on the test sample. In the other case, it gives all the correct and wrong activated rules.<br>\n",
    "\n",
    "FidexGlo is located in the fidex module. Here are the possible parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24ccff77-b9a8-4c97-b3f7-2f8756935bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "Warning! The files are localised with respect to root folder dimlpfidex.\n",
      "The arguments can be specified in the command or in a json configuration file with --json_config_file your_config_file.json.\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Required parameters:\n",
      "\n",
      "--test_data_file <str>        Test sample(s) data file with data and prediction(if no --test_pred_file), classes may been added here if launching with fidex(--with_fidex)\n",
      "--global_rules_file <str>     Ruleset input file\n",
      "--nb_attributes <int [1,inf[> Number of attributes in dataset\n",
      "--nb_classes <int [2,inf[>    Number of classes in dataset\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Optional parameters: \n",
      "\n",
      "--json_config_file <str>      JSON file to configure all parameters. If used, this must be the sole argument and must specify the file's relative path\n",
      "--root_folder <str>           Folder based on main folder dimlpfidex(default folder) containg all used files and where generated files will be saved. If a file name is specified with another option, his path will be configured with respect to this root folder\n",
      "--attributes_file <str>       File of attributes> Mandatory if rules file contains attribute names, if not, do not add it\n",
      "--test_pred_file <str>        Test prediction file> if given, --test_data_file needs to have only test datas\n",
      "--explanation_file <str>      Explanation(s) output file name\n",
      "--console_file <str>          File with console logs redirection\n",
      "--with_fidex <bool>           Whether to use Fidex if no rule is found in global rules (default: False)\n",
      "--with_minimal_version <bool> Whether to use minimal version, which only gets correct activated rules and if with_fidex, launches Fidex when no such rule is found (default: False)\n",
      "\n",
      "----------------------------\n",
      "\n",
      "If using fidex :\n",
      "\n",
      "Required :\n",
      "\n",
      "--train_data_file <str>       Train data file\n",
      "--train_pred_file <str>       Train prediction file\n",
      "--train_class_file <str>      Train true class file, not mandatory if classes are specified in train data file\n",
      "--weights_file <str>          Weights file (not mandatory if a rules file is given with --rules_file)\n",
      "--rules_file <str>            Rules file to be converted to hyperlocus (not mandatory if a weights file is given with --weights_file)\n",
      "\n",
      "Optional :\n",
      "\n",
      "--test_class_file <str>       Test true class file, classes can be specified in test data file\n",
      "--max_iterations <int [1,inf[>\n",
      "                              Max iteration number, also the max possible number of attributs in a rule, should be 25 if working with images (default: 10)\n",
      "--min_covering <int [1,inf[>  Minimum covering number (default: 2)\n",
      "--covering_strategy <bool>    Whether to use this strategy : if no rule is found with min_covering, find best rule with best covering using dichotomic search. Decreases min_fidelity if needed (default: True)\n",
      "--max_failed_attempts <int [0,inf[>\n",
      "                              Maximum number of failed attempts to find Fidex rule when covering is 1 and covering strategy is used (default: 30)\n",
      "--min_fidelity <float [0,1]>  Minimal rule fidelity accepted when generating a rule (default: 1.0)\n",
      "--lowest_min_fidelity <float [0,1]>\n",
      "                              Minimal min_fidelity to which we agree to go down during covering_strategy (default: 0.75)\n",
      "--dropout_dim <float [0,1]>   Dimension dropout parameter (default: 0.0)\n",
      "--dropout_hyp <float [0,1]>   Hyperplan dropout parameter (default: 0.0)\n",
      "--nb_quant_levels <int [3,inf[>\n",
      "                              Number of stairs in staircase activation function (default: 50)\n",
      "--normalization_file <str>    File containing the mean and std of some attributes. Used to denormalize the rules if specified\n",
      "--mus <list<float ]inf,inf[>> Mean or median of each attribute index to denormalize in the rules\n",
      "--sigmas <list<float ]inf,inf[>>\n",
      "                              Standard deviation of each attribute index to denormalize in the rules\n",
      "--normalization_indices <list<int [0,nb_attributes-1]>>\n",
      "                              Attribute indices to denormalize in the rules, only used when no normalization_file is given, index starts at 0 (default: [0,...,nb_attributes-1])\n",
      "--seed <int [0,inf[>          Seed, 0=random (default: 0)\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Execution example :\n",
      "\n",
      "fidex.fidexGlo(\"--test_data_file datanormTest.txt --test_pred_file predTest.out --global_rules_file globalRules.rls --nb_attributes 16 --nb_classes 2 --explanation_file explanation.txt --root_folder dimlp/datafiles --with_fidex true --train_data_file datanormTrain.txt --train_pred_file predTrain.out --train_class_file dataclass2Train.txt --test_class_file dataclass2Test.txt --weights_file weights.wts\")\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = fidex.fidexGlo(\"--help\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c845e1fe-9226-4aa7-874d-eb582695afda",
   "metadata": {},
   "source": [
    "As we want to use Fidex on test sample not covered by the global ruleset, we need to specify the Fidex parameters. We don't forget to add the normalization file and launch it with :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ec3cd7f-502b-49c4-b1ce-28f219b8d5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanations generated\n"
     ]
    }
   ],
   "source": [
    "#res = fidex.fidexGlo(\"--test_data_file testData.txt --test_pred_file predTest.out --global_rules_file globalRules.rls --nb_attributes 30 --nb_classes 2 --attributes_file attributes.txt --explanation_file explanations.txt --console_file fidexGloResults.txt --root_folder data/BCWDataset --with_fidex true --train_data_file trainData.txt --train_pred_file predTrain.out --train_class_file trainClass.txt --test_class_file testClass.txt --weights_file Weights/weights.wts --normalization_file normalization_stats.txt\")\n",
    "res = fidex.fidexGlo(\"--json_config_file data/BCWTemplates/config_fidexGlo.json\")\n",
    "\n",
    "if res == 0:\n",
    "    print(\"Explanations generated\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccf58f4-b70b-4586-ad3c-345d9a5d0823",
   "metadata": {},
   "source": [
    "The explanations for each test sample can then be found in the file explanations.txt. We do not find a global rule for around 2.6% of the samples, for which we calculate a local rule using Fidex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7f3208-c538-40eb-8c76-31e75d687198",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Throughout this notebook, we've learned how to use DimlpBT to train a dataset and get some explaining rules, and we got into the different Fidex algorithms to get some local and global explanations, and some statistics on the model's decisions. We used the example of the breast cancer dataset from Wisconsin and we saw that the algorithms perform very well. It gives some good explanations of the model's decision and does it very fast, especially if a fidexGlo ruleset has been computed beforehand. You can try with any tabular dataset you want, you just have to remember to transform the data in a good format. <be>\n",
    "\n",
    "We didn't speak about every single parameter, you can try to change every hyperparameter you want to see how it goes. An interesting parameter that we didn't consider is the parameter for decision threshold (--decision_threshold) in Fidex algorithms. It allows us to change prediction with respect to a specific threshold on the positive class. If the model gives a score prediction, for the positive class, greater than this threshold, the model prediction is considered to be the positive class, even if another class obtains a higher score. If the recall is not good enough, it's possible to improve it this way. Another parameter is the seed. It allows you to remove the randomness of the algorithms and get the same result in each execution for the same parameters and data.<br>\n",
    "\n",
    "We considered only a simple tabular dataset. It's also possible to use it for an image classification problem. To see how we can train a dataset with convolutions, we recommend exploring the Mnist notebook for a hands-on experience **Insérer lien notebook Mnist**. There are also other training methods, like an MLP or decision trees. The Keel Australian notebook goes through these and shows what to do when we have categorical attributes **Insérer Keel Australian notebook**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605dcb45-4862-4268-bef2-068cf96de3d9",
   "metadata": {},
   "source": [
    "# Références\n",
    "\n",
    "Article DimlpBT de Guido\n",
    "Article Fidex de Guido (à venir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
